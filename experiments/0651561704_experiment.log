EXPERIMENT ID: None [new experiment]

DATA DESCRIPTION:
{name: mnist,
 m_train_per_class_limit: None,
 m_test_per_class_limit: None,
 uniform_scaling: True,
 seed: 0,
 n_repetitions: 1}

HMDL CLF DESCRIPTION:
[(<class 'hmdl.SequentialClassifier'>, {'n_epochs': 100, 'n_batches': 20, 'loss': 'categorical_crossentropy', 'learning_rate': 0.001, 'decay_rate': 0.0, 'use_adam': True, 'momentum_rate': 0.0, 'gradient_clip': None}),
 (<class 'hmdl.Conv2D'>, {'input_shape': (28, 28, 1), 'kernel_size': 7, 'n_kernels': 32, 'activation': 'relu'}),
 (<class 'hmdl.Conv2D'>, {'kernel_size': 7, 'n_kernels': 32, 'activation': 'relu'}),
 (<class 'hmdl.MaxPool2D'>, {'pool_size': 2}),
 (<class 'hmdl.Dropout'>, {'rate': 0.125}),
 (<class 'hmdl.Conv2D'>, {'kernel_size': 5, 'n_kernels': 64, 'activation': 'relu'}),
 (<class 'hmdl.Conv2D'>, {'kernel_size': 5, 'n_kernels': 64, 'activation': 'relu'}),
 (<class 'hmdl.MaxPool2D'>, {'pool_size': 2}),
 (<class 'hmdl.Dropout'>, {'rate': 0.25}),
 (<class 'hmdl.Conv2D'>, {'kernel_size': 3, 'n_kernels': 128, 'activation': 'relu'}),
 (<class 'hmdl.Conv2D'>, {'kernel_size': 3, 'n_kernels': 128, 'activation': 'relu'}),
 (<class 'hmdl.MaxPool2D'>, {'pool_size': 2}),
 (<class 'hmdl.Dropout'>, {'rate': 0.5}),
 (<class 'hmdl.Flatten'>, {}),
 (<class 'hmdl.Dense'>, {'n_neurons': 128, 'activation': 'relu'}),
 (<class 'hmdl.Dropout'>, {'rate': 0.5}),
 (<class 'hmdl.Dense'>, {'n_neurons': 10, 'activation': 'softmax'})]

ABOUT TO RUN NEW EXPERIMENT WITH ID: 0651561704 [generated]
GPU PROPERTIES: {'name': b'Quadro M4000M', 'max_threads_per_block': 1024, 'max_block_dim_x': 1024, 'max_block_dim_y': 1024, 'max_block_dim_z': 64, 'max_grid_dim_x': 2147483647, 'max_grid_dim_y': 65535, 'max_grid_dim_z': 65535, 'max_shared_memory_per_block': 49152, 'async_engine_count': 5, 'can_map_host_memory': 1, 'multiprocessor_count': 10, 'warp_size': 32, 'unified_addressing': 1, 'pci_bus_id': 1, 'pci_device_id': 0, 'compute_capability': (5, 2), 'cores_per_SM': 128, 'cores_total': 1280}

***
REPETITION: 1/1... [seed now: 0]

HMDL MODEL SUMMARY:
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
NO. LAYER   TYPE        INPUT SHAPE             EXTRA INFO  ACTIVATION    OUTPUT SHAPE          DO FORWARD IMPL       DO BACKWARD IMPL      DO BACKWARD OUTPUT IMPL   L1 PENALTIES        L2 PENALTIES        PARAMS          
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
0   c0      Conv2D      (None, 28, 28, 1)       7x7         relu          (None, 28, 28, 32)    numba_cuda_tiles      numba_cuda_direct     numba_cuda_tiles                                                  1600            
1   c1      Conv2D      (None, 28, 28, 32)      7x7         relu          (None, 28, 28, 32)    numba_cuda_direct     numba_cuda_direct     numba_cuda_tiles                                                  50208           
2   m2      MaxPool2D   (None, 28, 28, 32)      2x2                       (None, 14, 14, 32)    numba_cuda_direct                           numba_cuda_direct                                                 0               
3   dr3     Dropout     (None, 14, 14, 32)      0.125                     (None, 14, 14, 32)                                                                                                                  0               
4   c4      Conv2D      (None, 14, 14, 32)      5x5         relu          (None, 14, 14, 64)    numba_cuda_direct     numba_cuda_direct     numba_cuda_direct                                                 51264           
5   c5      Conv2D      (None, 14, 14, 64)      5x5         relu          (None, 14, 14, 64)    numba_cuda_direct     numba_cuda_direct     numba_cuda_direct                                                 102464          
6   m6      MaxPool2D   (None, 14, 14, 64)      2x2                       (None, 7, 7, 64)      numba_cuda_direct                           numba_cuda_direct                                                 0               
7   dr7     Dropout     (None, 7, 7, 64)        0.25                      (None, 7, 7, 64)                                                                                                                    0               
8   c8      Conv2D      (None, 7, 7, 64)        3x3         relu          (None, 7, 7, 128)     numba_cuda_direct     numba_cuda_direct     numba_cuda_direct                                                 73856           
9   c9      Conv2D      (None, 7, 7, 128)       3x3         relu          (None, 7, 7, 128)     numba_cuda_direct     numba_cuda_direct     numba_cuda_direct                                                 147584          
10  m10     MaxPool2D   (None, 7, 7, 128)       2x2                       (None, 3, 3, 128)     numba_cuda_direct                           numba_cuda_direct                                                 0               
11  dr11    Dropout     (None, 3, 3, 128)       0.5                       (None, 3, 3, 128)                                                                                                                   0               
12  f12     Flatten     (None, 3, 3, 128)                                 (None, 1152)                                                                                                                        0               
13  d13     Dense       (None, 1152)                        relu          (None, 128)           numpy                 numpy                 numpy                                                             147584          
14  dr14    Dropout     (None, 128)             0.5                       (None, 128)                                                                                                                         0               
15  d15     Dense       (None, 128)                         softmax       (None, 10)            numpy                 numpy                 numpy                                                             1290            
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
TOTAL PARAMS: 575850
FIT SETTINGS: [n_epochs: 100, n_batches: 20, loss: categorical_crossentropy, learning_rate: 0.001, decay_rate: 0.0, use_adam: True, momentum_rate: 0.0, gradient_clip: None]
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

HMDL MODEL STRUCTURE STRING: 28x28x1->C(7,32,relu);C(7,32,relu);M(2);DR(0.125);C(5,64,relu);C(5,64,relu);M(2);DR(0.25);C(3,128,relu);C(3,128,relu);M(2);DR(0.5);F();D(128,relu);DR(0.5);D(10,softmax);
HMDL MODEL STRUCTURE STRING FOR MATHEMATICA: {{28,28,1},{"C",7,32,"relu"},{"C",7,32,"relu"},{"M",2},{"DR",0.125},{"C",5,64,"relu"},{"C",5,64,"relu"},{"M",2},{"DR",0.25},{"C",3,128,"relu"},{"C",3,128,"relu"},{"M",2},{"DR",0.5},{"F"},{"D",128,"relu"},{"DR",0.5},{"D",10,"softmax"}}

HMDL CLF ACC AND LOSS... [before fit]
[train acc: 0.10503333333333334, train loss: 4.09876012802124]
[test acc: 0.1036, test loss: 4.0988688468933105]
HMDL CLF ACC AND LOSS DONE. [time: 305.1106903553009 s]

HMDL FIT...
[norms of weights -> l1: 21730.57, l2: 34.26235]
EPOCH: 1/100...
[fit info (epoch 1):
 epoch: 1    batch: 1    loss: 9.918     acc: 0.09233
 epoch: 1    batch: 2    loss: 7.589     acc: 0.104
 epoch: 1    batch: 3    loss: 4.416     acc: 0.09033
 epoch: 1    batch: 4    loss: 5.214     acc: 0.1207
 epoch: 1    batch: 5    loss: 4.844     acc: 0.1043
 epoch: 1    batch: 6    loss: 2.862     acc: 0.104
 epoch: 1    batch: 7    loss: 2.481     acc: 0.08833
 epoch: 1    batch: 8    loss: 2.352     acc: 0.1113
 epoch: 1    batch: 9    loss: 2.409     acc: 0.1123
 epoch: 1    batch: 10   loss: 2.358     acc: 0.1027
 epoch: 1    batch: 11   loss: 2.351     acc: 0.1083
 epoch: 1    batch: 12   loss: 2.345     acc: 0.109
 epoch: 1    batch: 13   loss: 2.331     acc: 0.08567
 epoch: 1    batch: 14   loss: 2.317     acc: 0.09633
 epoch: 1    batch: 15   loss: 2.322     acc: 0.093
 epoch: 1    batch: 16   loss: 2.308     acc: 0.126
 epoch: 1    batch: 17   loss: 2.303     acc: 0.1167
 epoch: 1    batch: 18   loss: 2.31      acc: 0.08367
 epoch: 1    batch: 19   loss: 2.305     acc: 0.08567
 epoch: 1    batch: 20   loss: 2.306     acc: 0.094
 means -->               loss: 3.382     acc: 0.1014]
[norms of weights -> l1: 21799.521, l2: 34.413834]
EPOCH: 2/100...
[fit info (epoch 2):
 epoch: 2    batch: 1    loss: 2.303     acc: 0.105
 epoch: 2    batch: 2    loss: 2.306     acc: 0.09433
 epoch: 2    batch: 3    loss: 2.307     acc: 0.092
 epoch: 2    batch: 4    loss: 2.307     acc: 0.08433
 epoch: 2    batch: 5    loss: 2.304     acc: 0.09433
 epoch: 2    batch: 6    loss: 2.299     acc: 0.1063
 epoch: 2    batch: 7    loss: 2.302     acc: 0.1077
 epoch: 2    batch: 8    loss: 2.3       acc: 0.098
 epoch: 2    batch: 9    loss: 2.295     acc: 0.1673
 epoch: 2    batch: 10   loss: 2.302     acc: 0.09567
 epoch: 2    batch: 11   loss: 2.304     acc: 0.1017
 epoch: 2    batch: 12   loss: 2.305     acc: 0.09667
 epoch: 2    batch: 13   loss: 2.299     acc: 0.112
 epoch: 2    batch: 14   loss: 2.301     acc: 0.1033
 epoch: 2    batch: 15   loss: 2.302     acc: 0.09367
 epoch: 2    batch: 16   loss: 2.301     acc: 0.1073
 epoch: 2    batch: 17   loss: 2.299     acc: 0.09967
 epoch: 2    batch: 18   loss: 2.298     acc: 0.1033
 epoch: 2    batch: 19   loss: 2.299     acc: 0.09933
 epoch: 2    batch: 20   loss: 2.298     acc: 0.1093
 means -->               loss: 2.302     acc: 0.1036]
[norms of weights -> l1: 21830.07, l2: 34.479575]
EPOCH: 3/100...
[fit info (epoch 3):
 epoch: 3    batch: 1    loss: 2.301     acc: 0.086
 epoch: 3    batch: 2    loss: 2.301     acc: 0.1087
 epoch: 3    batch: 3    loss: 2.297     acc: 0.139
 epoch: 3    batch: 4    loss: 2.295     acc: 0.1003
 epoch: 3    batch: 5    loss: 2.297     acc: 0.1583
 epoch: 3    batch: 6    loss: 2.295     acc: 0.1093
 epoch: 3    batch: 7    loss: 2.296     acc: 0.168
 epoch: 3    batch: 8    loss: 2.298     acc: 0.103
 epoch: 3    batch: 9    loss: 2.293     acc: 0.122
 epoch: 3    batch: 10   loss: 2.297     acc: 0.09933
 epoch: 3    batch: 11   loss: 2.293     acc: 0.2633
 epoch: 3    batch: 12   loss: 2.294     acc: 0.1293
 epoch: 3    batch: 13   loss: 2.294     acc: 0.1273
 epoch: 3    batch: 14   loss: 2.296     acc: 0.1137
 epoch: 3    batch: 15   loss: 2.292     acc: 0.143
 epoch: 3    batch: 16   loss: 2.289     acc: 0.135
 epoch: 3    batch: 17   loss: 2.289     acc: 0.09533
 epoch: 3    batch: 18   loss: 2.287     acc: 0.153
 epoch: 3    batch: 19   loss: 2.293     acc: 0.1667
 epoch: 3    batch: 20   loss: 2.298     acc: 0.09767
 means -->               loss: 2.295     acc: 0.1309]
[norms of weights -> l1: 21846.584, l2: 34.513385]
EPOCH: 4/100...
[fit info (epoch 4):
 epoch: 4    batch: 1    loss: 2.29      acc: 0.1447
 epoch: 4    batch: 2    loss: 2.285     acc: 0.1143
 epoch: 4    batch: 3    loss: 2.277     acc: 0.1003
 epoch: 4    batch: 4    loss: 2.27      acc: 0.1537
 epoch: 4    batch: 5    loss: 2.273     acc: 0.1553
 epoch: 4    batch: 6    loss: 2.275     acc: 0.186
 epoch: 4    batch: 7    loss: 2.267     acc: 0.1067
 epoch: 4    batch: 8    loss: 2.273     acc: 0.1627
 epoch: 4    batch: 9    loss: 2.262     acc: 0.106
 epoch: 4    batch: 10   loss: 2.258     acc: 0.2107
 epoch: 4    batch: 11   loss: 2.251     acc: 0.1107
 epoch: 4    batch: 12   loss: 2.282     acc: 0.1427
 epoch: 4    batch: 13   loss: 2.244     acc: 0.1097
 epoch: 4    batch: 14   loss: 2.224     acc: 0.1777
 epoch: 4    batch: 15   loss: 2.221     acc: 0.1813
 epoch: 4    batch: 16   loss: 2.225     acc: 0.157
 epoch: 4    batch: 17   loss: 2.238     acc: 0.254
 epoch: 4    batch: 18   loss: 2.187     acc: 0.2087
 epoch: 4    batch: 19   loss: 2.187     acc: 0.1987
 epoch: 4    batch: 20   loss: 2.192     acc: 0.2167
 means -->               loss: 2.249     acc: 0.1599]
[norms of weights -> l1: 21880.648, l2: 34.582903]
EPOCH: 5/100...
[fit info (epoch 5):
 epoch: 5    batch: 1    loss: 2.151     acc: 0.2757
 epoch: 5    batch: 2    loss: 2.101     acc: 0.2937
 epoch: 5    batch: 3    loss: 2.128     acc: 0.1977
 epoch: 5    batch: 4    loss: 2.062     acc: 0.272
 epoch: 5    batch: 5    loss: 2.1       acc: 0.2147
 epoch: 5    batch: 6    loss: 1.959     acc: 0.264
 epoch: 5    batch: 7    loss: 2.003     acc: 0.291
 epoch: 5    batch: 8    loss: 2.028     acc: 0.2523
 epoch: 5    batch: 9    loss: 2.061     acc: 0.2653
 epoch: 5    batch: 10   loss: 1.972     acc: 0.3627
 epoch: 5    batch: 11   loss: 2.007     acc: 0.37
 epoch: 5    batch: 12   loss: 1.914     acc: 0.4173
 epoch: 5    batch: 13   loss: 1.848     acc: 0.375
 epoch: 5    batch: 14   loss: 1.826     acc: 0.3573
 epoch: 5    batch: 15   loss: 1.787     acc: 0.4693
 epoch: 5    batch: 16   loss: 1.964     acc: 0.444
 epoch: 5    batch: 17   loss: 1.6       acc: 0.4673
 epoch: 5    batch: 18   loss: 1.944     acc: 0.3777
 epoch: 5    batch: 19   loss: 1.966     acc: 0.2973
 epoch: 5    batch: 20   loss: 1.745     acc: 0.4257
 means -->               loss: 1.958     acc: 0.3345]
[norms of weights -> l1: 21944.742, l2: 34.718986]
EPOCH: 6/100...
[fit info (epoch 6):
 epoch: 6    batch: 1    loss: 1.725     acc: 0.4887
 epoch: 6    batch: 2    loss: 1.654     acc: 0.514
 epoch: 6    batch: 3    loss: 1.982     acc: 0.3123
 epoch: 6    batch: 4    loss: 1.907     acc: 0.286
 epoch: 6    batch: 5    loss: 1.647     acc: 0.4617
 epoch: 6    batch: 6    loss: 1.874     acc: 0.3733
 epoch: 6    batch: 7    loss: 1.542     acc: 0.5353
 epoch: 6    batch: 8    loss: 1.645     acc: 0.473
 epoch: 6    batch: 9    loss: 1.933     acc: 0.39
 epoch: 6    batch: 10   loss: 1.709     acc: 0.4883
 epoch: 6    batch: 11   loss: 1.698     acc: 0.4263
 epoch: 6    batch: 12   loss: 1.708     acc: 0.4273
 epoch: 6    batch: 13   loss: 1.531     acc: 0.5443
 epoch: 6    batch: 14   loss: 1.459     acc: 0.5647
 epoch: 6    batch: 15   loss: 1.429     acc: 0.4903
 epoch: 6    batch: 16   loss: 1.34      acc: 0.52
 epoch: 6    batch: 17   loss: 1.949     acc: 0.4103
 epoch: 6    batch: 18   loss: 1.74      acc: 0.3697
 epoch: 6    batch: 19   loss: 1.412     acc: 0.523
 epoch: 6    batch: 20   loss: 1.719     acc: 0.4447
 means -->               loss: 1.68      acc: 0.4522]
[norms of weights -> l1: 22023.178, l2: 34.883592]
EPOCH: 7/100...
[fit info (epoch 7):
 epoch: 7    batch: 1    loss: 1.5       acc: 0.49
 epoch: 7    batch: 2    loss: 1.333     acc: 0.596
 epoch: 7    batch: 3    loss: 1.52      acc: 0.578
 epoch: 7    batch: 4    loss: 1.281     acc: 0.5873
 epoch: 7    batch: 5    loss: 1.201     acc: 0.5577
 epoch: 7    batch: 6    loss: 1.208     acc: 0.593
 epoch: 7    batch: 7    loss: 1.289     acc: 0.526
 epoch: 7    batch: 8    loss: 1.362     acc: 0.5447
 epoch: 7    batch: 9    loss: 1.318     acc: 0.5583
 epoch: 7    batch: 10   loss: 1.669     acc: 0.499
 epoch: 7    batch: 11   loss: 1.183     acc: 0.5963
 epoch: 7    batch: 12   loss: 1.07      acc: 0.662
 epoch: 7    batch: 13   loss: 1.343     acc: 0.5463
 epoch: 7    batch: 14   loss: 1.289     acc: 0.5787
 epoch: 7    batch: 15   loss: 1.262     acc: 0.5703
 epoch: 7    batch: 16   loss: 1.351     acc: 0.5847
 epoch: 7    batch: 17   loss: 1.708     acc: 0.4567
 epoch: 7    batch: 18   loss: 1.44      acc: 0.4813
 epoch: 7    batch: 19   loss: 1.249     acc: 0.596
 epoch: 7    batch: 20   loss: 1.308     acc: 0.6297
 means -->               loss: 1.344     acc: 0.5616]
[norms of weights -> l1: 22108.413, l2: 35.061743]
EPOCH: 8/100...
[fit info (epoch 8):
 epoch: 8    batch: 1    loss: 1.387     acc: 0.4877
 epoch: 8    batch: 2    loss: 1.294     acc: 0.5773
 epoch: 8    batch: 3    loss: 1.196     acc: 0.6113
 epoch: 8    batch: 4    loss: 1.319     acc: 0.6103
 epoch: 8    batch: 5    loss: 1.067     acc: 0.6883
 epoch: 8    batch: 6    loss: 1.068     acc: 0.6383
 epoch: 8    batch: 7    loss: 1.095     acc: 0.6183
 epoch: 8    batch: 8    loss: 0.9923    acc: 0.6783
 epoch: 8    batch: 9    loss: 0.9563    acc: 0.6463
 epoch: 8    batch: 10   loss: 0.8038    acc: 0.7253
 epoch: 8    batch: 11   loss: 1.049     acc: 0.614
 epoch: 8    batch: 12   loss: 0.8093    acc: 0.716
 epoch: 8    batch: 13   loss: 0.8038    acc: 0.755
 epoch: 8    batch: 14   loss: 0.8406    acc: 0.739
 epoch: 8    batch: 15   loss: 0.8434    acc: 0.6707
 epoch: 8    batch: 16   loss: 0.7983    acc: 0.7313
 epoch: 8    batch: 17   loss: 1.017     acc: 0.674
 epoch: 8    batch: 18   loss: 0.8748    acc: 0.6957
 epoch: 8    batch: 19   loss: 0.9299    acc: 0.6923
 epoch: 8    batch: 20   loss: 0.8075    acc: 0.7603
 means -->               loss: 0.9976    acc: 0.6665]
[norms of weights -> l1: 22192.327, l2: 35.238624]
EPOCH: 9/100...
[fit info (epoch 9):
 epoch: 9    batch: 1    loss: 0.8176    acc: 0.7193
 epoch: 9    batch: 2    loss: 0.7695    acc: 0.7633
 epoch: 9    batch: 3    loss: 0.6606    acc: 0.778
 epoch: 9    batch: 4    loss: 0.8612    acc: 0.7133
 epoch: 9    batch: 5    loss: 0.949     acc: 0.709
 epoch: 9    batch: 6    loss: 1.012     acc: 0.6883
 epoch: 9    batch: 7    loss: 0.922     acc: 0.7123
 epoch: 9    batch: 8    loss: 0.873     acc: 0.7197
 epoch: 9    batch: 9    loss: 0.7536    acc: 0.756
 epoch: 9    batch: 10   loss: 1.099     acc: 0.6223
 epoch: 9    batch: 11   loss: 0.9516    acc: 0.6273
 epoch: 9    batch: 12   loss: 0.9541    acc: 0.7017
 epoch: 9    batch: 13   loss: 1.277     acc: 0.554
 epoch: 9    batch: 14   loss: 1.766     acc: 0.445
 epoch: 9    batch: 15   loss: 0.8627    acc: 0.694
 epoch: 9    batch: 16   loss: 0.7696    acc: 0.7377
 epoch: 9    batch: 17   loss: 0.7472    acc: 0.7723
 epoch: 9    batch: 18   loss: 0.8462    acc: 0.724
 epoch: 9    batch: 19   loss: 0.6824    acc: 0.8
 epoch: 9    batch: 20   loss: 0.9959    acc: 0.661
 means -->               loss: 0.9285    acc: 0.6949]
[norms of weights -> l1: 22259.15, l2: 35.380093]
EPOCH: 10/100...
[fit info (epoch 10):
 epoch: 10   batch: 1    loss: 1.135     acc: 0.608
 epoch: 10   batch: 2    loss: 0.7963    acc: 0.749
 epoch: 10   batch: 3    loss: 0.7682    acc: 0.7223
 epoch: 10   batch: 4    loss: 0.8935    acc: 0.703
 epoch: 10   batch: 5    loss: 0.8793    acc: 0.7267
 epoch: 10   batch: 6    loss: 0.6708    acc: 0.7927
 epoch: 10   batch: 7    loss: 0.7761    acc: 0.7347
 epoch: 10   batch: 8    loss: 0.6231    acc: 0.803
 epoch: 10   batch: 9    loss: 0.7284    acc: 0.7387
 epoch: 10   batch: 10   loss: 0.8845    acc: 0.7077
 epoch: 10   batch: 11   loss: 0.5979    acc: 0.776
 epoch: 10   batch: 12   loss: 0.7771    acc: 0.7477
 epoch: 10   batch: 13   loss: 0.6912    acc: 0.767
 epoch: 10   batch: 14   loss: 0.7568    acc: 0.7363
 epoch: 10   batch: 15   loss: 0.6537    acc: 0.7807
 epoch: 10   batch: 16   loss: 0.7639    acc: 0.7343
 epoch: 10   batch: 17   loss: 0.5701    acc: 0.7963
 epoch: 10   batch: 18   loss: 0.688     acc: 0.7363
 epoch: 10   batch: 19   loss: 0.5827    acc: 0.8027
 epoch: 10   batch: 20   loss: 0.7985    acc: 0.712
 means -->               loss: 0.7518    acc: 0.7437]
[norms of weights -> l1: 22325.719, l2: 35.517419]
EPOCH: 11/100...
[fit info (epoch 11):
 epoch: 11   batch: 1    loss: 0.7063    acc: 0.7577
 epoch: 11   batch: 2    loss: 0.7082    acc: 0.7587
 epoch: 11   batch: 3    loss: 0.6694    acc: 0.7667
 epoch: 11   batch: 4    loss: 0.7639    acc: 0.762
 epoch: 11   batch: 5    loss: 0.7281    acc: 0.7627
 epoch: 11   batch: 6    loss: 0.4874    acc: 0.8413
 epoch: 11   batch: 7    loss: 0.5511    acc: 0.8247
 epoch: 11   batch: 8    loss: 0.6412    acc: 0.7697
 epoch: 11   batch: 9    loss: 0.56      acc: 0.837
 epoch: 11   batch: 10   loss: 0.6965    acc: 0.7863
 epoch: 11   batch: 11   loss: 0.5693    acc: 0.812
 epoch: 11   batch: 12   loss: 0.6846    acc: 0.774
 epoch: 11   batch: 13   loss: 0.5241    acc: 0.8243
 epoch: 11   batch: 14   loss: 0.637     acc: 0.811
 epoch: 11   batch: 15   loss: 0.9226    acc: 0.672
 epoch: 11   batch: 16   loss: 0.487     acc: 0.8413
 epoch: 11   batch: 17   loss: 0.514     acc: 0.836
 epoch: 11   batch: 18   loss: 0.5774    acc: 0.8193
 epoch: 11   batch: 19   loss: 0.6935    acc: 0.7637
 epoch: 11   batch: 20   loss: 0.5583    acc: 0.813
 means -->               loss: 0.634     acc: 0.7917]
[norms of weights -> l1: 22384.526, l2: 35.640386]
EPOCH: 12/100...
[fit info (epoch 12):
 epoch: 12   batch: 1    loss: 0.5794    acc: 0.8087
 epoch: 12   batch: 2    loss: 0.666     acc: 0.773
 epoch: 12   batch: 3    loss: 0.7247    acc: 0.7487
 epoch: 12   batch: 4    loss: 0.4595    acc: 0.865
 epoch: 12   batch: 5    loss: 0.5457    acc: 0.8037
 epoch: 12   batch: 6    loss: 0.449     acc: 0.8553
 epoch: 12   batch: 7    loss: 0.429     acc: 0.891
 epoch: 12   batch: 8    loss: 0.4757    acc: 0.8383
 epoch: 12   batch: 9    loss: 0.4984    acc: 0.8313
 epoch: 12   batch: 10   loss: 0.5231    acc: 0.8277
 epoch: 12   batch: 11   loss: 0.5596    acc: 0.825
 epoch: 12   batch: 12   loss: 0.5108    acc: 0.855
 epoch: 12   batch: 13   loss: 0.6321    acc: 0.793
 epoch: 12   batch: 14   loss: 0.4764    acc: 0.8587
 epoch: 12   batch: 15   loss: 0.5201    acc: 0.8483
 epoch: 12   batch: 16   loss: 0.5108    acc: 0.8167
 epoch: 12   batch: 17   loss: 0.3851    acc: 0.884
 epoch: 12   batch: 18   loss: 0.5154    acc: 0.8367
 epoch: 12   batch: 19   loss: 0.5018    acc: 0.8317
 epoch: 12   batch: 20   loss: 0.5302    acc: 0.836
 means -->               loss: 0.5246    acc: 0.8314]
[norms of weights -> l1: 22434.788, l2: 35.74609]
EPOCH: 13/100...
[fit info (epoch 13):
 epoch: 13   batch: 1    loss: 0.5648    acc: 0.8197
 epoch: 13   batch: 2    loss: 0.6317    acc: 0.788
 epoch: 13   batch: 3    loss: 0.5004    acc: 0.8323
 epoch: 13   batch: 4    loss: 0.459     acc: 0.8467
 epoch: 13   batch: 5    loss: 0.4951    acc: 0.8573
 epoch: 13   batch: 6    loss: 0.3991    acc: 0.8737
 epoch: 13   batch: 7    loss: 0.4162    acc: 0.8773
 epoch: 13   batch: 8    loss: 0.5532    acc: 0.8363
 epoch: 13   batch: 9    loss: 0.4799    acc: 0.8497
 epoch: 13   batch: 10   loss: 0.6068    acc: 0.8123
 epoch: 13   batch: 11   loss: 0.4969    acc: 0.8503
 epoch: 13   batch: 12   loss: 0.4519    acc: 0.869
 epoch: 13   batch: 13   loss: 0.5026    acc: 0.8563
 epoch: 13   batch: 14   loss: 0.4027    acc: 0.8807
 epoch: 13   batch: 15   loss: 0.3169    acc: 0.9053
 epoch: 13   batch: 16   loss: 0.4632    acc: 0.872
 epoch: 13   batch: 17   loss: 0.3955    acc: 0.876
 epoch: 13   batch: 18   loss: 0.4646    acc: 0.8637
 epoch: 13   batch: 19   loss: 0.3567    acc: 0.9013
 epoch: 13   batch: 20   loss: 0.6087    acc: 0.8287
 means -->               loss: 0.4783    acc: 0.8548]
[norms of weights -> l1: 22480.867, l2: 35.841454]
EPOCH: 14/100...
[fit info (epoch 14):
 epoch: 14   batch: 1    loss: 0.8699    acc: 0.7337
 epoch: 14   batch: 2    loss: 0.4727    acc: 0.869
 epoch: 14   batch: 3    loss: 0.386     acc: 0.8877
 epoch: 14   batch: 4    loss: 0.5078    acc: 0.8423
 epoch: 14   batch: 5    loss: 0.4019    acc: 0.865
 epoch: 14   batch: 6    loss: 0.3796    acc: 0.878
 epoch: 14   batch: 7    loss: 0.4683    acc: 0.8403
 epoch: 14   batch: 8    loss: 0.4307    acc: 0.8707
 epoch: 14   batch: 9    loss: 0.4215    acc: 0.874
 epoch: 14   batch: 10   loss: 0.5544    acc: 0.8087
 epoch: 14   batch: 11   loss: 0.3763    acc: 0.8813
 epoch: 14   batch: 12   loss: 0.6408    acc: 0.7887
 epoch: 14   batch: 13   loss: 0.4671    acc: 0.855
 epoch: 14   batch: 14   loss: 0.4009    acc: 0.892
 epoch: 14   batch: 15   loss: 0.6962    acc: 0.7797
 epoch: 14   batch: 16   loss: 0.3492    acc: 0.892
 epoch: 14   batch: 17   loss: 0.4116    acc: 0.8857
 epoch: 14   batch: 18   loss: 0.3703    acc: 0.8883
 epoch: 14   batch: 19   loss: 0.3727    acc: 0.906
 epoch: 14   batch: 20   loss: 0.4697    acc: 0.8533
 means -->               loss: 0.4724    acc: 0.8546]
[norms of weights -> l1: 22521.367, l2: 35.925331]
EPOCH: 15/100...
[fit info (epoch 15):
 epoch: 15   batch: 1    loss: 0.3302    acc: 0.9173
 epoch: 15   batch: 2    loss: 0.3985    acc: 0.879
 epoch: 15   batch: 3    loss: 0.3918    acc: 0.88
 epoch: 15   batch: 4    loss: 0.4642    acc: 0.853
 epoch: 15   batch: 5    loss: 0.4502    acc: 0.848
 epoch: 15   batch: 6    loss: 0.4385    acc: 0.857
 epoch: 15   batch: 7    loss: 0.4046    acc: 0.868
 epoch: 15   batch: 8    loss: 0.4071    acc: 0.8573
 epoch: 15   batch: 9    loss: 0.5386    acc: 0.8423
 epoch: 15   batch: 10   loss: 0.5341    acc: 0.8447
 epoch: 15   batch: 11   loss: 0.3855    acc: 0.8987
 epoch: 15   batch: 12   loss: 0.5245    acc: 0.833
 epoch: 15   batch: 13   loss: 0.511     acc: 0.8397
 epoch: 15   batch: 14   loss: 0.6284    acc: 0.7837
 epoch: 15   batch: 15   loss: 0.3961    acc: 0.8823
 epoch: 15   batch: 16   loss: 0.4201    acc: 0.8643
 epoch: 15   batch: 17   loss: 0.3347    acc: 0.896
 epoch: 15   batch: 18   loss: 0.3307    acc: 0.8927
 epoch: 15   batch: 19   loss: 0.3123    acc: 0.903
 epoch: 15   batch: 20   loss: 0.4117    acc: 0.8793
 means -->               loss: 0.4306    acc: 0.866]
[norms of weights -> l1: 22558.544, l2: 36.004505]
EPOCH: 16/100...
[fit info (epoch 16):
 epoch: 16   batch: 1    loss: 0.5419    acc: 0.837
 epoch: 16   batch: 2    loss: 0.3788    acc: 0.8893
 epoch: 16   batch: 3    loss: 0.4722    acc: 0.854
 epoch: 16   batch: 4    loss: 0.3656    acc: 0.8963
 epoch: 16   batch: 5    loss: 0.4057    acc: 0.8743
 epoch: 16   batch: 6    loss: 0.3956    acc: 0.8883
 epoch: 16   batch: 7    loss: 0.3944    acc: 0.8747
 epoch: 16   batch: 8    loss: 0.376     acc: 0.8977
 epoch: 16   batch: 9    loss: 0.4911    acc: 0.8477
 epoch: 16   batch: 10   loss: 0.496     acc: 0.846
 epoch: 16   batch: 11   loss: 0.3784    acc: 0.887
 epoch: 16   batch: 12   loss: 0.3962    acc: 0.86
 epoch: 16   batch: 13   loss: 0.3083    acc: 0.9
 epoch: 16   batch: 14   loss: 0.3299    acc: 0.8997
 epoch: 16   batch: 15   loss: 0.3498    acc: 0.8843
 epoch: 16   batch: 16   loss: 0.4798    acc: 0.8657
 epoch: 16   batch: 17   loss: 0.3008    acc: 0.9097
 epoch: 16   batch: 18   loss: 0.4067    acc: 0.8823
 epoch: 16   batch: 19   loss: 0.3321    acc: 0.8977
 epoch: 16   batch: 20   loss: 0.3878    acc: 0.8813
 means -->               loss: 0.3993    acc: 0.8787]
[norms of weights -> l1: 22594.486, l2: 36.082956]
EPOCH: 17/100...
[fit info (epoch 17):
 epoch: 17   batch: 1    loss: 0.3264    acc: 0.905
 epoch: 17   batch: 2    loss: 0.3658    acc: 0.895
 epoch: 17   batch: 3    loss: 0.4031    acc: 0.8833
 epoch: 17   batch: 4    loss: 0.2957    acc: 0.908
 epoch: 17   batch: 5    loss: 0.3268    acc: 0.8967
 epoch: 17   batch: 6    loss: 0.4706    acc: 0.8393
 epoch: 17   batch: 7    loss: 0.2729    acc: 0.9263
 epoch: 17   batch: 8    loss: 0.3244    acc: 0.8997
 epoch: 17   batch: 9    loss: 0.3737    acc: 0.8977
 epoch: 17   batch: 10   loss: 0.5607    acc: 0.8213
 epoch: 17   batch: 11   loss: 0.3474    acc: 0.8827
 epoch: 17   batch: 12   loss: 0.384     acc: 0.8657
 epoch: 17   batch: 13   loss: 0.3066    acc: 0.9027
 epoch: 17   batch: 14   loss: 0.3399    acc: 0.904
 epoch: 17   batch: 15   loss: 0.3095    acc: 0.9127
 epoch: 17   batch: 16   loss: 0.2985    acc: 0.9143
 epoch: 17   batch: 17   loss: 0.5057    acc: 0.861
 epoch: 17   batch: 18   loss: 0.3896    acc: 0.884
 epoch: 17   batch: 19   loss: 0.3275    acc: 0.9097
 epoch: 17   batch: 20   loss: 0.4603    acc: 0.8453
 means -->               loss: 0.3695    acc: 0.8877]
[norms of weights -> l1: 22623.548, l2: 36.144674]
EPOCH: 18/100...
[fit info (epoch 18):
 epoch: 18   batch: 1    loss: 0.4387    acc: 0.866
 epoch: 18   batch: 2    loss: 0.4845    acc: 0.8417
 epoch: 18   batch: 3    loss: 0.2941    acc: 0.9183
 epoch: 18   batch: 4    loss: 0.2801    acc: 0.9153
 epoch: 18   batch: 5    loss: 0.3226    acc: 0.9027
 epoch: 18   batch: 6    loss: 0.3816    acc: 0.868
 epoch: 18   batch: 7    loss: 0.2926    acc: 0.9063
 epoch: 18   batch: 8    loss: 0.3444    acc: 0.9027
 epoch: 18   batch: 9    loss: 0.318     acc: 0.8963
 epoch: 18   batch: 10   loss: 0.2715    acc: 0.9257
 epoch: 18   batch: 11   loss: 0.3689    acc: 0.8803
 epoch: 18   batch: 12   loss: 0.3128    acc: 0.9033
 epoch: 18   batch: 13   loss: 0.394     acc: 0.8847
 epoch: 18   batch: 14   loss: 0.2492    acc: 0.9297
 epoch: 18   batch: 15   loss: 0.2911    acc: 0.9177
 epoch: 18   batch: 16   loss: 0.3258    acc: 0.9103
 epoch: 18   batch: 17   loss: 0.267     acc: 0.9143
 epoch: 18   batch: 18   loss: 0.2989    acc: 0.9223
 epoch: 18   batch: 19   loss: 0.2918    acc: 0.914
 epoch: 18   batch: 20   loss: 0.2599    acc: 0.921
 means -->               loss: 0.3244    acc: 0.902]
[norms of weights -> l1: 22659.628, l2: 36.220322]
EPOCH: 19/100...
[fit info (epoch 19):
 epoch: 19   batch: 1    loss: 0.4147    acc: 0.8787
 epoch: 19   batch: 2    loss: 0.2971    acc: 0.9133
 epoch: 19   batch: 3    loss: 0.231     acc: 0.932
 epoch: 19   batch: 4    loss: 0.293     acc: 0.91
 epoch: 19   batch: 5    loss: 0.3987    acc: 0.8913
 epoch: 19   batch: 6    loss: 0.2855    acc: 0.9123
 epoch: 19   batch: 7    loss: 0.216     acc: 0.9337
 epoch: 19   batch: 8    loss: 0.3809    acc: 0.8783
 epoch: 19   batch: 9    loss: 0.2567    acc: 0.92
 epoch: 19   batch: 10   loss: 0.266     acc: 0.922
 epoch: 19   batch: 11   loss: 0.2314    acc: 0.9343
 epoch: 19   batch: 12   loss: 0.2602    acc: 0.9187
 epoch: 19   batch: 13   loss: 0.4352    acc: 0.8623
 epoch: 19   batch: 14   loss: 0.2365    acc: 0.9323
 epoch: 19   batch: 15   loss: 0.2547    acc: 0.92
 epoch: 19   batch: 16   loss: 0.2581    acc: 0.9257
 epoch: 19   batch: 17   loss: 0.3256    acc: 0.9127
 epoch: 19   batch: 18   loss: 0.247     acc: 0.927
 epoch: 19   batch: 19   loss: 0.4911    acc: 0.8403
 epoch: 19   batch: 20   loss: 0.3888    acc: 0.877
 means -->               loss: 0.3084    acc: 0.9071]
[norms of weights -> l1: 22692.042, l2: 36.287906]
EPOCH: 20/100...
[fit info (epoch 20):
 epoch: 20   batch: 1    loss: 0.3812    acc: 0.8997
 epoch: 20   batch: 2    loss: 0.3288    acc: 0.898
 epoch: 20   batch: 3    loss: 0.2184    acc: 0.9373
 epoch: 20   batch: 4    loss: 0.3307    acc: 0.9093
 epoch: 20   batch: 5    loss: 0.2942    acc: 0.907
 epoch: 20   batch: 6    loss: 0.2849    acc: 0.913
 epoch: 20   batch: 7    loss: 0.3286    acc: 0.8967
 epoch: 20   batch: 8    loss: 0.3714    acc: 0.8887
 epoch: 20   batch: 9    loss: 0.3187    acc: 0.899
 epoch: 20   batch: 10   loss: 0.4271    acc: 0.8723
 epoch: 20   batch: 11   loss: 0.2579    acc: 0.9173
 epoch: 20   batch: 12   loss: 0.2715    acc: 0.915
 epoch: 20   batch: 13   loss: 0.3127    acc: 0.903
 epoch: 20   batch: 14   loss: 0.2694    acc: 0.9333
 epoch: 20   batch: 15   loss: 0.3525    acc: 0.8983
 epoch: 20   batch: 16   loss: 0.2796    acc: 0.9137
 epoch: 20   batch: 17   loss: 0.2372    acc: 0.9257
 epoch: 20   batch: 18   loss: 0.2954    acc: 0.9097
 epoch: 20   batch: 19   loss: 0.2863    acc: 0.9153
 epoch: 20   batch: 20   loss: 0.3178    acc: 0.913
 means -->               loss: 0.3082    acc: 0.9083]
[norms of weights -> l1: 22726.666, l2: 36.357331]
EPOCH: 21/100...
[fit info (epoch 21):
 epoch: 21   batch: 1    loss: 0.2555    acc: 0.9227
 epoch: 21   batch: 2    loss: 0.2003    acc: 0.9433
 epoch: 21   batch: 3    loss: 0.2467    acc: 0.9273
 epoch: 21   batch: 4    loss: 0.33      acc: 0.903
 epoch: 21   batch: 5    loss: 0.2362    acc: 0.9277
 epoch: 21   batch: 6    loss: 0.2903    acc: 0.9193
 epoch: 21   batch: 7    loss: 0.2735    acc: 0.929
 epoch: 21   batch: 8    loss: 0.2993    acc: 0.9143
 epoch: 21   batch: 9    loss: 0.2121    acc: 0.933
 epoch: 21   batch: 10   loss: 0.2211    acc: 0.9343
 epoch: 21   batch: 11   loss: 0.2236    acc: 0.9333
 epoch: 21   batch: 12   loss: 0.2886    acc: 0.9177
 epoch: 21   batch: 13   loss: 0.2646    acc: 0.92
 epoch: 21   batch: 14   loss: 0.2341    acc: 0.933
 epoch: 21   batch: 15   loss: 0.2574    acc: 0.9243
 epoch: 21   batch: 16   loss: 0.3008    acc: 0.9087
 epoch: 21   batch: 17   loss: 0.2754    acc: 0.915
 epoch: 21   batch: 18   loss: 0.2857    acc: 0.9203
 epoch: 21   batch: 19   loss: 0.2787    acc: 0.9153
 epoch: 21   batch: 20   loss: 0.2975    acc: 0.906
 means -->               loss: 0.2636    acc: 0.9224]
[norms of weights -> l1: 22755.15, l2: 36.418231]
EPOCH: 22/100...
[fit info (epoch 22):
 epoch: 22   batch: 1    loss: 0.2079    acc: 0.934
 epoch: 22   batch: 2    loss: 0.3451    acc: 0.9017
 epoch: 22   batch: 3    loss: 0.3074    acc: 0.9167
 epoch: 22   batch: 4    loss: 0.2389    acc: 0.9317
 epoch: 22   batch: 5    loss: 0.2396    acc: 0.9277
 epoch: 22   batch: 6    loss: 0.2577    acc: 0.9213
 epoch: 22   batch: 7    loss: 0.2942    acc: 0.9107
 epoch: 22   batch: 8    loss: 0.2551    acc: 0.9187
 epoch: 22   batch: 9    loss: 0.2369    acc: 0.927
 epoch: 22   batch: 10   loss: 0.2311    acc: 0.929
 epoch: 22   batch: 11   loss: 0.214     acc: 0.9317
 epoch: 22   batch: 12   loss: 0.2761    acc: 0.9193
 epoch: 22   batch: 13   loss: 0.2009    acc: 0.9447
 epoch: 22   batch: 14   loss: 0.3256    acc: 0.907
 epoch: 22   batch: 15   loss: 0.3145    acc: 0.918
 epoch: 22   batch: 16   loss: 0.2419    acc: 0.9263
 epoch: 22   batch: 17   loss: 0.2051    acc: 0.933
 epoch: 22   batch: 18   loss: 0.2656    acc: 0.913
 epoch: 22   batch: 19   loss: 0.278     acc: 0.901
 epoch: 22   batch: 20   loss: 0.3498    acc: 0.889
 means -->               loss: 0.2643    acc: 0.9201]
[norms of weights -> l1: 22785.54, l2: 36.483872]
EPOCH: 23/100...
[fit info (epoch 23):
 epoch: 23   batch: 1    loss: 0.2124    acc: 0.9297
 epoch: 23   batch: 2    loss: 0.3521    acc: 0.8903
 epoch: 23   batch: 3    loss: 0.2666    acc: 0.9073
 epoch: 23   batch: 4    loss: 0.328     acc: 0.902
 epoch: 23   batch: 5    loss: 0.2542    acc: 0.9173
 epoch: 23   batch: 6    loss: 0.2741    acc: 0.925
 epoch: 23   batch: 7    loss: 0.2978    acc: 0.9133
 epoch: 23   batch: 8    loss: 0.2871    acc: 0.9227
 epoch: 23   batch: 9    loss: 0.2775    acc: 0.9137
 epoch: 23   batch: 10   loss: 0.2298    acc: 0.9357
 epoch: 23   batch: 11   loss: 0.2404    acc: 0.9267
 epoch: 23   batch: 12   loss: 0.2222    acc: 0.9393
 epoch: 23   batch: 13   loss: 0.1857    acc: 0.9393
 epoch: 23   batch: 14   loss: 0.2532    acc: 0.92
 epoch: 23   batch: 15   loss: 0.2545    acc: 0.9223
 epoch: 23   batch: 16   loss: 0.3326    acc: 0.916
 epoch: 23   batch: 17   loss: 0.2383    acc: 0.9293
 epoch: 23   batch: 18   loss: 0.2238    acc: 0.9277
 epoch: 23   batch: 19   loss: 0.2504    acc: 0.9233
 epoch: 23   batch: 20   loss: 0.2976    acc: 0.914
 means -->               loss: 0.2639    acc: 0.9207]
[norms of weights -> l1: 22824.009, l2: 36.565466]
EPOCH: 24/100...
[fit info (epoch 24):
 epoch: 24   batch: 1    loss: 0.2212    acc: 0.9323
 epoch: 24   batch: 2    loss: 0.1842    acc: 0.942
 epoch: 24   batch: 3    loss: 0.3966    acc: 0.893
 epoch: 24   batch: 4    loss: 0.235     acc: 0.9273
 epoch: 24   batch: 5    loss: 0.1983    acc: 0.9403
 epoch: 24   batch: 6    loss: 0.2756    acc: 0.9203
 epoch: 24   batch: 7    loss: 0.1844    acc: 0.9443
 epoch: 24   batch: 8    loss: 0.2633    acc: 0.9233
 epoch: 24   batch: 9    loss: 0.2506    acc: 0.9233
 epoch: 24   batch: 10   loss: 0.3692    acc: 0.8893
 epoch: 24   batch: 11   loss: 0.2994    acc: 0.9167
 epoch: 24   batch: 12   loss: 0.1782    acc: 0.9507
 epoch: 24   batch: 13   loss: 0.2239    acc: 0.9313
 epoch: 24   batch: 14   loss: 0.1823    acc: 0.9507
 epoch: 24   batch: 15   loss: 0.2322    acc: 0.9287
 epoch: 24   batch: 16   loss: 0.2253    acc: 0.934
 epoch: 24   batch: 17   loss: 0.2092    acc: 0.943
 epoch: 24   batch: 18   loss: 0.1975    acc: 0.9457
 epoch: 24   batch: 19   loss: 0.2478    acc: 0.9287
 epoch: 24   batch: 20   loss: 0.229     acc: 0.9347
 means -->               loss: 0.2402    acc: 0.93]
[norms of weights -> l1: 22853.202, l2: 36.628572]
EPOCH: 25/100...
[fit info (epoch 25):
 epoch: 25   batch: 1    loss: 0.2125    acc: 0.9373
 epoch: 25   batch: 2    loss: 0.2947    acc: 0.9137
 epoch: 25   batch: 3    loss: 0.226     acc: 0.9323
 epoch: 25   batch: 4    loss: 0.2016    acc: 0.9423
 epoch: 25   batch: 5    loss: 0.2503    acc: 0.9197
 epoch: 25   batch: 6    loss: 0.2164    acc: 0.9347
 epoch: 25   batch: 7    loss: 0.3351    acc: 0.8853
 epoch: 25   batch: 8    loss: 0.1961    acc: 0.9403
 epoch: 25   batch: 9    loss: 0.263     acc: 0.92
 epoch: 25   batch: 10   loss: 0.2394    acc: 0.922
 epoch: 25   batch: 11   loss: 0.2262    acc: 0.9373
 epoch: 25   batch: 12   loss: 0.2905    acc: 0.9183
 epoch: 25   batch: 13   loss: 0.225     acc: 0.9437
 epoch: 25   batch: 14   loss: 0.2299    acc: 0.931
 epoch: 25   batch: 15   loss: 0.293     acc: 0.91
 epoch: 25   batch: 16   loss: 0.1882    acc: 0.946
 epoch: 25   batch: 17   loss: 0.1977    acc: 0.941
 epoch: 25   batch: 18   loss: 0.227     acc: 0.9343
 epoch: 25   batch: 19   loss: 0.2296    acc: 0.9303
 epoch: 25   batch: 20   loss: 0.3032    acc: 0.917
 means -->               loss: 0.2423    acc: 0.9278]
[norms of weights -> l1: 22882.689, l2: 36.690657]
EPOCH: 26/100...
[fit info (epoch 26):
 epoch: 26   batch: 1    loss: 0.2105    acc: 0.9333
 epoch: 26   batch: 2    loss: 0.2469    acc: 0.923
 epoch: 26   batch: 3    loss: 0.2734    acc: 0.9193
 epoch: 26   batch: 4    loss: 0.358     acc: 0.8957
 epoch: 26   batch: 5    loss: 0.2461    acc: 0.9303
 epoch: 26   batch: 6    loss: 0.2504    acc: 0.9267
 epoch: 26   batch: 7    loss: 0.1823    acc: 0.9463
 epoch: 26   batch: 8    loss: 0.3526    acc: 0.8977
 epoch: 26   batch: 9    loss: 0.2214    acc: 0.9347
 epoch: 26   batch: 10   loss: 0.2118    acc: 0.941
 epoch: 26   batch: 11   loss: 0.1944    acc: 0.944
 epoch: 26   batch: 12   loss: 0.2164    acc: 0.936
 epoch: 26   batch: 13   loss: 0.2045    acc: 0.9417
 epoch: 26   batch: 14   loss: 0.2393    acc: 0.9253
 epoch: 26   batch: 15   loss: 0.2098    acc: 0.941
 epoch: 26   batch: 16   loss: 0.2207    acc: 0.9423
 epoch: 26   batch: 17   loss: 0.1823    acc: 0.9397
 epoch: 26   batch: 18   loss: 0.2929    acc: 0.9267
 epoch: 26   batch: 19   loss: 0.3037    acc: 0.916
 epoch: 26   batch: 20   loss: 0.1983    acc: 0.9393
 means -->               loss: 0.2408    acc: 0.93]
[norms of weights -> l1: 22910.491, l2: 36.748696]
EPOCH: 27/100...
[fit info (epoch 27):
 epoch: 27   batch: 1    loss: 0.1919    acc: 0.9447
 epoch: 27   batch: 2    loss: 0.3238    acc: 0.9047
 epoch: 27   batch: 3    loss: 0.1866    acc: 0.9423
 epoch: 27   batch: 4    loss: 0.1885    acc: 0.945
 epoch: 27   batch: 5    loss: 0.1758    acc: 0.9447
 epoch: 27   batch: 6    loss: 0.3099    acc: 0.9047
 epoch: 27   batch: 7    loss: 0.232     acc: 0.928
 epoch: 27   batch: 8    loss: 0.2296    acc: 0.9403
 epoch: 27   batch: 9    loss: 0.1877    acc: 0.9457
 epoch: 27   batch: 10   loss: 0.2259    acc: 0.9367
 epoch: 27   batch: 11   loss: 0.2102    acc: 0.9353
 epoch: 27   batch: 12   loss: 0.2181    acc: 0.9287
 epoch: 27   batch: 13   loss: 0.198     acc: 0.9407
 epoch: 27   batch: 14   loss: 0.2195    acc: 0.9363
 epoch: 27   batch: 15   loss: 0.1863    acc: 0.946
 epoch: 27   batch: 16   loss: 0.2803    acc: 0.9217
 epoch: 27   batch: 17   loss: 0.2293    acc: 0.9267
 epoch: 27   batch: 18   loss: 0.1763    acc: 0.944
 epoch: 27   batch: 19   loss: 0.2102    acc: 0.94
 epoch: 27   batch: 20   loss: 0.2047    acc: 0.9403
 means -->               loss: 0.2192    acc: 0.9348]
[norms of weights -> l1: 22938.081, l2: 36.808805]
EPOCH: 28/100...
[fit info (epoch 28):
 epoch: 28   batch: 1    loss: 0.2018    acc: 0.939
 epoch: 28   batch: 2    loss: 0.2105    acc: 0.9393
 epoch: 28   batch: 3    loss: 0.1871    acc: 0.9467
 epoch: 28   batch: 4    loss: 0.1679    acc: 0.9467
 epoch: 28   batch: 5    loss: 0.2014    acc: 0.94
 epoch: 28   batch: 6    loss: 0.1889    acc: 0.943
 epoch: 28   batch: 7    loss: 0.1952    acc: 0.9373
 epoch: 28   batch: 8    loss: 0.2022    acc: 0.9413
 epoch: 28   batch: 9    loss: 0.1963    acc: 0.9403
 epoch: 28   batch: 10   loss: 0.1985    acc: 0.9417
 epoch: 28   batch: 11   loss: 0.1929    acc: 0.9387
 epoch: 28   batch: 12   loss: 0.2233    acc: 0.928
 epoch: 28   batch: 13   loss: 0.1773    acc: 0.9503
 epoch: 28   batch: 14   loss: 0.1652    acc: 0.9497
 epoch: 28   batch: 15   loss: 0.2143    acc: 0.9363
 epoch: 28   batch: 16   loss: 0.1596    acc: 0.95
 epoch: 28   batch: 17   loss: 0.2712    acc: 0.9213
 epoch: 28   batch: 18   loss: 0.254     acc: 0.9273
 epoch: 28   batch: 19   loss: 0.1756    acc: 0.947
 epoch: 28   batch: 20   loss: 0.1634    acc: 0.9497
 means -->               loss: 0.1973    acc: 0.9407]
[norms of weights -> l1: 22960.598, l2: 36.858548]
EPOCH: 29/100...
[fit info (epoch 29):
 epoch: 29   batch: 1    loss: 0.22      acc: 0.9437
 epoch: 29   batch: 2    loss: 0.2094    acc: 0.939
 epoch: 29   batch: 3    loss: 0.2452    acc: 0.9313
 epoch: 29   batch: 4    loss: 0.2556    acc: 0.9303
 epoch: 29   batch: 5    loss: 0.2256    acc: 0.9393
 epoch: 29   batch: 6    loss: 0.1873    acc: 0.944
 epoch: 29   batch: 7    loss: 0.1402    acc: 0.959
 epoch: 29   batch: 8    loss: 0.1547    acc: 0.9513
 epoch: 29   batch: 9    loss: 0.1915    acc: 0.944
 epoch: 29   batch: 10   loss: 0.2482    acc: 0.919
 epoch: 29   batch: 11   loss: 0.2341    acc: 0.9343
 epoch: 29   batch: 12   loss: 0.2473    acc: 0.933
 epoch: 29   batch: 13   loss: 0.1759    acc: 0.945
 epoch: 29   batch: 14   loss: 0.2028    acc: 0.9383
 epoch: 29   batch: 15   loss: 0.1794    acc: 0.945
 epoch: 29   batch: 16   loss: 0.2179    acc: 0.9357
 epoch: 29   batch: 17   loss: 0.1333    acc: 0.9637
 epoch: 29   batch: 18   loss: 0.2304    acc: 0.9317
 epoch: 29   batch: 19   loss: 0.2058    acc: 0.9387
 epoch: 29   batch: 20   loss: 0.1657    acc: 0.9477
 means -->               loss: 0.2035    acc: 0.9407]
[norms of weights -> l1: 22989.822, l2: 36.919967]
EPOCH: 30/100...
[fit info (epoch 30):
 epoch: 30   batch: 1    loss: 0.1287    acc: 0.9567
 epoch: 30   batch: 2    loss: 0.1745    acc: 0.954
 epoch: 30   batch: 3    loss: 0.2915    acc: 0.927
 epoch: 30   batch: 4    loss: 0.1456    acc: 0.9527
 epoch: 30   batch: 5    loss: 0.1956    acc: 0.943
 epoch: 30   batch: 6    loss: 0.194     acc: 0.9473
 epoch: 30   batch: 7    loss: 0.2024    acc: 0.941
 epoch: 30   batch: 8    loss: 0.1842    acc: 0.9453
 epoch: 30   batch: 9    loss: 0.1517    acc: 0.9523
 epoch: 30   batch: 10   loss: 0.2046    acc: 0.937
 epoch: 30   batch: 11   loss: 0.1692    acc: 0.9523
 epoch: 30   batch: 12   loss: 0.1493    acc: 0.958
 epoch: 30   batch: 13   loss: 0.1915    acc: 0.9433
 epoch: 30   batch: 14   loss: 0.186     acc: 0.941
 epoch: 30   batch: 15   loss: 0.2023    acc: 0.9373
 epoch: 30   batch: 16   loss: 0.154     acc: 0.9483
 epoch: 30   batch: 17   loss: 0.2184    acc: 0.933
 epoch: 30   batch: 18   loss: 0.177     acc: 0.9433
 epoch: 30   batch: 19   loss: 0.1664    acc: 0.9503
 epoch: 30   batch: 20   loss: 0.189     acc: 0.9443
 means -->               loss: 0.1838    acc: 0.9454]
[norms of weights -> l1: 23014.723, l2: 36.972742]
EPOCH: 31/100...
[fit info (epoch 31):
 epoch: 31   batch: 1    loss: 0.2345    acc: 0.9313
 epoch: 31   batch: 2    loss: 0.1869    acc: 0.9467
 epoch: 31   batch: 3    loss: 0.1407    acc: 0.9593
 epoch: 31   batch: 4    loss: 0.177     acc: 0.9497
 epoch: 31   batch: 5    loss: 0.1767    acc: 0.9483
 epoch: 31   batch: 6    loss: 0.1835    acc: 0.9457
 epoch: 31   batch: 7    loss: 0.1559    acc: 0.9477
 epoch: 31   batch: 8    loss: 0.1647    acc: 0.948
 epoch: 31   batch: 9    loss: 0.2372    acc: 0.9263
 epoch: 31   batch: 10   loss: 0.1306    acc: 0.9627
 epoch: 31   batch: 11   loss: 0.1849    acc: 0.9467
 epoch: 31   batch: 12   loss: 0.1761    acc: 0.9463
 epoch: 31   batch: 13   loss: 0.1825    acc: 0.9423
 epoch: 31   batch: 14   loss: 0.1488    acc: 0.9563
 epoch: 31   batch: 15   loss: 0.1839    acc: 0.9483
 epoch: 31   batch: 16   loss: 0.1605    acc: 0.9493
 epoch: 31   batch: 17   loss: 0.2125    acc: 0.9387
 epoch: 31   batch: 18   loss: 0.187     acc: 0.944
 epoch: 31   batch: 19   loss: 0.1593    acc: 0.9557
 epoch: 31   batch: 20   loss: 0.1666    acc: 0.956
 means -->               loss: 0.1775    acc: 0.9475]
[norms of weights -> l1: 23036.214, l2: 37.018215]
EPOCH: 32/100...
[fit info (epoch 32):
 epoch: 32   batch: 1    loss: 0.183     acc: 0.9443
 epoch: 32   batch: 2    loss: 0.1401    acc: 0.956
 epoch: 32   batch: 3    loss: 0.1667    acc: 0.9503
 epoch: 32   batch: 4    loss: 0.1645    acc: 0.955
 epoch: 32   batch: 5    loss: 0.1838    acc: 0.9443
 epoch: 32   batch: 6    loss: 0.2246    acc: 0.9327
 epoch: 32   batch: 7    loss: 0.1586    acc: 0.9493
 epoch: 32   batch: 8    loss: 0.1885    acc: 0.9503
 epoch: 32   batch: 9    loss: 0.1939    acc: 0.9393
 epoch: 32   batch: 10   loss: 0.1796    acc: 0.945
 epoch: 32   batch: 11   loss: 0.173     acc: 0.9413
 epoch: 32   batch: 12   loss: 0.1946    acc: 0.9443
 epoch: 32   batch: 13   loss: 0.1521    acc: 0.9583
 epoch: 32   batch: 14   loss: 0.1571    acc: 0.955
 epoch: 32   batch: 15   loss: 0.2067    acc: 0.9363
 epoch: 32   batch: 16   loss: 0.1867    acc: 0.947
 epoch: 32   batch: 17   loss: 0.2205    acc: 0.9373
 epoch: 32   batch: 18   loss: 0.1865    acc: 0.9503
 epoch: 32   batch: 19   loss: 0.1499    acc: 0.956
 epoch: 32   batch: 20   loss: 0.1539    acc: 0.9563
 means -->               loss: 0.1782    acc: 0.9475]
[norms of weights -> l1: 23058.912, l2: 37.068805]
EPOCH: 33/100...
[fit info (epoch 33):
 epoch: 33   batch: 1    loss: 0.181     acc: 0.9397
 epoch: 33   batch: 2    loss: 0.1587    acc: 0.951
 epoch: 33   batch: 3    loss: 0.1526    acc: 0.9567
 epoch: 33   batch: 4    loss: 0.1738    acc: 0.9533
 epoch: 33   batch: 5    loss: 0.1413    acc: 0.9587
 epoch: 33   batch: 6    loss: 0.1479    acc: 0.9543
 epoch: 33   batch: 7    loss: 0.1837    acc: 0.946
 epoch: 33   batch: 8    loss: 0.1409    acc: 0.9563
 epoch: 33   batch: 9    loss: 0.1671    acc: 0.949
 epoch: 33   batch: 10   loss: 0.1882    acc: 0.948
 epoch: 33   batch: 11   loss: 0.1936    acc: 0.9417
 epoch: 33   batch: 12   loss: 0.1374    acc: 0.9583
 epoch: 33   batch: 13   loss: 0.1984    acc: 0.9417
 epoch: 33   batch: 14   loss: 0.178     acc: 0.946
 epoch: 33   batch: 15   loss: 0.1782    acc: 0.944
 epoch: 33   batch: 16   loss: 0.1676    acc: 0.9493
 epoch: 33   batch: 17   loss: 0.1466    acc: 0.9557
 epoch: 33   batch: 18   loss: 0.178     acc: 0.9467
 epoch: 33   batch: 19   loss: 0.1671    acc: 0.9487
 epoch: 33   batch: 20   loss: 0.1926    acc: 0.947
 means -->               loss: 0.1686    acc: 0.9496]
[norms of weights -> l1: 23081.762, l2: 37.117376]
EPOCH: 34/100...
[fit info (epoch 34):
 epoch: 34   batch: 1    loss: 0.1989    acc: 0.948
 epoch: 34   batch: 2    loss: 0.1798    acc: 0.9463
 epoch: 34   batch: 3    loss: 0.185     acc: 0.9437
 epoch: 34   batch: 4    loss: 0.1837    acc: 0.952
 epoch: 34   batch: 5    loss: 0.1736    acc: 0.952
 epoch: 34   batch: 6    loss: 0.18      acc: 0.9447
 epoch: 34   batch: 7    loss: 0.1555    acc: 0.9513
 epoch: 34   batch: 8    loss: 0.1737    acc: 0.9497
 epoch: 34   batch: 9    loss: 0.1383    acc: 0.9583
 epoch: 34   batch: 10   loss: 0.2712    acc: 0.921
 epoch: 34   batch: 11   loss: 0.1937    acc: 0.9383
 epoch: 34   batch: 12   loss: 0.1714    acc: 0.9483
 epoch: 34   batch: 13   loss: 0.1463    acc: 0.956
 epoch: 34   batch: 14   loss: 0.148     acc: 0.9543
 epoch: 34   batch: 15   loss: 0.2025    acc: 0.9407
 epoch: 34   batch: 16   loss: 0.1215    acc: 0.965
 epoch: 34   batch: 17   loss: 0.1655    acc: 0.9557
 epoch: 34   batch: 18   loss: 0.134     acc: 0.9563
 epoch: 34   batch: 19   loss: 0.152     acc: 0.9527
 epoch: 34   batch: 20   loss: 0.1854    acc: 0.9443
 means -->               loss: 0.173     acc: 0.9489]
[norms of weights -> l1: 23103.998, l2: 37.167279]
EPOCH: 35/100...
[fit info (epoch 35):
 epoch: 35   batch: 1    loss: 0.2639    acc: 0.9253
 epoch: 35   batch: 2    loss: 0.1165    acc: 0.966
 epoch: 35   batch: 3    loss: 0.1605    acc: 0.954
 epoch: 35   batch: 4    loss: 0.1143    acc: 0.963
 epoch: 35   batch: 5    loss: 0.1495    acc: 0.9557
 epoch: 35   batch: 6    loss: 0.1508    acc: 0.9583
 epoch: 35   batch: 7    loss: 0.2008    acc: 0.9363
 epoch: 35   batch: 8    loss: 0.1288    acc: 0.957
 epoch: 35   batch: 9    loss: 0.1429    acc: 0.9523
 epoch: 35   batch: 10   loss: 0.1745    acc: 0.9517
 epoch: 35   batch: 11   loss: 0.2271    acc: 0.9383
 epoch: 35   batch: 12   loss: 0.1407    acc: 0.955
 epoch: 35   batch: 13   loss: 0.1674    acc: 0.9477
 epoch: 35   batch: 14   loss: 0.1295    acc: 0.9627
 epoch: 35   batch: 15   loss: 0.1511    acc: 0.95
 epoch: 35   batch: 16   loss: 0.1766    acc: 0.9443
 epoch: 35   batch: 17   loss: 0.1758    acc: 0.9497
 epoch: 35   batch: 18   loss: 0.1411    acc: 0.959
 epoch: 35   batch: 19   loss: 0.1499    acc: 0.951
 epoch: 35   batch: 20   loss: 0.1375    acc: 0.956
 means -->               loss: 0.16      acc: 0.9517]
[norms of weights -> l1: 23127.314, l2: 37.21754]
EPOCH: 36/100...
[fit info (epoch 36):
 epoch: 36   batch: 1    loss: 0.1372    acc: 0.9587
 epoch: 36   batch: 2    loss: 0.1373    acc: 0.9607
 epoch: 36   batch: 3    loss: 0.1706    acc: 0.948
 epoch: 36   batch: 4    loss: 0.1241    acc: 0.9603
 epoch: 36   batch: 5    loss: 0.1829    acc: 0.9477
 epoch: 36   batch: 6    loss: 0.1223    acc: 0.9633
 epoch: 36   batch: 7    loss: 0.1192    acc: 0.9653
 epoch: 36   batch: 8    loss: 0.1883    acc: 0.9397
 epoch: 36   batch: 9    loss: 0.1552    acc: 0.9527
 epoch: 36   batch: 10   loss: 0.2502    acc: 0.9347
 epoch: 36   batch: 11   loss: 0.1354    acc: 0.9627
 epoch: 36   batch: 12   loss: 0.1613    acc: 0.9503
 epoch: 36   batch: 13   loss: 0.1443    acc: 0.953
 epoch: 36   batch: 14   loss: 0.1599    acc: 0.9497
 epoch: 36   batch: 15   loss: 0.1404    acc: 0.957
 epoch: 36   batch: 16   loss: 0.135     acc: 0.9577
 epoch: 36   batch: 17   loss: 0.1497    acc: 0.9593
 epoch: 36   batch: 18   loss: 0.1595    acc: 0.9513
 epoch: 36   batch: 19   loss: 0.1946    acc: 0.946
 epoch: 36   batch: 20   loss: 0.1532    acc: 0.9573
 means -->               loss: 0.156     acc: 0.9538]
[norms of weights -> l1: 23149.779, l2: 37.265187]
EPOCH: 37/100...
[fit info (epoch 37):
 epoch: 37   batch: 1    loss: 0.2143    acc: 0.9427
 epoch: 37   batch: 2    loss: 0.1356    acc: 0.9563
 epoch: 37   batch: 3    loss: 0.1128    acc: 0.9637
 epoch: 37   batch: 4    loss: 0.1447    acc: 0.9563
 epoch: 37   batch: 5    loss: 0.1888    acc: 0.9423
 epoch: 37   batch: 6    loss: 0.1498    acc: 0.954
 epoch: 37   batch: 7    loss: 0.1521    acc: 0.9537
 epoch: 37   batch: 8    loss: 0.1248    acc: 0.9637
 epoch: 37   batch: 9    loss: 0.149     acc: 0.962
 epoch: 37   batch: 10   loss: 0.09886   acc: 0.972
 epoch: 37   batch: 11   loss: 0.1508    acc: 0.952
 epoch: 37   batch: 12   loss: 0.1271    acc: 0.9657
 epoch: 37   batch: 13   loss: 0.1626    acc: 0.953
 epoch: 37   batch: 14   loss: 0.1776    acc: 0.948
 epoch: 37   batch: 15   loss: 0.1812    acc: 0.9457
 epoch: 37   batch: 16   loss: 0.2266    acc: 0.9373
 epoch: 37   batch: 17   loss: 0.1543    acc: 0.9513
 epoch: 37   batch: 18   loss: 0.1445    acc: 0.9573
 epoch: 37   batch: 19   loss: 0.1118    acc: 0.9697
 epoch: 37   batch: 20   loss: 0.1263    acc: 0.9583
 means -->               loss: 0.1517    acc: 0.9553]
[norms of weights -> l1: 23167.982, l2: 37.305453]
EPOCH: 38/100...
[fit info (epoch 38):
 epoch: 38   batch: 1    loss: 0.1296    acc: 0.962
 epoch: 38   batch: 2    loss: 0.1477    acc: 0.9553
 epoch: 38   batch: 3    loss: 0.1407    acc: 0.9587
 epoch: 38   batch: 4    loss: 0.1715    acc: 0.946
 epoch: 38   batch: 5    loss: 0.1544    acc: 0.9507
 epoch: 38   batch: 6    loss: 0.1819    acc: 0.9477
 epoch: 38   batch: 7    loss: 0.1218    acc: 0.9643
 epoch: 38   batch: 8    loss: 0.1522    acc: 0.954
 epoch: 38   batch: 9    loss: 0.1301    acc: 0.9617
 epoch: 38   batch: 10   loss: 0.1399    acc: 0.9577
 epoch: 38   batch: 11   loss: 0.1634    acc: 0.9473
 epoch: 38   batch: 12   loss: 0.171     acc: 0.9483
 epoch: 38   batch: 13   loss: 0.2295    acc: 0.9353
 epoch: 38   batch: 14   loss: 0.1202    acc: 0.961
 epoch: 38   batch: 15   loss: 0.2094    acc: 0.9327
 epoch: 38   batch: 16   loss: 0.1096    acc: 0.9637
 epoch: 38   batch: 17   loss: 0.1462    acc: 0.9537
 epoch: 38   batch: 18   loss: 0.1329    acc: 0.959
 epoch: 38   batch: 19   loss: 0.1238    acc: 0.965
 epoch: 38   batch: 20   loss: 0.1357    acc: 0.9567
 means -->               loss: 0.1506    acc: 0.954]
[norms of weights -> l1: 23188.151, l2: 37.350505]
EPOCH: 39/100...
[fit info (epoch 39):
 epoch: 39   batch: 1    loss: 0.138     acc: 0.9577
 epoch: 39   batch: 2    loss: 0.1268    acc: 0.9637
 epoch: 39   batch: 3    loss: 0.1211    acc: 0.9633
 epoch: 39   batch: 4    loss: 0.1225    acc: 0.965
 epoch: 39   batch: 5    loss: 0.1812    acc: 0.9463
 epoch: 39   batch: 6    loss: 0.1321    acc: 0.9613
 epoch: 39   batch: 7    loss: 0.1356    acc: 0.9617
 epoch: 39   batch: 8    loss: 0.1484    acc: 0.9567
 epoch: 39   batch: 9    loss: 0.1274    acc: 0.964
 epoch: 39   batch: 10   loss: 0.1447    acc: 0.9597
 epoch: 39   batch: 11   loss: 0.1325    acc: 0.9613
 epoch: 39   batch: 12   loss: 0.129     acc: 0.959
 epoch: 39   batch: 13   loss: 0.1154    acc: 0.964
 epoch: 39   batch: 14   loss: 0.1388    acc: 0.9577
 epoch: 39   batch: 15   loss: 0.1424    acc: 0.9627
 epoch: 39   batch: 16   loss: 0.1245    acc: 0.9587
 epoch: 39   batch: 17   loss: 0.1695    acc: 0.9457
 epoch: 39   batch: 18   loss: 0.09248   acc: 0.9717
 epoch: 39   batch: 19   loss: 0.1435    acc: 0.9557
 epoch: 39   batch: 20   loss: 0.1596    acc: 0.9483
 means -->               loss: 0.1363    acc: 0.9592]
[norms of weights -> l1: 23208.143, l2: 37.395598]
EPOCH: 40/100...
[fit info (epoch 40):
 epoch: 40   batch: 1    loss: 0.1601    acc: 0.9497
 epoch: 40   batch: 2    loss: 0.1256    acc: 0.9637
 epoch: 40   batch: 3    loss: 0.1386    acc: 0.963
 epoch: 40   batch: 4    loss: 0.1049    acc: 0.968
 epoch: 40   batch: 5    loss: 0.1247    acc: 0.9627
 epoch: 40   batch: 6    loss: 0.1389    acc: 0.953
 epoch: 40   batch: 7    loss: 0.161     acc: 0.9533
 epoch: 40   batch: 8    loss: 0.1855    acc: 0.942
 epoch: 40   batch: 9    loss: 0.1326    acc: 0.9597
 epoch: 40   batch: 10   loss: 0.1415    acc: 0.9577
 epoch: 40   batch: 11   loss: 0.1141    acc: 0.9647
 epoch: 40   batch: 12   loss: 0.2035    acc: 0.9403
 epoch: 40   batch: 13   loss: 0.09978   acc: 0.9683
 epoch: 40   batch: 14   loss: 0.107     acc: 0.964
 epoch: 40   batch: 15   loss: 0.169     acc: 0.9513
 epoch: 40   batch: 16   loss: 0.0916    acc: 0.9683
 epoch: 40   batch: 17   loss: 0.1192    acc: 0.9607
 epoch: 40   batch: 18   loss: 0.1722    acc: 0.952
 epoch: 40   batch: 19   loss: 0.121     acc: 0.9627
 epoch: 40   batch: 20   loss: 0.1159    acc: 0.9657
 means -->               loss: 0.1363    acc: 0.9585]
[norms of weights -> l1: 23228.634, l2: 37.440035]
EPOCH: 41/100...
[fit info (epoch 41):
 epoch: 41   batch: 1    loss: 0.1499    acc: 0.953
 epoch: 41   batch: 2    loss: 0.1039    acc: 0.9707
 epoch: 41   batch: 3    loss: 0.2165    acc: 0.937
 epoch: 41   batch: 4    loss: 0.1332    acc: 0.9593
 epoch: 41   batch: 5    loss: 0.1121    acc: 0.9653
 epoch: 41   batch: 6    loss: 0.1189    acc: 0.962
 epoch: 41   batch: 7    loss: 0.122     acc: 0.9587
 epoch: 41   batch: 8    loss: 0.1438    acc: 0.954
 epoch: 41   batch: 9    loss: 0.1889    acc: 0.949
 epoch: 41   batch: 10   loss: 0.1098    acc: 0.9687
 epoch: 41   batch: 11   loss: 0.2206    acc: 0.9277
 epoch: 41   batch: 12   loss: 0.1144    acc: 0.963
 epoch: 41   batch: 13   loss: 0.1334    acc: 0.9623
 epoch: 41   batch: 14   loss: 0.1435    acc: 0.961
 epoch: 41   batch: 15   loss: 0.1403    acc: 0.9623
 epoch: 41   batch: 16   loss: 0.135     acc: 0.9543
 epoch: 41   batch: 17   loss: 0.2168    acc: 0.939
 epoch: 41   batch: 18   loss: 0.1591    acc: 0.954
 epoch: 41   batch: 19   loss: 0.1602    acc: 0.95
 epoch: 41   batch: 20   loss: 0.1476    acc: 0.9613
 means -->               loss: 0.1485    acc: 0.9556]
[norms of weights -> l1: 23249.761, l2: 37.485048]
EPOCH: 42/100...
[fit info (epoch 42):
 epoch: 42   batch: 1    loss: 0.1141    acc: 0.9677
 epoch: 42   batch: 2    loss: 0.1947    acc: 0.9343
 epoch: 42   batch: 3    loss: 0.1358    acc: 0.962
 epoch: 42   batch: 4    loss: 0.1926    acc: 0.9433
 epoch: 42   batch: 5    loss: 0.1548    acc: 0.958
 epoch: 42   batch: 6    loss: 0.1402    acc: 0.9597
 epoch: 42   batch: 7    loss: 0.1158    acc: 0.9673
 epoch: 42   batch: 8    loss: 0.1344    acc: 0.9627
 epoch: 42   batch: 9    loss: 0.1441    acc: 0.9523
 epoch: 42   batch: 10   loss: 0.1412    acc: 0.9573
 epoch: 42   batch: 11   loss: 0.1164    acc: 0.966
 epoch: 42   batch: 12   loss: 0.1116    acc: 0.9667
 epoch: 42   batch: 13   loss: 0.127     acc: 0.9613
 epoch: 42   batch: 14   loss: 0.1419    acc: 0.9557
 epoch: 42   batch: 15   loss: 0.1088    acc: 0.972
 epoch: 42   batch: 16   loss: 0.1757    acc: 0.948
 epoch: 42   batch: 17   loss: 0.1734    acc: 0.9557
 epoch: 42   batch: 18   loss: 0.1671    acc: 0.9497
 epoch: 42   batch: 19   loss: 0.1229    acc: 0.9663
 epoch: 42   batch: 20   loss: 0.1269    acc: 0.9613
 means -->               loss: 0.142     acc: 0.9584]
[norms of weights -> l1: 23274.418, l2: 37.539345]
EPOCH: 43/100...
[fit info (epoch 43):
 epoch: 43   batch: 1    loss: 0.1107    acc: 0.965
 epoch: 43   batch: 2    loss: 0.1618    acc: 0.9573
 epoch: 43   batch: 3    loss: 0.1277    acc: 0.9573
 epoch: 43   batch: 4    loss: 0.1641    acc: 0.9457
 epoch: 43   batch: 5    loss: 0.1524    acc: 0.951
 epoch: 43   batch: 6    loss: 0.1477    acc: 0.9553
 epoch: 43   batch: 7    loss: 0.1515    acc: 0.954
 epoch: 43   batch: 8    loss: 0.1541    acc: 0.954
 epoch: 43   batch: 9    loss: 0.1268    acc: 0.965
 epoch: 43   batch: 10   loss: 0.1577    acc: 0.9587
 epoch: 43   batch: 11   loss: 0.2018    acc: 0.9407
 epoch: 43   batch: 12   loss: 0.1427    acc: 0.96
 epoch: 43   batch: 13   loss: 0.1711    acc: 0.951
 epoch: 43   batch: 14   loss: 0.2049    acc: 0.9403
 epoch: 43   batch: 15   loss: 0.1609    acc: 0.951
 epoch: 43   batch: 16   loss: 0.2185    acc: 0.942
 epoch: 43   batch: 17   loss: 0.1369    acc: 0.962
 epoch: 43   batch: 18   loss: 0.1216    acc: 0.963
 epoch: 43   batch: 19   loss: 0.1325    acc: 0.9553
 epoch: 43   batch: 20   loss: 0.1168    acc: 0.963
 means -->               loss: 0.1531    acc: 0.9546]
[norms of weights -> l1: 23296.737, l2: 37.589311]
EPOCH: 44/100...
[fit info (epoch 44):
 epoch: 44   batch: 1    loss: 0.1409    acc: 0.9563
 epoch: 44   batch: 2    loss: 0.1182    acc: 0.9613
 epoch: 44   batch: 3    loss: 0.1387    acc: 0.9593
 epoch: 44   batch: 4    loss: 0.162     acc: 0.951
 epoch: 44   batch: 5    loss: 0.09654   acc: 0.9693
 epoch: 44   batch: 6    loss: 0.1465    acc: 0.9583
 epoch: 44   batch: 7    loss: 0.1713    acc: 0.9513
 epoch: 44   batch: 8    loss: 0.1388    acc: 0.9623
 epoch: 44   batch: 9    loss: 0.1564    acc: 0.9597
 epoch: 44   batch: 10   loss: 0.1543    acc: 0.9563
 epoch: 44   batch: 11   loss: 0.1237    acc: 0.9643
 epoch: 44   batch: 12   loss: 0.1379    acc: 0.9583
 epoch: 44   batch: 13   loss: 0.09492   acc: 0.9723
 epoch: 44   batch: 14   loss: 0.1593    acc: 0.958
 epoch: 44   batch: 15   loss: 0.1015    acc: 0.9703
 epoch: 44   batch: 16   loss: 0.1269    acc: 0.964
 epoch: 44   batch: 17   loss: 0.2145    acc: 0.952
 epoch: 44   batch: 18   loss: 0.1446    acc: 0.954
 epoch: 44   batch: 19   loss: 0.1268    acc: 0.9633
 epoch: 44   batch: 20   loss: 0.1093    acc: 0.966
 means -->               loss: 0.1382    acc: 0.9604]
[norms of weights -> l1: 23324.135, l2: 37.647445]
EPOCH: 45/100...
[fit info (epoch 45):
 epoch: 45   batch: 1    loss: 0.1522    acc: 0.9577
 epoch: 45   batch: 2    loss: 0.135     acc: 0.957
 epoch: 45   batch: 3    loss: 0.09929   acc: 0.968
 epoch: 45   batch: 4    loss: 0.08441   acc: 0.9753
 epoch: 45   batch: 5    loss: 0.1744    acc: 0.9553
 epoch: 45   batch: 6    loss: 0.1449    acc: 0.958
 epoch: 45   batch: 7    loss: 0.1211    acc: 0.9613
 epoch: 45   batch: 8    loss: 0.125     acc: 0.961
 epoch: 45   batch: 9    loss: 0.186     acc: 0.942
 epoch: 45   batch: 10   loss: 0.1623    acc: 0.951
 epoch: 45   batch: 11   loss: 0.2151    acc: 0.9443
 epoch: 45   batch: 12   loss: 0.1308    acc: 0.959
 epoch: 45   batch: 13   loss: 0.177     acc: 0.9527
 epoch: 45   batch: 14   loss: 0.1408    acc: 0.9587
 epoch: 45   batch: 15   loss: 0.2225    acc: 0.9397
 epoch: 45   batch: 16   loss: 0.1276    acc: 0.9613
 epoch: 45   batch: 17   loss: 0.1972    acc: 0.9427
 epoch: 45   batch: 18   loss: 0.1055    acc: 0.9633
 epoch: 45   batch: 19   loss: 0.1047    acc: 0.9667
 epoch: 45   batch: 20   loss: 0.1092    acc: 0.9703
 means -->               loss: 0.1458    acc: 0.9573]
[norms of weights -> l1: 23351.48, l2: 37.704124]
EPOCH: 46/100...
[fit info (epoch 46):
 epoch: 46   batch: 1    loss: 0.13      acc: 0.9603
 epoch: 46   batch: 2    loss: 0.1172    acc: 0.9603
 epoch: 46   batch: 3    loss: 0.1767    acc: 0.9387
 epoch: 46   batch: 4    loss: 0.1698    acc: 0.9437
 epoch: 46   batch: 5    loss: 0.1516    acc: 0.9557
 epoch: 46   batch: 6    loss: 0.1402    acc: 0.9593
 epoch: 46   batch: 7    loss: 0.1267    acc: 0.9637
 epoch: 46   batch: 8    loss: 0.1337    acc: 0.9607
 epoch: 46   batch: 9    loss: 0.1319    acc: 0.9623
 epoch: 46   batch: 10   loss: 0.1067    acc: 0.965
 epoch: 46   batch: 11   loss: 0.1338    acc: 0.961
 epoch: 46   batch: 12   loss: 0.1428    acc: 0.9603
 epoch: 46   batch: 13   loss: 0.09158   acc: 0.9717
 epoch: 46   batch: 14   loss: 0.128     acc: 0.959
 epoch: 46   batch: 15   loss: 0.09066   acc: 0.9727
 epoch: 46   batch: 16   loss: 0.1198    acc: 0.967
 epoch: 46   batch: 17   loss: 0.08469   acc: 0.9707
 epoch: 46   batch: 18   loss: 0.1264    acc: 0.9627
 epoch: 46   batch: 19   loss: 0.1322    acc: 0.964
 epoch: 46   batch: 20   loss: 0.124     acc: 0.9607
 means -->               loss: 0.1279    acc: 0.961]
[norms of weights -> l1: 23378.042, l2: 37.762248]
EPOCH: 47/100...
[fit info (epoch 47):
 epoch: 47   batch: 1    loss: 0.111     acc: 0.9633
 epoch: 47   batch: 2    loss: 0.1164    acc: 0.966
 epoch: 47   batch: 3    loss: 0.1137    acc: 0.9653
 epoch: 47   batch: 4    loss: 0.1122    acc: 0.9673
 epoch: 47   batch: 5    loss: 0.111     acc: 0.964
 epoch: 47   batch: 6    loss: 0.1127    acc: 0.9677
 epoch: 47   batch: 7    loss: 0.1347    acc: 0.9617
 epoch: 47   batch: 8    loss: 0.1118    acc: 0.967
 epoch: 47   batch: 9    loss: 0.1079    acc: 0.969
 epoch: 47   batch: 10   loss: 0.1084    acc: 0.9657
 epoch: 47   batch: 11   loss: 0.1132    acc: 0.9677
 epoch: 47   batch: 12   loss: 0.1055    acc: 0.9687
 epoch: 47   batch: 13   loss: 0.1666    acc: 0.9567
 epoch: 47   batch: 14   loss: 0.1208    acc: 0.968
 epoch: 47   batch: 15   loss: 0.1201    acc: 0.968
 epoch: 47   batch: 16   loss: 0.1256    acc: 0.9633
 epoch: 47   batch: 17   loss: 0.08131   acc: 0.9757
 epoch: 47   batch: 18   loss: 0.1719    acc: 0.9443
 epoch: 47   batch: 19   loss: 0.08189   acc: 0.973
 epoch: 47   batch: 20   loss: 0.1291    acc: 0.964
 means -->               loss: 0.1178    acc: 0.9653]
[norms of weights -> l1: 23397.101, l2: 37.805059]
EPOCH: 48/100...
[fit info (epoch 48):
 epoch: 48   batch: 1    loss: 0.1232    acc: 0.963
 epoch: 48   batch: 2    loss: 0.1052    acc: 0.9667
 epoch: 48   batch: 3    loss: 0.1026    acc: 0.9733
 epoch: 48   batch: 4    loss: 0.148     acc: 0.9587
 epoch: 48   batch: 5    loss: 0.1326    acc: 0.9657
 epoch: 48   batch: 6    loss: 0.09252   acc: 0.9683
 epoch: 48   batch: 7    loss: 0.09485   acc: 0.97
 epoch: 48   batch: 8    loss: 0.09517   acc: 0.9737
 epoch: 48   batch: 9    loss: 0.1347    acc: 0.956
 epoch: 48   batch: 10   loss: 0.1316    acc: 0.9573
 epoch: 48   batch: 11   loss: 0.126     acc: 0.963
 epoch: 48   batch: 12   loss: 0.1051    acc: 0.968
 epoch: 48   batch: 13   loss: 0.101     acc: 0.9707
 epoch: 48   batch: 14   loss: 0.115     acc: 0.9673
 epoch: 48   batch: 15   loss: 0.1239    acc: 0.9673
 epoch: 48   batch: 16   loss: 0.1129    acc: 0.9673
 epoch: 48   batch: 17   loss: 0.1138    acc: 0.9677
 epoch: 48   batch: 18   loss: 0.08993   acc: 0.9707
 epoch: 48   batch: 19   loss: 0.1085    acc: 0.969
 epoch: 48   batch: 20   loss: 0.1117    acc: 0.9657
 means -->               loss: 0.1134    acc: 0.9665]
[norms of weights -> l1: 23416.549, l2: 37.849382]
EPOCH: 49/100...
[fit info (epoch 49):
 epoch: 49   batch: 1    loss: 0.1112    acc: 0.9663
 epoch: 49   batch: 2    loss: 0.1377    acc: 0.957
 epoch: 49   batch: 3    loss: 0.1098    acc: 0.9657
 epoch: 49   batch: 4    loss: 0.09858   acc: 0.972
 epoch: 49   batch: 5    loss: 0.1465    acc: 0.957
 epoch: 49   batch: 6    loss: 0.1128    acc: 0.9657
 epoch: 49   batch: 7    loss: 0.167     acc: 0.9563
 epoch: 49   batch: 8    loss: 0.07578   acc: 0.9773
 epoch: 49   batch: 9    loss: 0.1233    acc: 0.9657
 epoch: 49   batch: 10   loss: 0.1133    acc: 0.9673
 epoch: 49   batch: 11   loss: 0.1085    acc: 0.969
 epoch: 49   batch: 12   loss: 0.1005    acc: 0.9693
 epoch: 49   batch: 13   loss: 0.1134    acc: 0.9657
 epoch: 49   batch: 14   loss: 0.147     acc: 0.953
 epoch: 49   batch: 15   loss: 0.1234    acc: 0.9637
 epoch: 49   batch: 16   loss: 0.1258    acc: 0.9617
 epoch: 49   batch: 17   loss: 0.1265    acc: 0.9637
 epoch: 49   batch: 18   loss: 0.1184    acc: 0.9663
 epoch: 49   batch: 19   loss: 0.09758   acc: 0.9677
 epoch: 49   batch: 20   loss: 0.09477   acc: 0.9693
 means -->               loss: 0.1176    acc: 0.965]
[norms of weights -> l1: 23436.055, l2: 37.895234]
EPOCH: 50/100...
[fit info (epoch 50):
 epoch: 50   batch: 1    loss: 0.1237    acc: 0.963
 epoch: 50   batch: 2    loss: 0.1246    acc: 0.9633
 epoch: 50   batch: 3    loss: 0.1094    acc: 0.967
 epoch: 50   batch: 4    loss: 0.09063   acc: 0.971
 epoch: 50   batch: 5    loss: 0.09698   acc: 0.971
 epoch: 50   batch: 6    loss: 0.09065   acc: 0.9733
 epoch: 50   batch: 7    loss: 0.1243    acc: 0.9607
 epoch: 50   batch: 8    loss: 0.1254    acc: 0.961
 epoch: 50   batch: 9    loss: 0.1329    acc: 0.96
 epoch: 50   batch: 10   loss: 0.122     acc: 0.9653
 epoch: 50   batch: 11   loss: 0.1318    acc: 0.963
 epoch: 50   batch: 12   loss: 0.1337    acc: 0.9607
 epoch: 50   batch: 13   loss: 0.1145    acc: 0.966
 epoch: 50   batch: 14   loss: 0.122     acc: 0.97
 epoch: 50   batch: 15   loss: 0.1048    acc: 0.9693
 epoch: 50   batch: 16   loss: 0.08557   acc: 0.9723
 epoch: 50   batch: 17   loss: 0.1504    acc: 0.956
 epoch: 50   batch: 18   loss: 0.07611   acc: 0.9753
 epoch: 50   batch: 19   loss: 0.1015    acc: 0.9677
 epoch: 50   batch: 20   loss: 0.0879    acc: 0.9727
 means -->               loss: 0.1124    acc: 0.9664]
[norms of weights -> l1: 23453.658, l2: 37.935744]
EPOCH: 51/100...
[fit info (epoch 51):
 epoch: 51   batch: 1    loss: 0.09147   acc: 0.9743
 epoch: 51   batch: 2    loss: 0.1236    acc: 0.9623
 epoch: 51   batch: 3    loss: 0.1178    acc: 0.962
 epoch: 51   batch: 4    loss: 0.1036    acc: 0.967
 epoch: 51   batch: 5    loss: 0.07848   acc: 0.9743
 epoch: 51   batch: 6    loss: 0.09408   acc: 0.9707
 epoch: 51   batch: 7    loss: 0.09295   acc: 0.9733
 epoch: 51   batch: 8    loss: 0.1141    acc: 0.964
 epoch: 51   batch: 9    loss: 0.08918   acc: 0.972
 epoch: 51   batch: 10   loss: 0.125     acc: 0.963
 epoch: 51   batch: 11   loss: 0.104     acc: 0.975
 epoch: 51   batch: 12   loss: 0.09326   acc: 0.973
 epoch: 51   batch: 13   loss: 0.1061    acc: 0.967
 epoch: 51   batch: 14   loss: 0.1017    acc: 0.97
 epoch: 51   batch: 15   loss: 0.08571   acc: 0.9763
 epoch: 51   batch: 16   loss: 0.114     acc: 0.9667
 epoch: 51   batch: 17   loss: 0.104     acc: 0.972
 epoch: 51   batch: 18   loss: 0.1755    acc: 0.9503
 epoch: 51   batch: 19   loss: 0.08334   acc: 0.972
 epoch: 51   batch: 20   loss: 0.1019    acc: 0.9677
 means -->               loss: 0.105     acc: 0.9687]
[norms of weights -> l1: 23469.299, l2: 37.971265]
EPOCH: 52/100...
[fit info (epoch 52):
 epoch: 52   batch: 1    loss: 0.09043   acc: 0.972
 epoch: 52   batch: 2    loss: 0.07564   acc: 0.9773
 epoch: 52   batch: 3    loss: 0.1065    acc: 0.9723
 epoch: 52   batch: 4    loss: 0.122     acc: 0.967
 epoch: 52   batch: 5    loss: 0.1165    acc: 0.9663
 epoch: 52   batch: 6    loss: 0.09026   acc: 0.9743
 epoch: 52   batch: 7    loss: 0.07166   acc: 0.9803
 epoch: 52   batch: 8    loss: 0.1519    acc: 0.9673
 epoch: 52   batch: 9    loss: 0.165     acc: 0.953
 epoch: 52   batch: 10   loss: 0.08477   acc: 0.9727
 epoch: 52   batch: 11   loss: 0.0861    acc: 0.9753
 epoch: 52   batch: 12   loss: 0.09763   acc: 0.9723
 epoch: 52   batch: 13   loss: 0.1017    acc: 0.9653
 epoch: 52   batch: 14   loss: 0.1099    acc: 0.9683
 epoch: 52   batch: 15   loss: 0.1189    acc: 0.9637
 epoch: 52   batch: 16   loss: 0.09147   acc: 0.9713
 epoch: 52   batch: 17   loss: 0.09327   acc: 0.971
 epoch: 52   batch: 18   loss: 0.1145    acc: 0.9667
 epoch: 52   batch: 19   loss: 0.1033    acc: 0.9673
 epoch: 52   batch: 20   loss: 0.1058    acc: 0.9663
 means -->               loss: 0.1049    acc: 0.9695]
[norms of weights -> l1: 23486.528, l2: 38.010014]
EPOCH: 53/100...
[fit info (epoch 53):
 epoch: 53   batch: 1    loss: 0.09957   acc: 0.97
 epoch: 53   batch: 2    loss: 0.1158    acc: 0.9623
 epoch: 53   batch: 3    loss: 0.08901   acc: 0.974
 epoch: 53   batch: 4    loss: 0.1446    acc: 0.9583
 epoch: 53   batch: 5    loss: 0.1269    acc: 0.9647
 epoch: 53   batch: 6    loss: 0.1088    acc: 0.9697
 epoch: 53   batch: 7    loss: 0.1313    acc: 0.9577
 epoch: 53   batch: 8    loss: 0.1232    acc: 0.9607
 epoch: 53   batch: 9    loss: 0.07536   acc: 0.977
 epoch: 53   batch: 10   loss: 0.1088    acc: 0.967
 epoch: 53   batch: 11   loss: 0.08354   acc: 0.9723
 epoch: 53   batch: 12   loss: 0.0972    acc: 0.9713
 epoch: 53   batch: 13   loss: 0.1165    acc: 0.967
 epoch: 53   batch: 14   loss: 0.1136    acc: 0.97
 epoch: 53   batch: 15   loss: 0.09976   acc: 0.969
 epoch: 53   batch: 16   loss: 0.1089    acc: 0.9683
 epoch: 53   batch: 17   loss: 0.1194    acc: 0.9663
 epoch: 53   batch: 18   loss: 0.07766   acc: 0.976
 epoch: 53   batch: 19   loss: 0.1091    acc: 0.964
 epoch: 53   batch: 20   loss: 0.1178    acc: 0.966
 means -->               loss: 0.1083    acc: 0.9676]
[norms of weights -> l1: 23503.062, l2: 38.048362]
EPOCH: 54/100...
[fit info (epoch 54):
 epoch: 54   batch: 1    loss: 0.1141    acc: 0.966
 epoch: 54   batch: 2    loss: 0.1133    acc: 0.963
 epoch: 54   batch: 3    loss: 0.1178    acc: 0.9627
 epoch: 54   batch: 4    loss: 0.1258    acc: 0.9633
 epoch: 54   batch: 5    loss: 0.07232   acc: 0.9763
 epoch: 54   batch: 6    loss: 0.1275    acc: 0.963
 epoch: 54   batch: 7    loss: 0.1562    acc: 0.9527
 epoch: 54   batch: 8    loss: 0.1095    acc: 0.968
 epoch: 54   batch: 9    loss: 0.1135    acc: 0.965
 epoch: 54   batch: 10   loss: 0.09332   acc: 0.9723
 epoch: 54   batch: 11   loss: 0.1103    acc: 0.966
 epoch: 54   batch: 12   loss: 0.1831    acc: 0.9427
 epoch: 54   batch: 13   loss: 0.1817    acc: 0.9547
 epoch: 54   batch: 14   loss: 0.1046    acc: 0.9687
 epoch: 54   batch: 15   loss: 0.1056    acc: 0.967
 epoch: 54   batch: 16   loss: 0.07485   acc: 0.977
 epoch: 54   batch: 17   loss: 0.09367   acc: 0.9687
 epoch: 54   batch: 18   loss: 0.124     acc: 0.9623
 epoch: 54   batch: 19   loss: 0.1031    acc: 0.9643
 epoch: 54   batch: 20   loss: 0.1485    acc: 0.9537
 means -->               loss: 0.1186    acc: 0.9639]
[norms of weights -> l1: 23522.48, l2: 38.09365]
EPOCH: 55/100...
[fit info (epoch 55):
 epoch: 55   batch: 1    loss: 0.1331    acc: 0.9563
 epoch: 55   batch: 2    loss: 0.1065    acc: 0.9677
 epoch: 55   batch: 3    loss: 0.1005    acc: 0.9667
 epoch: 55   batch: 4    loss: 0.09333   acc: 0.9717
 epoch: 55   batch: 5    loss: 0.1092    acc: 0.9673
 epoch: 55   batch: 6    loss: 0.1135    acc: 0.9637
 epoch: 55   batch: 7    loss: 0.1011    acc: 0.9737
 epoch: 55   batch: 8    loss: 0.1128    acc: 0.9693
 epoch: 55   batch: 9    loss: 0.08097   acc: 0.9757
 epoch: 55   batch: 10   loss: 0.08757   acc: 0.9707
 epoch: 55   batch: 11   loss: 0.08404   acc: 0.9733
 epoch: 55   batch: 12   loss: 0.1058    acc: 0.9677
 epoch: 55   batch: 13   loss: 0.09506   acc: 0.97
 epoch: 55   batch: 14   loss: 0.09757   acc: 0.9683
 epoch: 55   batch: 15   loss: 0.1116    acc: 0.963
 epoch: 55   batch: 16   loss: 0.1516    acc: 0.9533
 epoch: 55   batch: 17   loss: 0.09134   acc: 0.973
 epoch: 55   batch: 18   loss: 0.1124    acc: 0.9647
 epoch: 55   batch: 19   loss: 0.09504   acc: 0.9727
 epoch: 55   batch: 20   loss: 0.1018    acc: 0.9687
 means -->               loss: 0.1042    acc: 0.9679]
[norms of weights -> l1: 23541.55, l2: 38.137127]
EPOCH: 56/100...
[fit info (epoch 56):
 epoch: 56   batch: 1    loss: 0.1017    acc: 0.9697
 epoch: 56   batch: 2    loss: 0.09169   acc: 0.9743
 epoch: 56   batch: 3    loss: 0.09333   acc: 0.9693
 epoch: 56   batch: 4    loss: 0.08044   acc: 0.975
 epoch: 56   batch: 5    loss: 0.0624    acc: 0.982
 epoch: 56   batch: 6    loss: 0.06645   acc: 0.98
 epoch: 56   batch: 7    loss: 0.121     acc: 0.9657
 epoch: 56   batch: 8    loss: 0.103     acc: 0.972
 epoch: 56   batch: 9    loss: 0.1821    acc: 0.9503
 epoch: 56   batch: 10   loss: 0.07349   acc: 0.9767
 epoch: 56   batch: 11   loss: 0.0894    acc: 0.9713
 epoch: 56   batch: 12   loss: 0.1389    acc: 0.9617
 epoch: 56   batch: 13   loss: 0.1197    acc: 0.9643
 epoch: 56   batch: 14   loss: 0.08383   acc: 0.974
 epoch: 56   batch: 15   loss: 0.08419   acc: 0.97
 epoch: 56   batch: 16   loss: 0.09341   acc: 0.9697
 epoch: 56   batch: 17   loss: 0.1018    acc: 0.9713
 epoch: 56   batch: 18   loss: 0.1083    acc: 0.9683
 epoch: 56   batch: 19   loss: 0.08524   acc: 0.9717
 epoch: 56   batch: 20   loss: 0.1936    acc: 0.94
 means -->               loss: 0.1037    acc: 0.9689]
[norms of weights -> l1: 23557.301, l2: 38.173745]
EPOCH: 57/100...
[fit info (epoch 57):
 epoch: 57   batch: 1    loss: 0.104     acc: 0.9707
 epoch: 57   batch: 2    loss: 0.09862   acc: 0.9713
 epoch: 57   batch: 3    loss: 0.08844   acc: 0.9743
 epoch: 57   batch: 4    loss: 0.1087    acc: 0.969
 epoch: 57   batch: 5    loss: 0.07661   acc: 0.976
 epoch: 57   batch: 6    loss: 0.1108    acc: 0.9653
 epoch: 57   batch: 7    loss: 0.08966   acc: 0.9733
 epoch: 57   batch: 8    loss: 0.09408   acc: 0.9697
 epoch: 57   batch: 9    loss: 0.1117    acc: 0.97
 epoch: 57   batch: 10   loss: 0.0962    acc: 0.9697
 epoch: 57   batch: 11   loss: 0.0978    acc: 0.9663
 epoch: 57   batch: 12   loss: 0.09244   acc: 0.9713
 epoch: 57   batch: 13   loss: 0.1078    acc: 0.9673
 epoch: 57   batch: 14   loss: 0.116     acc: 0.9697
 epoch: 57   batch: 15   loss: 0.09976   acc: 0.969
 epoch: 57   batch: 16   loss: 0.0751    acc: 0.978
 epoch: 57   batch: 17   loss: 0.1067    acc: 0.966
 epoch: 57   batch: 18   loss: 0.07087   acc: 0.9753
 epoch: 57   batch: 19   loss: 0.09301   acc: 0.9703
 epoch: 57   batch: 20   loss: 0.07736   acc: 0.9777
 means -->               loss: 0.09578   acc: 0.971]
[norms of weights -> l1: 23577.112, l2: 38.217499]
EPOCH: 58/100...
[fit info (epoch 58):
 epoch: 58   batch: 1    loss: 0.09695   acc: 0.969
 epoch: 58   batch: 2    loss: 0.07415   acc: 0.9783
 epoch: 58   batch: 3    loss: 0.1097    acc: 0.9647
 epoch: 58   batch: 4    loss: 0.1055    acc: 0.971
 epoch: 58   batch: 5    loss: 0.08311   acc: 0.9777
 epoch: 58   batch: 6    loss: 0.07992   acc: 0.9783
 epoch: 58   batch: 7    loss: 0.06198   acc: 0.9803
 epoch: 58   batch: 8    loss: 0.1161    acc: 0.9663
 epoch: 58   batch: 9    loss: 0.09104   acc: 0.9727
 epoch: 58   batch: 10   loss: 0.08323   acc: 0.9743
 epoch: 58   batch: 11   loss: 0.06486   acc: 0.978
 epoch: 58   batch: 12   loss: 0.1131    acc: 0.9677
 epoch: 58   batch: 13   loss: 0.094     acc: 0.9687
 epoch: 58   batch: 14   loss: 0.07422   acc: 0.9793
 epoch: 58   batch: 15   loss: 0.1239    acc: 0.964
 epoch: 58   batch: 16   loss: 0.08563   acc: 0.9727
 epoch: 58   batch: 17   loss: 0.0973    acc: 0.9687
 epoch: 58   batch: 18   loss: 0.08617   acc: 0.975
 epoch: 58   batch: 19   loss: 0.08088   acc: 0.9753
 epoch: 58   batch: 20   loss: 0.1018    acc: 0.9713
 means -->               loss: 0.09118   acc: 0.9727]
[norms of weights -> l1: 23594.7, l2: 38.255788]
EPOCH: 59/100...
[fit info (epoch 59):
 epoch: 59   batch: 1    loss: 0.08695   acc: 0.973
 epoch: 59   batch: 2    loss: 0.07681   acc: 0.978
 epoch: 59   batch: 3    loss: 0.07028   acc: 0.979
 epoch: 59   batch: 4    loss: 0.1596    acc: 0.952
 epoch: 59   batch: 5    loss: 0.1066    acc: 0.969
 epoch: 59   batch: 6    loss: 0.06409   acc: 0.98
 epoch: 59   batch: 7    loss: 0.08495   acc: 0.9737
 epoch: 59   batch: 8    loss: 0.09083   acc: 0.968
 epoch: 59   batch: 9    loss: 0.07216   acc: 0.9803
 epoch: 59   batch: 10   loss: 0.0693    acc: 0.9777
 epoch: 59   batch: 11   loss: 0.09302   acc: 0.9703
 epoch: 59   batch: 12   loss: 0.08998   acc: 0.9703
 epoch: 59   batch: 13   loss: 0.1172    acc: 0.9707
 epoch: 59   batch: 14   loss: 0.0676    acc: 0.9827
 epoch: 59   batch: 15   loss: 0.08186   acc: 0.9777
 epoch: 59   batch: 16   loss: 0.09089   acc: 0.9743
 epoch: 59   batch: 17   loss: 0.107     acc: 0.966
 epoch: 59   batch: 18   loss: 0.07665   acc: 0.9767
 epoch: 59   batch: 19   loss: 0.0968    acc: 0.9717
 epoch: 59   batch: 20   loss: 0.1083    acc: 0.9717
 means -->               loss: 0.09055   acc: 0.9731]
[norms of weights -> l1: 23612.663, l2: 38.294853]
EPOCH: 60/100...
[fit info (epoch 60):
 epoch: 60   batch: 1    loss: 0.08878   acc: 0.9753
 epoch: 60   batch: 2    loss: 0.07132   acc: 0.976
 epoch: 60   batch: 3    loss: 0.06952   acc: 0.977
 epoch: 60   batch: 4    loss: 0.05104   acc: 0.984
 epoch: 60   batch: 5    loss: 0.1058    acc: 0.969
 epoch: 60   batch: 6    loss: 0.1153    acc: 0.971
 epoch: 60   batch: 7    loss: 0.07517   acc: 0.9757
 epoch: 60   batch: 8    loss: 0.09342   acc: 0.97
 epoch: 60   batch: 9    loss: 0.08914   acc: 0.9783
 epoch: 60   batch: 10   loss: 0.1075    acc: 0.9643
 epoch: 60   batch: 11   loss: 0.07274   acc: 0.9767
 epoch: 60   batch: 12   loss: 0.1282    acc: 0.963
 epoch: 60   batch: 13   loss: 0.105     acc: 0.9703
 epoch: 60   batch: 14   loss: 0.09418   acc: 0.968
 epoch: 60   batch: 15   loss: 0.12      acc: 0.9647
 epoch: 60   batch: 16   loss: 0.08748   acc: 0.9723
 epoch: 60   batch: 17   loss: 0.07222   acc: 0.9803
 epoch: 60   batch: 18   loss: 0.09331   acc: 0.9733
 epoch: 60   batch: 19   loss: 0.08146   acc: 0.975
 epoch: 60   batch: 20   loss: 0.05504   acc: 0.9833
 means -->               loss: 0.08883   acc: 0.9734]
[norms of weights -> l1: 23627.336, l2: 38.329101]
EPOCH: 61/100...
[fit info (epoch 61):
 epoch: 61   batch: 1    loss: 0.096     acc: 0.9723
 epoch: 61   batch: 2    loss: 0.1043    acc: 0.9653
 epoch: 61   batch: 3    loss: 0.06924   acc: 0.98
 epoch: 61   batch: 4    loss: 0.1033    acc: 0.9697
 epoch: 61   batch: 5    loss: 0.1337    acc: 0.9627
 epoch: 61   batch: 6    loss: 0.1401    acc: 0.961
 epoch: 61   batch: 7    loss: 0.08695   acc: 0.9707
 epoch: 61   batch: 8    loss: 0.07436   acc: 0.9763
 epoch: 61   batch: 9    loss: 0.09204   acc: 0.974
 epoch: 61   batch: 10   loss: 0.08672   acc: 0.973
 epoch: 61   batch: 11   loss: 0.09488   acc: 0.9727
 epoch: 61   batch: 12   loss: 0.08446   acc: 0.9787
 epoch: 61   batch: 13   loss: 0.07288   acc: 0.977
 epoch: 61   batch: 14   loss: 0.07821   acc: 0.9747
 epoch: 61   batch: 15   loss: 0.1398    acc: 0.965
 epoch: 61   batch: 16   loss: 0.05015   acc: 0.9843
 epoch: 61   batch: 17   loss: 0.1096    acc: 0.9657
 epoch: 61   batch: 18   loss: 0.1062    acc: 0.9667
 epoch: 61   batch: 19   loss: 0.05826   acc: 0.985
 epoch: 61   batch: 20   loss: 0.08867   acc: 0.9727
 means -->               loss: 0.09349   acc: 0.9724]
[norms of weights -> l1: 23646.516, l2: 38.372571]
EPOCH: 62/100...
[fit info (epoch 62):
 epoch: 62   batch: 1    loss: 0.1096    acc: 0.9697
 epoch: 62   batch: 2    loss: 0.08071   acc: 0.9767
 epoch: 62   batch: 3    loss: 0.1164    acc: 0.964
 epoch: 62   batch: 4    loss: 0.08382   acc: 0.9747
 epoch: 62   batch: 5    loss: 0.07077   acc: 0.9753
 epoch: 62   batch: 6    loss: 0.09326   acc: 0.97
 epoch: 62   batch: 7    loss: 0.1656    acc: 0.9567
 epoch: 62   batch: 8    loss: 0.17      acc: 0.9497
 epoch: 62   batch: 9    loss: 0.08403   acc: 0.972
 epoch: 62   batch: 10   loss: 0.09163   acc: 0.9723
 epoch: 62   batch: 11   loss: 0.1028    acc: 0.9723
 epoch: 62   batch: 12   loss: 0.1009    acc: 0.9707
 epoch: 62   batch: 13   loss: 0.05623   acc: 0.9813
 epoch: 62   batch: 14   loss: 0.1499    acc: 0.953
 epoch: 62   batch: 15   loss: 0.08506   acc: 0.976
 epoch: 62   batch: 16   loss: 0.08236   acc: 0.9757
 epoch: 62   batch: 17   loss: 0.09469   acc: 0.972
 epoch: 62   batch: 18   loss: 0.09661   acc: 0.9703
 epoch: 62   batch: 19   loss: 0.07266   acc: 0.9797
 epoch: 62   batch: 20   loss: 0.1154    acc: 0.97
 means -->               loss: 0.1011    acc: 0.9701]
[norms of weights -> l1: 23668.907, l2: 38.420916]
EPOCH: 63/100...
[fit info (epoch 63):
 epoch: 63   batch: 1    loss: 0.1538    acc: 0.9573
 epoch: 63   batch: 2    loss: 0.08739   acc: 0.9743
 epoch: 63   batch: 3    loss: 0.09506   acc: 0.97
 epoch: 63   batch: 4    loss: 0.08748   acc: 0.9707
 epoch: 63   batch: 5    loss: 0.1258    acc: 0.9617
 epoch: 63   batch: 6    loss: 0.08573   acc: 0.9737
 epoch: 63   batch: 7    loss: 0.1077    acc: 0.9707
 epoch: 63   batch: 8    loss: 0.06681   acc: 0.979
 epoch: 63   batch: 9    loss: 0.2967    acc: 0.9097
 epoch: 63   batch: 10   loss: 0.08871   acc: 0.9767
 epoch: 63   batch: 11   loss: 0.1154    acc: 0.9687
 epoch: 63   batch: 12   loss: 0.1411    acc: 0.959
 epoch: 63   batch: 13   loss: 0.1322    acc: 0.9593
 epoch: 63   batch: 14   loss: 0.1098    acc: 0.9667
 epoch: 63   batch: 15   loss: 0.06208   acc: 0.9823
 epoch: 63   batch: 16   loss: 0.07866   acc: 0.9753
 epoch: 63   batch: 17   loss: 0.1121    acc: 0.9677
 epoch: 63   batch: 18   loss: 0.07938   acc: 0.9757
 epoch: 63   batch: 19   loss: 0.1162    acc: 0.9623
 epoch: 63   batch: 20   loss: 0.09863   acc: 0.968
 means -->               loss: 0.112     acc: 0.9664]
[norms of weights -> l1: 23691.712, l2: 38.472293]
EPOCH: 64/100...
[fit info (epoch 64):
 epoch: 64   batch: 1    loss: 0.1574    acc: 0.944
 epoch: 64   batch: 2    loss: 0.1125    acc: 0.9687
 epoch: 64   batch: 3    loss: 0.08795   acc: 0.9733
 epoch: 64   batch: 4    loss: 0.07688   acc: 0.9783
 epoch: 64   batch: 5    loss: 0.1369    acc: 0.961
 epoch: 64   batch: 6    loss: 0.1052    acc: 0.9703
 epoch: 64   batch: 7    loss: 0.07868   acc: 0.9787
 epoch: 64   batch: 8    loss: 0.09878   acc: 0.9683
 epoch: 64   batch: 9    loss: 0.1108    acc: 0.966
 epoch: 64   batch: 10   loss: 0.1582    acc: 0.9573
 epoch: 64   batch: 11   loss: 0.1019    acc: 0.9703
 epoch: 64   batch: 12   loss: 0.07623   acc: 0.975
 epoch: 64   batch: 13   loss: 0.1271    acc: 0.9637
 epoch: 64   batch: 14   loss: 0.09569   acc: 0.971
 epoch: 64   batch: 15   loss: 0.1111    acc: 0.9693
 epoch: 64   batch: 16   loss: 0.1168    acc: 0.9643
 epoch: 64   batch: 17   loss: 0.08189   acc: 0.9763
 epoch: 64   batch: 18   loss: 0.06916   acc: 0.978
 epoch: 64   batch: 19   loss: 0.107     acc: 0.9717
 epoch: 64   batch: 20   loss: 0.07458   acc: 0.9793
 means -->               loss: 0.1042    acc: 0.9693]
[norms of weights -> l1: 23713.268, l2: 38.523652]
EPOCH: 65/100...
[fit info (epoch 65):
 epoch: 65   batch: 1    loss: 0.1235    acc: 0.9673
 epoch: 65   batch: 2    loss: 0.07624   acc: 0.9817
 epoch: 65   batch: 3    loss: 0.1024    acc: 0.9693
 epoch: 65   batch: 4    loss: 0.0799    acc: 0.9753
 epoch: 65   batch: 5    loss: 0.08985   acc: 0.9753
 epoch: 65   batch: 6    loss: 0.0736    acc: 0.9773
 epoch: 65   batch: 7    loss: 0.0935    acc: 0.9723
 epoch: 65   batch: 8    loss: 0.07814   acc: 0.9777
 epoch: 65   batch: 9    loss: 0.0839    acc: 0.9737
 epoch: 65   batch: 10   loss: 0.07473   acc: 0.9773
 epoch: 65   batch: 11   loss: 0.09155   acc: 0.971
 epoch: 65   batch: 12   loss: 0.07313   acc: 0.9787
 epoch: 65   batch: 13   loss: 0.06828   acc: 0.9787
 epoch: 65   batch: 14   loss: 0.1012    acc: 0.973
 epoch: 65   batch: 15   loss: 0.0614    acc: 0.98
 epoch: 65   batch: 16   loss: 0.07599   acc: 0.979
 epoch: 65   batch: 17   loss: 0.1125    acc: 0.966
 epoch: 65   batch: 18   loss: 0.1247    acc: 0.969
 epoch: 65   batch: 19   loss: 0.06551   acc: 0.9807
 epoch: 65   batch: 20   loss: 0.06644   acc: 0.981
 means -->               loss: 0.08583   acc: 0.9752]
[norms of weights -> l1: 23729.964, l2: 38.561142]
EPOCH: 66/100...
[fit info (epoch 66):
 epoch: 66   batch: 1    loss: 0.1205    acc: 0.9603
 epoch: 66   batch: 2    loss: 0.06183   acc: 0.9833
 epoch: 66   batch: 3    loss: 0.09914   acc: 0.9727
 epoch: 66   batch: 4    loss: 0.07847   acc: 0.9763
 epoch: 66   batch: 5    loss: 0.06589   acc: 0.9783
 epoch: 66   batch: 6    loss: 0.07908   acc: 0.9767
 epoch: 66   batch: 7    loss: 0.06627   acc: 0.979
 epoch: 66   batch: 8    loss: 0.05307   acc: 0.982
 epoch: 66   batch: 9    loss: 0.07315   acc: 0.9743
 epoch: 66   batch: 10   loss: 0.1124    acc: 0.9683
 epoch: 66   batch: 11   loss: 0.09789   acc: 0.9737
 epoch: 66   batch: 12   loss: 0.07719   acc: 0.98
 epoch: 66   batch: 13   loss: 0.0903    acc: 0.972
 epoch: 66   batch: 14   loss: 0.06757   acc: 0.978
 epoch: 66   batch: 15   loss: 0.06721   acc: 0.9807
 epoch: 66   batch: 16   loss: 0.07591   acc: 0.9783
 epoch: 66   batch: 17   loss: 0.08278   acc: 0.9743
 epoch: 66   batch: 18   loss: 0.09661   acc: 0.9723
 epoch: 66   batch: 19   loss: 0.07235   acc: 0.9763
 epoch: 66   batch: 20   loss: 0.08562   acc: 0.9743
 means -->               loss: 0.08116   acc: 0.9756]
[norms of weights -> l1: 23743.083, l2: 38.592316]
EPOCH: 67/100...
[fit info (epoch 67):
 epoch: 67   batch: 1    loss: 0.083     acc: 0.9797
 epoch: 67   batch: 2    loss: 0.07155   acc: 0.978
 epoch: 67   batch: 3    loss: 0.06056   acc: 0.9813
 epoch: 67   batch: 4    loss: 0.08669   acc: 0.9763
 epoch: 67   batch: 5    loss: 0.1234    acc: 0.9653
 epoch: 67   batch: 6    loss: 0.06229   acc: 0.9797
 epoch: 67   batch: 7    loss: 0.06889   acc: 0.9813
 epoch: 67   batch: 8    loss: 0.06067   acc: 0.9823
 epoch: 67   batch: 9    loss: 0.09691   acc: 0.9697
 epoch: 67   batch: 10   loss: 0.05158   acc: 0.9863
 epoch: 67   batch: 11   loss: 0.05681   acc: 0.9833
 epoch: 67   batch: 12   loss: 0.06115   acc: 0.9833
 epoch: 67   batch: 13   loss: 0.09112   acc: 0.972
 epoch: 67   batch: 14   loss: 0.07878   acc: 0.976
 epoch: 67   batch: 15   loss: 0.2941    acc: 0.9173
 epoch: 67   batch: 16   loss: 0.06954   acc: 0.9767
 epoch: 67   batch: 17   loss: 0.09724   acc: 0.9723
 epoch: 67   batch: 18   loss: 0.1371    acc: 0.9623
 epoch: 67   batch: 19   loss: 0.1503    acc: 0.9533
 epoch: 67   batch: 20   loss: 0.1768    acc: 0.9503
 means -->               loss: 0.09892   acc: 0.9713]
[norms of weights -> l1: 23760.296, l2: 38.631583]
EPOCH: 68/100...
[fit info (epoch 68):
 epoch: 68   batch: 1    loss: 0.1267    acc: 0.9593
 epoch: 68   batch: 2    loss: 0.09634   acc: 0.97
 epoch: 68   batch: 3    loss: 0.07832   acc: 0.9753
 epoch: 68   batch: 4    loss: 0.08103   acc: 0.9717
 epoch: 68   batch: 5    loss: 0.1033    acc: 0.9703
 epoch: 68   batch: 6    loss: 0.1097    acc: 0.97
 epoch: 68   batch: 7    loss: 0.126     acc: 0.9633
 epoch: 68   batch: 8    loss: 0.1062    acc: 0.9767
 epoch: 68   batch: 9    loss: 0.1008    acc: 0.969
 epoch: 68   batch: 10   loss: 0.1291    acc: 0.9637
 epoch: 68   batch: 11   loss: 0.07582   acc: 0.976
 epoch: 68   batch: 12   loss: 0.1142    acc: 0.966
 epoch: 68   batch: 13   loss: 0.1241    acc: 0.9653
 epoch: 68   batch: 14   loss: 0.1023    acc: 0.968
 epoch: 68   batch: 15   loss: 0.1358    acc: 0.962
 epoch: 68   batch: 16   loss: 0.1155    acc: 0.9613
 epoch: 68   batch: 17   loss: 0.1115    acc: 0.9643
 epoch: 68   batch: 18   loss: 0.1062    acc: 0.9667
 epoch: 68   batch: 19   loss: 0.08242   acc: 0.9747
 epoch: 68   batch: 20   loss: 0.1353    acc: 0.9563
 means -->               loss: 0.108     acc: 0.9675]
[norms of weights -> l1: 23789.62, l2: 38.696254]
EPOCH: 69/100...
[fit info (epoch 69):
 epoch: 69   batch: 1    loss: 0.08755   acc: 0.975
 epoch: 69   batch: 2    loss: 0.09528   acc: 0.97
 epoch: 69   batch: 3    loss: 0.0651    acc: 0.9817
 epoch: 69   batch: 4    loss: 0.09432   acc: 0.973
 epoch: 69   batch: 5    loss: 0.06802   acc: 0.98
 epoch: 69   batch: 6    loss: 0.1259    acc: 0.966
 epoch: 69   batch: 7    loss: 0.06917   acc: 0.977
 epoch: 69   batch: 8    loss: 0.0839    acc: 0.9757
 epoch: 69   batch: 9    loss: 0.1315    acc: 0.9583
 epoch: 69   batch: 10   loss: 0.07259   acc: 0.9753
 epoch: 69   batch: 11   loss: 0.09817   acc: 0.9677
 epoch: 69   batch: 12   loss: 0.09666   acc: 0.9717
 epoch: 69   batch: 13   loss: 0.06767   acc: 0.9787
 epoch: 69   batch: 14   loss: 0.06438   acc: 0.9803
 epoch: 69   batch: 15   loss: 0.09527   acc: 0.9783
 epoch: 69   batch: 16   loss: 0.1172    acc: 0.9677
 epoch: 69   batch: 17   loss: 0.08066   acc: 0.9767
 epoch: 69   batch: 18   loss: 0.07999   acc: 0.9773
 epoch: 69   batch: 19   loss: 0.06717   acc: 0.9827
 epoch: 69   batch: 20   loss: 0.06907   acc: 0.983
 means -->               loss: 0.08648   acc: 0.9748]
[norms of weights -> l1: 23811.103, l2: 38.745168]
EPOCH: 70/100...
[fit info (epoch 70):
 epoch: 70   batch: 1    loss: 0.1399    acc: 0.9603
 epoch: 70   batch: 2    loss: 0.07623   acc: 0.9743
 epoch: 70   batch: 3    loss: 0.0614    acc: 0.9813
 epoch: 70   batch: 4    loss: 0.08196   acc: 0.9777
 epoch: 70   batch: 5    loss: 0.05707   acc: 0.98
 epoch: 70   batch: 6    loss: 0.1353    acc: 0.965
 epoch: 70   batch: 7    loss: 0.09613   acc: 0.973
 epoch: 70   batch: 8    loss: 0.0818    acc: 0.976
 epoch: 70   batch: 9    loss: 0.1006    acc: 0.9697
 epoch: 70   batch: 10   loss: 0.06298   acc: 0.9817
 epoch: 70   batch: 11   loss: 0.07519   acc: 0.977
 epoch: 70   batch: 12   loss: 0.08817   acc: 0.9707
 epoch: 70   batch: 13   loss: 0.08432   acc: 0.9747
 epoch: 70   batch: 14   loss: 0.06509   acc: 0.982
 epoch: 70   batch: 15   loss: 0.1113    acc: 0.9717
 epoch: 70   batch: 16   loss: 0.07009   acc: 0.978
 epoch: 70   batch: 17   loss: 0.1038    acc: 0.967
 epoch: 70   batch: 18   loss: 0.09078   acc: 0.9777
 epoch: 70   batch: 19   loss: 0.06696   acc: 0.981
 epoch: 70   batch: 20   loss: 0.06063   acc: 0.9807
 means -->               loss: 0.08548   acc: 0.975]
[norms of weights -> l1: 23828.81, l2: 38.786238]
EPOCH: 71/100...
[fit info (epoch 71):
 epoch: 71   batch: 1    loss: 0.07029   acc: 0.9757
 epoch: 71   batch: 2    loss: 0.0691    acc: 0.9793
 epoch: 71   batch: 3    loss: 0.0717    acc: 0.981
 epoch: 71   batch: 4    loss: 0.07194   acc: 0.985
 epoch: 71   batch: 5    loss: 0.0566    acc: 0.9837
 epoch: 71   batch: 6    loss: 0.07515   acc: 0.9793
 epoch: 71   batch: 7    loss: 0.06246   acc: 0.982
 epoch: 71   batch: 8    loss: 0.08336   acc: 0.9743
 epoch: 71   batch: 9    loss: 0.1069    acc: 0.972
 epoch: 71   batch: 10   loss: 0.06872   acc: 0.98
 epoch: 71   batch: 11   loss: 0.09589   acc: 0.9713
 epoch: 71   batch: 12   loss: 0.07885   acc: 0.975
 epoch: 71   batch: 13   loss: 0.06558   acc: 0.9807
 epoch: 71   batch: 14   loss: 0.062     acc: 0.984
 epoch: 71   batch: 15   loss: 0.1065    acc: 0.9673
 epoch: 71   batch: 16   loss: 0.06269   acc: 0.9823
 epoch: 71   batch: 17   loss: 0.0925    acc: 0.9743
 epoch: 71   batch: 18   loss: 0.05931   acc: 0.9843
 epoch: 71   batch: 19   loss: 0.06602   acc: 0.979
 epoch: 71   batch: 20   loss: 0.105     acc: 0.9683
 means -->               loss: 0.07653   acc: 0.9779]
[norms of weights -> l1: 23844.759, l2: 38.821464]
EPOCH: 72/100...
[fit info (epoch 72):
 epoch: 72   batch: 1    loss: 0.07511   acc: 0.9767
 epoch: 72   batch: 2    loss: 0.07878   acc: 0.977
 epoch: 72   batch: 3    loss: 0.06563   acc: 0.98
 epoch: 72   batch: 4    loss: 0.05298   acc: 0.9813
 epoch: 72   batch: 5    loss: 0.06246   acc: 0.9803
 epoch: 72   batch: 6    loss: 0.06621   acc: 0.978
 epoch: 72   batch: 7    loss: 0.05683   acc: 0.981
 epoch: 72   batch: 8    loss: 0.06131   acc: 0.9803
 epoch: 72   batch: 9    loss: 0.08249   acc: 0.9767
 epoch: 72   batch: 10   loss: 0.05336   acc: 0.9837
 epoch: 72   batch: 11   loss: 0.09303   acc: 0.9767
 epoch: 72   batch: 12   loss: 0.0764    acc: 0.975
 epoch: 72   batch: 13   loss: 0.1049    acc: 0.9687
 epoch: 72   batch: 14   loss: 0.06701   acc: 0.9827
 epoch: 72   batch: 15   loss: 0.05301   acc: 0.9807
 epoch: 72   batch: 16   loss: 0.07532   acc: 0.9757
 epoch: 72   batch: 17   loss: 0.05486   acc: 0.987
 epoch: 72   batch: 18   loss: 0.07549   acc: 0.9737
 epoch: 72   batch: 19   loss: 0.06153   acc: 0.9813
 epoch: 72   batch: 20   loss: 0.08766   acc: 0.9737
 means -->               loss: 0.07022   acc: 0.9785]
[norms of weights -> l1: 23858.244, l2: 38.851633]
EPOCH: 73/100...
[fit info (epoch 73):
 epoch: 73   batch: 1    loss: 0.08223   acc: 0.9753
 epoch: 73   batch: 2    loss: 0.05412   acc: 0.9823
 epoch: 73   batch: 3    loss: 0.05344   acc: 0.9833
 epoch: 73   batch: 4    loss: 0.06777   acc: 0.9797
 epoch: 73   batch: 5    loss: 0.05828   acc: 0.983
 epoch: 73   batch: 6    loss: 0.05419   acc: 0.983
 epoch: 73   batch: 7    loss: 0.1132    acc: 0.971
 epoch: 73   batch: 8    loss: 0.08309   acc: 0.9753
 epoch: 73   batch: 9    loss: 0.0865    acc: 0.975
 epoch: 73   batch: 10   loss: 0.07985   acc: 0.9757
 epoch: 73   batch: 11   loss: 0.06736   acc: 0.9773
 epoch: 73   batch: 12   loss: 0.08908   acc: 0.97
 epoch: 73   batch: 13   loss: 0.06517   acc: 0.981
 epoch: 73   batch: 14   loss: 0.06536   acc: 0.9797
 epoch: 73   batch: 15   loss: 0.06031   acc: 0.9807
 epoch: 73   batch: 16   loss: 0.07835   acc: 0.9777
 epoch: 73   batch: 17   loss: 0.08007   acc: 0.9767
 epoch: 73   batch: 18   loss: 0.06673   acc: 0.9797
 epoch: 73   batch: 19   loss: 0.08363   acc: 0.972
 epoch: 73   batch: 20   loss: 0.05268   acc: 0.9837
 means -->               loss: 0.07207   acc: 0.9781]
[norms of weights -> l1: 23870.781, l2: 38.879721]
EPOCH: 74/100...
[fit info (epoch 74):
 epoch: 74   batch: 1    loss: 0.06551   acc: 0.978
 epoch: 74   batch: 2    loss: 0.0756    acc: 0.9783
 epoch: 74   batch: 3    loss: 0.06086   acc: 0.9843
 epoch: 74   batch: 4    loss: 0.07754   acc: 0.9787
 epoch: 74   batch: 5    loss: 0.05307   acc: 0.9833
 epoch: 74   batch: 6    loss: 0.08465   acc: 0.9747
 epoch: 74   batch: 7    loss: 0.07909   acc: 0.9773
 epoch: 74   batch: 8    loss: 0.1317    acc: 0.956
 epoch: 74   batch: 9    loss: 0.07223   acc: 0.976
 epoch: 74   batch: 10   loss: 0.1064    acc: 0.971
 epoch: 74   batch: 11   loss: 0.1251    acc: 0.9647
 epoch: 74   batch: 12   loss: 0.06618   acc: 0.9843
 epoch: 74   batch: 13   loss: 0.07768   acc: 0.9757
 epoch: 74   batch: 14   loss: 0.06513   acc: 0.9823
 epoch: 74   batch: 15   loss: 0.06917   acc: 0.9787
 epoch: 74   batch: 16   loss: 0.06721   acc: 0.978
 epoch: 74   batch: 17   loss: 0.06137   acc: 0.9817
 epoch: 74   batch: 18   loss: 0.06866   acc: 0.9807
 epoch: 74   batch: 19   loss: 0.08467   acc: 0.9763
 epoch: 74   batch: 20   loss: 0.07581   acc: 0.975
 means -->               loss: 0.07838   acc: 0.9768]
[norms of weights -> l1: 23886.088, l2: 38.913126]
EPOCH: 75/100...
[fit info (epoch 75):
 epoch: 75   batch: 1    loss: 0.0554    acc: 0.979
 epoch: 75   batch: 2    loss: 0.09435   acc: 0.974
 epoch: 75   batch: 3    loss: 0.04896   acc: 0.986
 epoch: 75   batch: 4    loss: 0.07815   acc: 0.979
 epoch: 75   batch: 5    loss: 0.05038   acc: 0.9827
 epoch: 75   batch: 6    loss: 0.06891   acc: 0.976
 epoch: 75   batch: 7    loss: 0.04344   acc: 0.9863
 epoch: 75   batch: 8    loss: 0.04632   acc: 0.9867
 epoch: 75   batch: 9    loss: 0.05701   acc: 0.9797
 epoch: 75   batch: 10   loss: 0.08767   acc: 0.9763
 epoch: 75   batch: 11   loss: 0.05357   acc: 0.985
 epoch: 75   batch: 12   loss: 0.06898   acc: 0.977
 epoch: 75   batch: 13   loss: 0.05472   acc: 0.9847
 epoch: 75   batch: 14   loss: 0.08937   acc: 0.9747
 epoch: 75   batch: 15   loss: 0.06992   acc: 0.9813
 epoch: 75   batch: 16   loss: 0.08104   acc: 0.9723
 epoch: 75   batch: 17   loss: 0.06906   acc: 0.9777
 epoch: 75   batch: 18   loss: 0.07769   acc: 0.9757
 epoch: 75   batch: 19   loss: 0.08735   acc: 0.975
 epoch: 75   batch: 20   loss: 0.06738   acc: 0.9783
 means -->               loss: 0.06748   acc: 0.9794]
[norms of weights -> l1: 23899.551, l2: 38.945312]
EPOCH: 76/100...
[fit info (epoch 76):
 epoch: 76   batch: 1    loss: 0.0724    acc: 0.9797
 epoch: 76   batch: 2    loss: 0.05371   acc: 0.9833
 epoch: 76   batch: 3    loss: 0.07986   acc: 0.976
 epoch: 76   batch: 4    loss: 0.06688   acc: 0.9837
 epoch: 76   batch: 5    loss: 0.07149   acc: 0.9793
 epoch: 76   batch: 6    loss: 0.1161    acc: 0.9683
 epoch: 76   batch: 7    loss: 0.06807   acc: 0.978
 epoch: 76   batch: 8    loss: 0.0755    acc: 0.9767
 epoch: 76   batch: 9    loss: 0.07627   acc: 0.9743
 epoch: 76   batch: 10   loss: 0.05393   acc: 0.9853
 epoch: 76   batch: 11   loss: 0.07993   acc: 0.9767
 epoch: 76   batch: 12   loss: 0.07188   acc: 0.9793
 epoch: 76   batch: 13   loss: 0.08241   acc: 0.9767
 epoch: 76   batch: 14   loss: 0.04554   acc: 0.986
 epoch: 76   batch: 15   loss: 0.05536   acc: 0.987
 epoch: 76   batch: 16   loss: 0.06115   acc: 0.9817
 epoch: 76   batch: 17   loss: 0.05603   acc: 0.9823
 epoch: 76   batch: 18   loss: 0.06641   acc: 0.9797
 epoch: 76   batch: 19   loss: 0.0683    acc: 0.9797
 epoch: 76   batch: 20   loss: 0.06475   acc: 0.979
 means -->               loss: 0.0693    acc: 0.9796]
[norms of weights -> l1: 23913.275, l2: 38.976337]
EPOCH: 77/100...
[fit info (epoch 77):
 epoch: 77   batch: 1    loss: 0.07022   acc: 0.982
 epoch: 77   batch: 2    loss: 0.07024   acc: 0.9793
 epoch: 77   batch: 3    loss: 0.05816   acc: 0.9823
 epoch: 77   batch: 4    loss: 0.07175   acc: 0.98
 epoch: 77   batch: 5    loss: 0.06172   acc: 0.9817
 epoch: 77   batch: 6    loss: 0.05387   acc: 0.9833
 epoch: 77   batch: 7    loss: 0.08687   acc: 0.9777
 epoch: 77   batch: 8    loss: 0.06059   acc: 0.9813
 epoch: 77   batch: 9    loss: 0.117     acc: 0.965
 epoch: 77   batch: 10   loss: 0.05868   acc: 0.985
 epoch: 77   batch: 11   loss: 0.04355   acc: 0.986
 epoch: 77   batch: 12   loss: 0.06729   acc: 0.98
 epoch: 77   batch: 13   loss: 0.08042   acc: 0.9777
 epoch: 77   batch: 14   loss: 0.08333   acc: 0.973
 epoch: 77   batch: 15   loss: 0.07643   acc: 0.9797
 epoch: 77   batch: 16   loss: 0.1197    acc: 0.966
 epoch: 77   batch: 17   loss: 0.06451   acc: 0.9813
 epoch: 77   batch: 18   loss: 0.08369   acc: 0.9797
 epoch: 77   batch: 19   loss: 0.0477    acc: 0.9843
 epoch: 77   batch: 20   loss: 0.06703   acc: 0.984
 means -->               loss: 0.07214   acc: 0.9795]
[norms of weights -> l1: 23928.891, l2: 39.011131]
EPOCH: 78/100...
[fit info (epoch 78):
 epoch: 78   batch: 1    loss: 0.04559   acc: 0.985
 epoch: 78   batch: 2    loss: 0.06623   acc: 0.9823
 epoch: 78   batch: 3    loss: 0.06668   acc: 0.9787
 epoch: 78   batch: 4    loss: 0.05947   acc: 0.986
 epoch: 78   batch: 5    loss: 0.06421   acc: 0.98
 epoch: 78   batch: 6    loss: 0.08091   acc: 0.9753
 epoch: 78   batch: 7    loss: 0.04396   acc: 0.987
 epoch: 78   batch: 8    loss: 0.055     acc: 0.983
 epoch: 78   batch: 9    loss: 0.05428   acc: 0.9837
 epoch: 78   batch: 10   loss: 0.08354   acc: 0.9753
 epoch: 78   batch: 11   loss: 0.08631   acc: 0.9737
 epoch: 78   batch: 12   loss: 0.0783    acc: 0.9783
 epoch: 78   batch: 13   loss: 0.07191   acc: 0.9787
 epoch: 78   batch: 14   loss: 0.05265   acc: 0.9863
 epoch: 78   batch: 15   loss: 0.06866   acc: 0.9797
 epoch: 78   batch: 16   loss: 0.07395   acc: 0.9733
 epoch: 78   batch: 17   loss: 0.06878   acc: 0.981
 epoch: 78   batch: 18   loss: 0.04724   acc: 0.9857
 epoch: 78   batch: 19   loss: 0.05106   acc: 0.984
 epoch: 78   batch: 20   loss: 0.07242   acc: 0.9787
 means -->               loss: 0.06456   acc: 0.9808]
[norms of weights -> l1: 23941.336, l2: 39.040455]
EPOCH: 79/100...
[fit info (epoch 79):
 epoch: 79   batch: 1    loss: 0.07699   acc: 0.9803
 epoch: 79   batch: 2    loss: 0.09898   acc: 0.9683
 epoch: 79   batch: 3    loss: 0.04899   acc: 0.987
 epoch: 79   batch: 4    loss: 0.07607   acc: 0.9767
 epoch: 79   batch: 5    loss: 0.06901   acc: 0.9777
 epoch: 79   batch: 6    loss: 0.06946   acc: 0.981
 epoch: 79   batch: 7    loss: 0.06296   acc: 0.981
 epoch: 79   batch: 8    loss: 0.07105   acc: 0.979
 epoch: 79   batch: 9    loss: 0.06314   acc: 0.9793
 epoch: 79   batch: 10   loss: 0.06488   acc: 0.9843
 epoch: 79   batch: 11   loss: 0.08833   acc: 0.9723
 epoch: 79   batch: 12   loss: 0.08459   acc: 0.9763
 epoch: 79   batch: 13   loss: 0.07119   acc: 0.9787
 epoch: 79   batch: 14   loss: 0.08404   acc: 0.9773
 epoch: 79   batch: 15   loss: 0.04427   acc: 0.9867
 epoch: 79   batch: 16   loss: 0.06203   acc: 0.9817
 epoch: 79   batch: 17   loss: 0.07294   acc: 0.9793
 epoch: 79   batch: 18   loss: 0.07357   acc: 0.9757
 epoch: 79   batch: 19   loss: 0.06177   acc: 0.9797
 epoch: 79   batch: 20   loss: 0.0609    acc: 0.982
 means -->               loss: 0.07026   acc: 0.9792]
[norms of weights -> l1: 23955.315, l2: 39.073638]
EPOCH: 80/100...
[fit info (epoch 80):
 epoch: 80   batch: 1    loss: 0.07552   acc: 0.9797
 epoch: 80   batch: 2    loss: 0.05996   acc: 0.9823
 epoch: 80   batch: 3    loss: 0.07008   acc: 0.9783
 epoch: 80   batch: 4    loss: 0.04931   acc: 0.9817
 epoch: 80   batch: 5    loss: 0.06063   acc: 0.9833
 epoch: 80   batch: 6    loss: 0.05966   acc: 0.982
 epoch: 80   batch: 7    loss: 0.0394    acc: 0.9853
 epoch: 80   batch: 8    loss: 0.04968   acc: 0.9857
 epoch: 80   batch: 9    loss: 0.05634   acc: 0.9847
 epoch: 80   batch: 10   loss: 0.07679   acc: 0.979
 epoch: 80   batch: 11   loss: 0.04897   acc: 0.9833
 epoch: 80   batch: 12   loss: 0.04273   acc: 0.9887
 epoch: 80   batch: 13   loss: 0.07715   acc: 0.976
 epoch: 80   batch: 14   loss: 0.08316   acc: 0.9713
 epoch: 80   batch: 15   loss: 0.04184   acc: 0.9893
 epoch: 80   batch: 16   loss: 0.05975   acc: 0.9797
 epoch: 80   batch: 17   loss: 0.08341   acc: 0.9757
 epoch: 80   batch: 18   loss: 0.04595   acc: 0.9853
 epoch: 80   batch: 19   loss: 0.07676   acc: 0.9797
 epoch: 80   batch: 20   loss: 0.04293   acc: 0.984
 means -->               loss: 0.06      acc: 0.9817]
[norms of weights -> l1: 23969.391, l2: 39.105873]
EPOCH: 81/100...
[fit info (epoch 81):
 epoch: 81   batch: 1    loss: 0.05942   acc: 0.983
 epoch: 81   batch: 2    loss: 0.08108   acc: 0.9767
 epoch: 81   batch: 3    loss: 0.05925   acc: 0.9817
 epoch: 81   batch: 4    loss: 0.06565   acc: 0.9787
 epoch: 81   batch: 5    loss: 0.05271   acc: 0.9817
 epoch: 81   batch: 6    loss: 0.05076   acc: 0.986
 epoch: 81   batch: 7    loss: 0.04603   acc: 0.9853
 epoch: 81   batch: 8    loss: 0.04474   acc: 0.9867
 epoch: 81   batch: 9    loss: 0.05857   acc: 0.9837
 epoch: 81   batch: 10   loss: 0.06618   acc: 0.9783
 epoch: 81   batch: 11   loss: 0.06937   acc: 0.978
 epoch: 81   batch: 12   loss: 0.06011   acc: 0.9807
 epoch: 81   batch: 13   loss: 0.06731   acc: 0.9777
 epoch: 81   batch: 14   loss: 0.08115   acc: 0.977
 epoch: 81   batch: 15   loss: 0.06482   acc: 0.9803
 epoch: 81   batch: 16   loss: 0.07302   acc: 0.9803
 epoch: 81   batch: 17   loss: 0.05736   acc: 0.984
 epoch: 81   batch: 18   loss: 0.07542   acc: 0.982
 epoch: 81   batch: 19   loss: 0.09301   acc: 0.9733
 epoch: 81   batch: 20   loss: 0.07826   acc: 0.9797
 means -->               loss: 0.06521   acc: 0.9807]
[norms of weights -> l1: 23979.936, l2: 39.130183]
EPOCH: 82/100...
[fit info (epoch 82):
 epoch: 82   batch: 1    loss: 0.0685    acc: 0.9797
 epoch: 82   batch: 2    loss: 0.05324   acc: 0.9817
 epoch: 82   batch: 3    loss: 0.07021   acc: 0.9797
 epoch: 82   batch: 4    loss: 0.0529    acc: 0.9807
 epoch: 82   batch: 5    loss: 0.105     acc: 0.9703
 epoch: 82   batch: 6    loss: 0.06589   acc: 0.981
 epoch: 82   batch: 7    loss: 0.07948   acc: 0.976
 epoch: 82   batch: 8    loss: 0.06491   acc: 0.98
 epoch: 82   batch: 9    loss: 0.04235   acc: 0.9857
 epoch: 82   batch: 10   loss: 0.06664   acc: 0.9797
 epoch: 82   batch: 11   loss: 0.08677   acc: 0.9747
 epoch: 82   batch: 12   loss: 0.0532    acc: 0.9853
 epoch: 82   batch: 13   loss: 0.09509   acc: 0.9733
 epoch: 82   batch: 14   loss: 0.03355   acc: 0.9907
 epoch: 82   batch: 15   loss: 0.0521    acc: 0.9833
 epoch: 82   batch: 16   loss: 0.06312   acc: 0.9823
 epoch: 82   batch: 17   loss: 0.0543    acc: 0.9817
 epoch: 82   batch: 18   loss: 0.07044   acc: 0.9777
 epoch: 82   batch: 19   loss: 0.09346   acc: 0.9703
 epoch: 82   batch: 20   loss: 0.05329   acc: 0.9837
 means -->               loss: 0.06622   acc: 0.9799]
[norms of weights -> l1: 23995.224, l2: 39.164849]
EPOCH: 83/100...
[fit info (epoch 83):
 epoch: 83   batch: 1    loss: 0.05824   acc: 0.9797
 epoch: 83   batch: 2    loss: 0.04772   acc: 0.9857
 epoch: 83   batch: 3    loss: 0.07546   acc: 0.977
 epoch: 83   batch: 4    loss: 0.09576   acc: 0.9747
 epoch: 83   batch: 5    loss: 0.03933   acc: 0.9877
 epoch: 83   batch: 6    loss: 0.06055   acc: 0.983
 epoch: 83   batch: 7    loss: 0.06687   acc: 0.9807
 epoch: 83   batch: 8    loss: 0.04805   acc: 0.9857
 epoch: 83   batch: 9    loss: 0.07834   acc: 0.976
 epoch: 83   batch: 10   loss: 0.06886   acc: 0.9793
 epoch: 83   batch: 11   loss: 0.05843   acc: 0.979
 epoch: 83   batch: 12   loss: 0.04727   acc: 0.9853
 epoch: 83   batch: 13   loss: 0.0389    acc: 0.9863
 epoch: 83   batch: 14   loss: 0.08037   acc: 0.977
 epoch: 83   batch: 15   loss: 0.05389   acc: 0.982
 epoch: 83   batch: 16   loss: 0.05673   acc: 0.985
 epoch: 83   batch: 17   loss: 0.05799   acc: 0.9833
 epoch: 83   batch: 18   loss: 0.05739   acc: 0.983
 epoch: 83   batch: 19   loss: 0.06327   acc: 0.9807
 epoch: 83   batch: 20   loss: 0.06902   acc: 0.9797
 means -->               loss: 0.06112   acc: 0.9815]
[norms of weights -> l1: 24008.538, l2: 39.195327]
EPOCH: 84/100...
[fit info (epoch 84):
 epoch: 84   batch: 1    loss: 0.05019   acc: 0.9853
 epoch: 84   batch: 2    loss: 0.05269   acc: 0.9833
 epoch: 84   batch: 3    loss: 0.05196   acc: 0.9853
 epoch: 84   batch: 4    loss: 0.04722   acc: 0.9847
 epoch: 84   batch: 5    loss: 0.04442   acc: 0.987
 epoch: 84   batch: 6    loss: 0.05154   acc: 0.986
 epoch: 84   batch: 7    loss: 0.05224   acc: 0.9857
 epoch: 84   batch: 8    loss: 0.03774   acc: 0.9863
 epoch: 84   batch: 9    loss: 0.05652   acc: 0.9823
 epoch: 84   batch: 10   loss: 0.05118   acc: 0.9823
 epoch: 84   batch: 11   loss: 0.06018   acc: 0.9793
 epoch: 84   batch: 12   loss: 0.05363   acc: 0.9843
 epoch: 84   batch: 13   loss: 0.05186   acc: 0.986
 epoch: 84   batch: 14   loss: 0.06559   acc: 0.9823
 epoch: 84   batch: 15   loss: 0.07937   acc: 0.9783
 epoch: 84   batch: 16   loss: 0.06714   acc: 0.9763
 epoch: 84   batch: 17   loss: 0.05463   acc: 0.9853
 epoch: 84   batch: 18   loss: 0.06269   acc: 0.9817
 epoch: 84   batch: 19   loss: 0.08829   acc: 0.9777
 epoch: 84   batch: 20   loss: 0.0396    acc: 0.9873
 means -->               loss: 0.05593   acc: 0.9833]
[norms of weights -> l1: 24023.15, l2: 39.229395]
EPOCH: 85/100...
[fit info (epoch 85):
 epoch: 85   batch: 1    loss: 0.0567    acc: 0.9797
 epoch: 85   batch: 2    loss: 0.05972   acc: 0.9827
 epoch: 85   batch: 3    loss: 0.04707   acc: 0.9863
 epoch: 85   batch: 4    loss: 0.08835   acc: 0.9723
 epoch: 85   batch: 5    loss: 0.06308   acc: 0.9813
 epoch: 85   batch: 6    loss: 0.04939   acc: 0.9837
 epoch: 85   batch: 7    loss: 0.04748   acc: 0.9863
 epoch: 85   batch: 8    loss: 0.06822   acc: 0.982
 epoch: 85   batch: 9    loss: 0.05532   acc: 0.9817
 epoch: 85   batch: 10   loss: 0.08002   acc: 0.9777
 epoch: 85   batch: 11   loss: 0.06311   acc: 0.9827
 epoch: 85   batch: 12   loss: 0.03812   acc: 0.988
 epoch: 85   batch: 13   loss: 0.08121   acc: 0.9757
 epoch: 85   batch: 14   loss: 0.06552   acc: 0.9807
 epoch: 85   batch: 15   loss: 0.03716   acc: 0.9883
 epoch: 85   batch: 16   loss: 0.06315   acc: 0.9837
 epoch: 85   batch: 17   loss: 0.07074   acc: 0.9843
 epoch: 85   batch: 18   loss: 0.03473   acc: 0.9887
 epoch: 85   batch: 19   loss: 0.06697   acc: 0.978
 epoch: 85   batch: 20   loss: 0.04346   acc: 0.985
 means -->               loss: 0.05898   acc: 0.9824]
[norms of weights -> l1: 24037.032, l2: 39.262485]
EPOCH: 86/100...
[fit info (epoch 86):
 epoch: 86   batch: 1    loss: 0.04087   acc: 0.9867
 epoch: 86   batch: 2    loss: 0.04498   acc: 0.99
 epoch: 86   batch: 3    loss: 0.06344   acc: 0.9827
 epoch: 86   batch: 4    loss: 0.05093   acc: 0.9887
 epoch: 86   batch: 5    loss: 0.04064   acc: 0.989
 epoch: 86   batch: 6    loss: 0.05788   acc: 0.984
 epoch: 86   batch: 7    loss: 0.05456   acc: 0.984
 epoch: 86   batch: 8    loss: 0.06046   acc: 0.9763
 epoch: 86   batch: 9    loss: 0.06242   acc: 0.9813
 epoch: 86   batch: 10   loss: 0.04452   acc: 0.987
 epoch: 86   batch: 11   loss: 0.0644    acc: 0.982
 epoch: 86   batch: 12   loss: 0.04456   acc: 0.9857
 epoch: 86   batch: 13   loss: 0.06183   acc: 0.982
 epoch: 86   batch: 14   loss: 0.05475   acc: 0.9847
 epoch: 86   batch: 15   loss: 0.07526   acc: 0.9777
 epoch: 86   batch: 16   loss: 0.08324   acc: 0.9733
 epoch: 86   batch: 17   loss: 0.05757   acc: 0.9827
 epoch: 86   batch: 18   loss: 0.04058   acc: 0.9873
 epoch: 86   batch: 19   loss: 0.06447   acc: 0.9827
 epoch: 86   batch: 20   loss: 0.04676   acc: 0.986
 means -->               loss: 0.05571   acc: 0.9837]
[norms of weights -> l1: 24048.945, l2: 39.289848]
EPOCH: 87/100...
[fit info (epoch 87):
 epoch: 87   batch: 1    loss: 0.05658   acc: 0.9853
 epoch: 87   batch: 2    loss: 0.04664   acc: 0.9867
 epoch: 87   batch: 3    loss: 0.03725   acc: 0.988
 epoch: 87   batch: 4    loss: 0.0574    acc: 0.983
 epoch: 87   batch: 5    loss: 0.04612   acc: 0.9857
 epoch: 87   batch: 6    loss: 0.06789   acc: 0.9787
 epoch: 87   batch: 7    loss: 0.07532   acc: 0.9767
 epoch: 87   batch: 8    loss: 0.04598   acc: 0.9863
 epoch: 87   batch: 9    loss: 0.0563    acc: 0.9823
 epoch: 87   batch: 10   loss: 0.05904   acc: 0.9803
 epoch: 87   batch: 11   loss: 0.06058   acc: 0.9843
 epoch: 87   batch: 12   loss: 0.05994   acc: 0.9823
 epoch: 87   batch: 13   loss: 0.05668   acc: 0.9837
 epoch: 87   batch: 14   loss: 0.05328   acc: 0.9857
 epoch: 87   batch: 15   loss: 0.05687   acc: 0.9847
 epoch: 87   batch: 16   loss: 0.04999   acc: 0.9857
 epoch: 87   batch: 17   loss: 0.06183   acc: 0.98
 epoch: 87   batch: 18   loss: 0.07913   acc: 0.9797
 epoch: 87   batch: 19   loss: 0.06039   acc: 0.9817
 epoch: 87   batch: 20   loss: 0.05528   acc: 0.986
 means -->               loss: 0.05712   acc: 0.9833]
[norms of weights -> l1: 24063.656, l2: 39.322445]
EPOCH: 88/100...
[fit info (epoch 88):
 epoch: 88   batch: 1    loss: 0.09225   acc: 0.9763
 epoch: 88   batch: 2    loss: 0.09318   acc: 0.9717
 epoch: 88   batch: 3    loss: 0.05018   acc: 0.9847
 epoch: 88   batch: 4    loss: 0.07279   acc: 0.9807
 epoch: 88   batch: 5    loss: 0.05898   acc: 0.982
 epoch: 88   batch: 6    loss: 0.05085   acc: 0.9877
 epoch: 88   batch: 7    loss: 0.06465   acc: 0.9803
 epoch: 88   batch: 8    loss: 0.05455   acc: 0.9837
 epoch: 88   batch: 9    loss: 0.0521    acc: 0.9837
 epoch: 88   batch: 10   loss: 0.06984   acc: 0.9783
 epoch: 88   batch: 11   loss: 0.05182   acc: 0.986
 epoch: 88   batch: 12   loss: 0.0437    acc: 0.9883
 epoch: 88   batch: 13   loss: 0.04642   acc: 0.9857
 epoch: 88   batch: 14   loss: 0.04894   acc: 0.9867
 epoch: 88   batch: 15   loss: 0.06232   acc: 0.9837
 epoch: 88   batch: 16   loss: 0.04339   acc: 0.983
 epoch: 88   batch: 17   loss: 0.1185    acc: 0.966
 epoch: 88   batch: 18   loss: 0.04939   acc: 0.984
 epoch: 88   batch: 19   loss: 0.03456   acc: 0.9883
 epoch: 88   batch: 20   loss: 0.0635    acc: 0.9813
 means -->               loss: 0.06109   acc: 0.9821]
[norms of weights -> l1: 24079.142, l2: 39.35637]
EPOCH: 89/100...
[fit info (epoch 89):
 epoch: 89   batch: 1    loss: 0.1025    acc: 0.97
 epoch: 89   batch: 2    loss: 0.07367   acc: 0.982
 epoch: 89   batch: 3    loss: 0.06491   acc: 0.9823
 epoch: 89   batch: 4    loss: 0.0688    acc: 0.9807
 epoch: 89   batch: 5    loss: 0.0511    acc: 0.984
 epoch: 89   batch: 6    loss: 0.09547   acc: 0.9733
 epoch: 89   batch: 7    loss: 0.05167   acc: 0.9867
 epoch: 89   batch: 8    loss: 0.06933   acc: 0.981
 epoch: 89   batch: 9    loss: 0.0492    acc: 0.9867
 epoch: 89   batch: 10   loss: 0.1226    acc: 0.9717
 epoch: 89   batch: 11   loss: 0.07294   acc: 0.9787
 epoch: 89   batch: 12   loss: 0.05742   acc: 0.9843
 epoch: 89   batch: 13   loss: 0.07055   acc: 0.9787
 epoch: 89   batch: 14   loss: 0.06809   acc: 0.9807
 epoch: 89   batch: 15   loss: 0.04585   acc: 0.985
 epoch: 89   batch: 16   loss: 0.04093   acc: 0.987
 epoch: 89   batch: 17   loss: 0.0658    acc: 0.9813
 epoch: 89   batch: 18   loss: 0.06657   acc: 0.9803
 epoch: 89   batch: 19   loss: 0.04979   acc: 0.982
 epoch: 89   batch: 20   loss: 0.05002   acc: 0.9833
 means -->               loss: 0.06686   acc: 0.981]
[norms of weights -> l1: 24098.137, l2: 39.39703]
EPOCH: 90/100...
[fit info (epoch 90):
 epoch: 90   batch: 1    loss: 0.03979   acc: 0.9873
 epoch: 90   batch: 2    loss: 0.0577    acc: 0.9827
 epoch: 90   batch: 3    loss: 0.05216   acc: 0.9833
 epoch: 90   batch: 4    loss: 0.06147   acc: 0.9813
 epoch: 90   batch: 5    loss: 0.03609   acc: 0.9917
 epoch: 90   batch: 6    loss: 0.05205   acc: 0.9853
 epoch: 90   batch: 7    loss: 0.06121   acc: 0.9837
 epoch: 90   batch: 8    loss: 0.05874   acc: 0.982
 epoch: 90   batch: 9    loss: 0.05324   acc: 0.9823
 epoch: 90   batch: 10   loss: 0.03818   acc: 0.987
 epoch: 90   batch: 11   loss: 0.06327   acc: 0.985
 epoch: 90   batch: 12   loss: 0.04001   acc: 0.9853
 epoch: 90   batch: 13   loss: 0.08872   acc: 0.9743
 epoch: 90   batch: 14   loss: 0.07096   acc: 0.9783
 epoch: 90   batch: 15   loss: 0.04526   acc: 0.9863
 epoch: 90   batch: 16   loss: 0.0546    acc: 0.986
 epoch: 90   batch: 17   loss: 0.04785   acc: 0.984
 epoch: 90   batch: 18   loss: 0.03993   acc: 0.987
 epoch: 90   batch: 19   loss: 0.03719   acc: 0.99
 epoch: 90   batch: 20   loss: 0.03915   acc: 0.9877
 means -->               loss: 0.05188   acc: 0.9845]
[norms of weights -> l1: 24113.505, l2: 39.428537]
EPOCH: 91/100...
[fit info (epoch 91):
 epoch: 91   batch: 1    loss: 0.07534   acc: 0.977
 epoch: 91   batch: 2    loss: 0.04759   acc: 0.986
 epoch: 91   batch: 3    loss: 0.03808   acc: 0.987
 epoch: 91   batch: 4    loss: 0.04111   acc: 0.985
 epoch: 91   batch: 5    loss: 0.06302   acc: 0.9857
 epoch: 91   batch: 6    loss: 0.0701    acc: 0.9803
 epoch: 91   batch: 7    loss: 0.04761   acc: 0.987
 epoch: 91   batch: 8    loss: 0.06754   acc: 0.982
 epoch: 91   batch: 9    loss: 0.04438   acc: 0.9893
 epoch: 91   batch: 10   loss: 0.06622   acc: 0.9797
 epoch: 91   batch: 11   loss: 0.08331   acc: 0.977
 epoch: 91   batch: 12   loss: 0.04344   acc: 0.986
 epoch: 91   batch: 13   loss: 0.07906   acc: 0.9727
 epoch: 91   batch: 14   loss: 0.0644    acc: 0.9807
 epoch: 91   batch: 15   loss: 0.04868   acc: 0.9863
 epoch: 91   batch: 16   loss: 0.05222   acc: 0.983
 epoch: 91   batch: 17   loss: 0.05771   acc: 0.9837
 epoch: 91   batch: 18   loss: 0.05745   acc: 0.9827
 epoch: 91   batch: 19   loss: 0.05432   acc: 0.985
 epoch: 91   batch: 20   loss: 0.04202   acc: 0.9867
 means -->               loss: 0.05718   acc: 0.9831]
[norms of weights -> l1: 24126.217, l2: 39.457779]
EPOCH: 92/100...
[fit info (epoch 92):
 epoch: 92   batch: 1    loss: 0.0473    acc: 0.9873
 epoch: 92   batch: 2    loss: 0.09759   acc: 0.9707
 epoch: 92   batch: 3    loss: 0.05538   acc: 0.9857
 epoch: 92   batch: 4    loss: 0.04074   acc: 0.9887
 epoch: 92   batch: 5    loss: 0.04328   acc: 0.9863
 epoch: 92   batch: 6    loss: 0.04871   acc: 0.9857
 epoch: 92   batch: 7    loss: 0.05715   acc: 0.9813
 epoch: 92   batch: 8    loss: 0.07105   acc: 0.9793
 epoch: 92   batch: 9    loss: 0.08297   acc: 0.9747
 epoch: 92   batch: 10   loss: 0.0402    acc: 0.9893
 epoch: 92   batch: 11   loss: 0.03995   acc: 0.9867
 epoch: 92   batch: 12   loss: 0.05339   acc: 0.9813
 epoch: 92   batch: 13   loss: 0.04149   acc: 0.9847
 epoch: 92   batch: 14   loss: 0.04823   acc: 0.9847
 epoch: 92   batch: 15   loss: 0.04027   acc: 0.9883
 epoch: 92   batch: 16   loss: 0.07022   acc: 0.9803
 epoch: 92   batch: 17   loss: 0.0441    acc: 0.9867
 epoch: 92   batch: 18   loss: 0.0486    acc: 0.9863
 epoch: 92   batch: 19   loss: 0.04775   acc: 0.9867
 epoch: 92   batch: 20   loss: 0.04932   acc: 0.9833
 means -->               loss: 0.05338   acc: 0.9839]
[norms of weights -> l1: 24140.666, l2: 39.490339]
EPOCH: 93/100...
[fit info (epoch 93):
 epoch: 93   batch: 1    loss: 0.08968   acc: 0.9763
 epoch: 93   batch: 2    loss: 0.06237   acc: 0.9833
 epoch: 93   batch: 3    loss: 0.05623   acc: 0.982
 epoch: 93   batch: 4    loss: 0.06353   acc: 0.9857
 epoch: 93   batch: 5    loss: 0.05162   acc: 0.9853
 epoch: 93   batch: 6    loss: 0.04288   acc: 0.986
 epoch: 93   batch: 7    loss: 0.07842   acc: 0.976
 epoch: 93   batch: 8    loss: 0.05992   acc: 0.9807
 epoch: 93   batch: 9    loss: 0.0364    acc: 0.988
 epoch: 93   batch: 10   loss: 0.0522    acc: 0.985
 epoch: 93   batch: 11   loss: 0.03855   acc: 0.99
 epoch: 93   batch: 12   loss: 0.05786   acc: 0.982
 epoch: 93   batch: 13   loss: 0.1099    acc: 0.9763
 epoch: 93   batch: 14   loss: 0.05189   acc: 0.9857
 epoch: 93   batch: 15   loss: 0.063     acc: 0.9813
 epoch: 93   batch: 16   loss: 0.04547   acc: 0.986
 epoch: 93   batch: 17   loss: 0.04939   acc: 0.986
 epoch: 93   batch: 18   loss: 0.04557   acc: 0.985
 epoch: 93   batch: 19   loss: 0.07559   acc: 0.9767
 epoch: 93   batch: 20   loss: 0.04486   acc: 0.986
 means -->               loss: 0.05877   acc: 0.9832]
[norms of weights -> l1: 24157.662, l2: 39.526182]
EPOCH: 94/100...
[fit info (epoch 94):
 epoch: 94   batch: 1    loss: 0.05009   acc: 0.98
 epoch: 94   batch: 2    loss: 0.05873   acc: 0.9857
 epoch: 94   batch: 3    loss: 0.0559    acc: 0.984
 epoch: 94   batch: 4    loss: 0.04961   acc: 0.986
 epoch: 94   batch: 5    loss: 0.04819   acc: 0.9833
 epoch: 94   batch: 6    loss: 0.05275   acc: 0.9867
 epoch: 94   batch: 7    loss: 0.04178   acc: 0.9897
 epoch: 94   batch: 8    loss: 0.05483   acc: 0.9827
 epoch: 94   batch: 9    loss: 0.04215   acc: 0.9863
 epoch: 94   batch: 10   loss: 0.04211   acc: 0.9877
 epoch: 94   batch: 11   loss: 0.04356   acc: 0.9857
 epoch: 94   batch: 12   loss: 0.04294   acc: 0.987
 epoch: 94   batch: 13   loss: 0.06916   acc: 0.9777
 epoch: 94   batch: 14   loss: 0.04553   acc: 0.986
 epoch: 94   batch: 15   loss: 0.04841   acc: 0.985
 epoch: 94   batch: 16   loss: 0.04085   acc: 0.9883
 epoch: 94   batch: 17   loss: 0.04974   acc: 0.9857
 epoch: 94   batch: 18   loss: 0.04079   acc: 0.9873
 epoch: 94   batch: 19   loss: 0.057     acc: 0.985
 epoch: 94   batch: 20   loss: 0.04577   acc: 0.9833
 means -->               loss: 0.04899   acc: 0.9851]
[norms of weights -> l1: 24171.932, l2: 39.558893]
EPOCH: 95/100...
[fit info (epoch 95):
 epoch: 95   batch: 1    loss: 0.0344    acc: 0.9897
 epoch: 95   batch: 2    loss: 0.05237   acc: 0.985
 epoch: 95   batch: 3    loss: 0.07475   acc: 0.9767
 epoch: 95   batch: 4    loss: 0.04996   acc: 0.985
 epoch: 95   batch: 5    loss: 0.05285   acc: 0.9843
 epoch: 95   batch: 6    loss: 0.08007   acc: 0.9787
 epoch: 95   batch: 7    loss: 0.08184   acc: 0.9733
 epoch: 95   batch: 8    loss: 0.07165   acc: 0.9813
 epoch: 95   batch: 9    loss: 0.03906   acc: 0.9907
 epoch: 95   batch: 10   loss: 0.05199   acc: 0.9853
 epoch: 95   batch: 11   loss: 0.0512    acc: 0.984
 epoch: 95   batch: 12   loss: 0.05397   acc: 0.9833
 epoch: 95   batch: 13   loss: 0.06159   acc: 0.982
 epoch: 95   batch: 14   loss: 0.08795   acc: 0.9717
 epoch: 95   batch: 15   loss: 0.05019   acc: 0.9867
 epoch: 95   batch: 16   loss: 0.05593   acc: 0.9823
 epoch: 95   batch: 17   loss: 0.04894   acc: 0.9843
 epoch: 95   batch: 18   loss: 0.05692   acc: 0.9813
 epoch: 95   batch: 19   loss: 0.0607    acc: 0.9837
 epoch: 95   batch: 20   loss: 0.05268   acc: 0.9847
 means -->               loss: 0.05845   acc: 0.9827]
[norms of weights -> l1: 24186.804, l2: 39.593284]
EPOCH: 96/100...
[fit info (epoch 96):
 epoch: 96   batch: 1    loss: 0.05842   acc: 0.9843
 epoch: 96   batch: 2    loss: 0.05489   acc: 0.985
 epoch: 96   batch: 3    loss: 0.04752   acc: 0.9877
 epoch: 96   batch: 4    loss: 0.04973   acc: 0.9863
 epoch: 96   batch: 5    loss: 0.05781   acc: 0.9843
 epoch: 96   batch: 6    loss: 0.06517   acc: 0.978
 epoch: 96   batch: 7    loss: 0.05624   acc: 0.982
 epoch: 96   batch: 8    loss: 0.07192   acc: 0.9797
 epoch: 96   batch: 9    loss: 0.04389   acc: 0.9887
 epoch: 96   batch: 10   loss: 0.05574   acc: 0.9847
 epoch: 96   batch: 11   loss: 0.06555   acc: 0.9767
 epoch: 96   batch: 12   loss: 0.05246   acc: 0.987
 epoch: 96   batch: 13   loss: 0.07277   acc: 0.979
 epoch: 96   batch: 14   loss: 0.07631   acc: 0.981
 epoch: 96   batch: 15   loss: 0.04013   acc: 0.9863
 epoch: 96   batch: 16   loss: 0.09933   acc: 0.976
 epoch: 96   batch: 17   loss: 0.04596   acc: 0.9847
 epoch: 96   batch: 18   loss: 0.0402    acc: 0.9877
 epoch: 96   batch: 19   loss: 0.0471    acc: 0.9877
 epoch: 96   batch: 20   loss: 0.04946   acc: 0.986
 means -->               loss: 0.05753   acc: 0.9836]
[norms of weights -> l1: 24202.147, l2: 39.628853]
EPOCH: 97/100...
[fit info (epoch 97):
 epoch: 97   batch: 1    loss: 0.03668   acc: 0.9897
 epoch: 97   batch: 2    loss: 0.04792   acc: 0.9847
 epoch: 97   batch: 3    loss: 0.06035   acc: 0.9833
 epoch: 97   batch: 4    loss: 0.04451   acc: 0.988
 epoch: 97   batch: 5    loss: 0.04566   acc: 0.986
 epoch: 97   batch: 6    loss: 0.03655   acc: 0.9883
 epoch: 97   batch: 7    loss: 0.03337   acc: 0.9893
 epoch: 97   batch: 8    loss: 0.03751   acc: 0.9867
 epoch: 97   batch: 9    loss: 0.02879   acc: 0.9923
 epoch: 97   batch: 10   loss: 0.03438   acc: 0.989
 epoch: 97   batch: 11   loss: 0.05861   acc: 0.9817
 epoch: 97   batch: 12   loss: 0.04404   acc: 0.988
 epoch: 97   batch: 13   loss: 0.04247   acc: 0.987
 epoch: 97   batch: 14   loss: 0.05449   acc: 0.984
 epoch: 97   batch: 15   loss: 0.05849   acc: 0.9827
 epoch: 97   batch: 16   loss: 0.04216   acc: 0.989
 epoch: 97   batch: 17   loss: 0.04193   acc: 0.9863
 epoch: 97   batch: 18   loss: 0.05931   acc: 0.983
 epoch: 97   batch: 19   loss: 0.05291   acc: 0.9847
 epoch: 97   batch: 20   loss: 0.0867    acc: 0.98
 means -->               loss: 0.04734   acc: 0.9862]
[norms of weights -> l1: 24215.227, l2: 39.65877]
EPOCH: 98/100...
[fit info (epoch 98):
 epoch: 98   batch: 1    loss: 0.02753   acc: 0.992
 epoch: 98   batch: 2    loss: 0.04984   acc: 0.9873
 epoch: 98   batch: 3    loss: 0.05923   acc: 0.983
 epoch: 98   batch: 4    loss: 0.07479   acc: 0.976
 epoch: 98   batch: 5    loss: 0.0958    acc: 0.9727
 epoch: 98   batch: 6    loss: 0.04629   acc: 0.9873
 epoch: 98   batch: 7    loss: 0.05244   acc: 0.9857
 epoch: 98   batch: 8    loss: 0.0623    acc: 0.984
 epoch: 98   batch: 9    loss: 0.06209   acc: 0.9817
 epoch: 98   batch: 10   loss: 0.05378   acc: 0.9823
 epoch: 98   batch: 11   loss: 0.06193   acc: 0.98
 epoch: 98   batch: 12   loss: 0.0529    acc: 0.9827
 epoch: 98   batch: 13   loss: 0.04988   acc: 0.985
 epoch: 98   batch: 14   loss: 0.05963   acc: 0.9803
 epoch: 98   batch: 15   loss: 0.04134   acc: 0.986
 epoch: 98   batch: 16   loss: 0.04855   acc: 0.987
 epoch: 98   batch: 17   loss: 0.06749   acc: 0.9817
 epoch: 98   batch: 18   loss: 0.06154   acc: 0.983
 epoch: 98   batch: 19   loss: 0.06416   acc: 0.9813
 epoch: 98   batch: 20   loss: 0.05578   acc: 0.981
 means -->               loss: 0.05736   acc: 0.983]
[norms of weights -> l1: 24231.664, l2: 39.694731]
EPOCH: 99/100...
[fit info (epoch 99):
 epoch: 99   batch: 1    loss: 0.04234   acc: 0.987
 epoch: 99   batch: 2    loss: 0.03673   acc: 0.9893
 epoch: 99   batch: 3    loss: 0.03414   acc: 0.9883
 epoch: 99   batch: 4    loss: 0.05829   acc: 0.9793
 epoch: 99   batch: 5    loss: 0.04712   acc: 0.9887
 epoch: 99   batch: 6    loss: 0.0467    acc: 0.9827
 epoch: 99   batch: 7    loss: 0.04108   acc: 0.9843
 epoch: 99   batch: 8    loss: 0.036     acc: 0.9903
 epoch: 99   batch: 9    loss: 0.04484   acc: 0.9867
 epoch: 99   batch: 10   loss: 0.09304   acc: 0.9763
 epoch: 99   batch: 11   loss: 0.06855   acc: 0.9793
 epoch: 99   batch: 12   loss: 0.03819   acc: 0.9883
 epoch: 99   batch: 13   loss: 0.04361   acc: 0.989
 epoch: 99   batch: 14   loss: 0.02917   acc: 0.9903
 epoch: 99   batch: 15   loss: 0.07836   acc: 0.9757
 epoch: 99   batch: 16   loss: 0.05119   acc: 0.986
 epoch: 99   batch: 17   loss: 0.07612   acc: 0.9797
 epoch: 99   batch: 18   loss: 0.05963   acc: 0.9807
 epoch: 99   batch: 19   loss: 0.04677   acc: 0.9877
 epoch: 99   batch: 20   loss: 0.03626   acc: 0.99
 means -->               loss: 0.05041   acc: 0.985]
[norms of weights -> l1: 24247.571, l2: 39.729355]
EPOCH: 100/100...
[fit info (epoch 100):
 epoch: 100  batch: 1    loss: 0.04379   acc: 0.9863
 epoch: 100  batch: 2    loss: 0.05433   acc: 0.984
 epoch: 100  batch: 3    loss: 0.03592   acc: 0.9893
 epoch: 100  batch: 4    loss: 0.04644   acc: 0.9863
 epoch: 100  batch: 5    loss: 0.04109   acc: 0.986
 epoch: 100  batch: 6    loss: 0.05611   acc: 0.9823
 epoch: 100  batch: 7    loss: 0.0341    acc: 0.9883
 epoch: 100  batch: 8    loss: 0.04567   acc: 0.986
 epoch: 100  batch: 9    loss: 0.03271   acc: 0.989
 epoch: 100  batch: 10   loss: 0.03892   acc: 0.9897
 epoch: 100  batch: 11   loss: 0.0559    acc: 0.9827
 epoch: 100  batch: 12   loss: 0.05334   acc: 0.9857
 epoch: 100  batch: 13   loss: 0.0431    acc: 0.987
 epoch: 100  batch: 14   loss: 0.02996   acc: 0.9913
 epoch: 100  batch: 15   loss: 0.08467   acc: 0.9813
 epoch: 100  batch: 16   loss: 0.04639   acc: 0.984
 epoch: 100  batch: 17   loss: 0.05362   acc: 0.9883
 epoch: 100  batch: 18   loss: 0.03894   acc: 0.9893
 epoch: 100  batch: 19   loss: 0.04425   acc: 0.987
 epoch: 100  batch: 20   loss: 0.04962   acc: 0.9853
 means -->               loss: 0.04644   acc: 0.9865]
[norms of weights -> l1: 24262.007, l2: 39.760737]
HMDL FIT DONE. [time: 108260.65874099731 s]
DO PICKLE... [to: ./hmdl_clfs/0651561704_hmdl_clf.bin]
DO PICKLE DONE. [time: 0.30222296714782715 s]

HMDL CLF ACC AND LOSS... [after fit]
[train acc: 0.9942833333333333, train loss: 0.018535077571868896]
[test acc: 0.9913, test loss: 0.026751525700092316]
HMDL CLF ACC AND LOSS DONE. [time: 314.3828854560852 s]


KERAS MODEL SUMMARY:
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 c0 (Conv2D)                 (None, 28, 28, 32)        1600      
                                                                 
 c1 (Conv2D)                 (None, 28, 28, 32)        50208     
                                                                 
 m2 (MaxPooling2D)           (None, 14, 14, 32)        0         
                                                                 
 dr3 (Dropout)               (None, 14, 14, 32)        0         
                                                                 
 c4 (Conv2D)                 (None, 14, 14, 64)        51264     
                                                                 
 c5 (Conv2D)                 (None, 14, 14, 64)        102464    
                                                                 
 m6 (MaxPooling2D)           (None, 7, 7, 64)          0         
                                                                 
 dr7 (Dropout)               (None, 7, 7, 64)          0         
                                                                 
 c8 (Conv2D)                 (None, 7, 7, 128)         73856     
                                                                 
 c9 (Conv2D)                 (None, 7, 7, 128)         147584    
                                                                 
 m10 (MaxPooling2D)          (None, 3, 3, 128)         0         
                                                                 
 dr11 (Dropout)              (None, 3, 3, 128)         0         
                                                                 
 f12 (Flatten)               (None, 1152)              0         
                                                                 
 d13 (Dense)                 (None, 128)               147584    
                                                                 
 dr14 (Dropout)              (None, 128)               0         
                                                                 
 d15 (Dense)                 (None, 10)                1290      
                                                                 
=================================================================
Total params: 575,850
Trainable params: 575,850
Non-trainable params: 0
_________________________________________________________________

KERAS CLF ACC AND LOSS... [before fit]

   1/1875 [..............................] - ETA: 1:20:21 - loss: 5.3573 - accuracy: 0.0312
   7/1875 [..............................] - ETA: 17s - loss: 5.4194 - accuracy: 0.0536    
  13/1875 [..............................] - ETA: 18s - loss: 5.2337 - accuracy: 0.0817
  19/1875 [..............................] - ETA: 17s - loss: 5.4650 - accuracy: 0.0839
  25/1875 [..............................] - ETA: 17s - loss: 5.4222 - accuracy: 0.0850
  31/1875 [..............................] - ETA: 17s - loss: 5.4051 - accuracy: 0.0857
  37/1875 [..............................] - ETA: 17s - loss: 5.4176 - accuracy: 0.0836
  43/1875 [..............................] - ETA: 17s - loss: 5.4469 - accuracy: 0.0836
  49/1875 [..............................] - ETA: 17s - loss: 5.4548 - accuracy: 0.0880
  55/1875 [..............................] - ETA: 17s - loss: 5.4188 - accuracy: 0.0881
  61/1875 [..............................] - ETA: 17s - loss: 5.3778 - accuracy: 0.0922
  67/1875 [>.............................] - ETA: 16s - loss: 5.3645 - accuracy: 0.0938
  73/1875 [>.............................] - ETA: 16s - loss: 5.3752 - accuracy: 0.0942
  79/1875 [>.............................] - ETA: 16s - loss: 5.3651 - accuracy: 0.0941
  85/1875 [>.............................] - ETA: 16s - loss: 5.3462 - accuracy: 0.0938
  91/1875 [>.............................] - ETA: 16s - loss: 5.3458 - accuracy: 0.0965
  97/1875 [>.............................] - ETA: 16s - loss: 5.3295 - accuracy: 0.0986
 103/1875 [>.............................] - ETA: 16s - loss: 5.3120 - accuracy: 0.0968
 109/1875 [>.............................] - ETA: 16s - loss: 5.3050 - accuracy: 0.0992
 115/1875 [>.............................] - ETA: 16s - loss: 5.2999 - accuracy: 0.1008
 121/1875 [>.............................] - ETA: 16s - loss: 5.2985 - accuracy: 0.1010
 127/1875 [=>............................] - ETA: 16s - loss: 5.2907 - accuracy: 0.1004
 133/1875 [=>............................] - ETA: 16s - loss: 5.3008 - accuracy: 0.0996
 139/1875 [=>............................] - ETA: 16s - loss: 5.2939 - accuracy: 0.0991
 145/1875 [=>............................] - ETA: 16s - loss: 5.3016 - accuracy: 0.0985
 151/1875 [=>............................] - ETA: 16s - loss: 5.2953 - accuracy: 0.0989
 157/1875 [=>............................] - ETA: 16s - loss: 5.3055 - accuracy: 0.0991
 163/1875 [=>............................] - ETA: 15s - loss: 5.3088 - accuracy: 0.0991
 169/1875 [=>............................] - ETA: 15s - loss: 5.3016 - accuracy: 0.0993
 175/1875 [=>............................] - ETA: 15s - loss: 5.2942 - accuracy: 0.0998
 181/1875 [=>............................] - ETA: 15s - loss: 5.2761 - accuracy: 0.1015
 187/1875 [=>............................] - ETA: 15s - loss: 5.2776 - accuracy: 0.1018
 193/1875 [==>...........................] - ETA: 15s - loss: 5.2769 - accuracy: 0.1025
 199/1875 [==>...........................] - ETA: 15s - loss: 5.2779 - accuracy: 0.1014
 205/1875 [==>...........................] - ETA: 15s - loss: 5.2767 - accuracy: 0.1018
 211/1875 [==>...........................] - ETA: 15s - loss: 5.2907 - accuracy: 0.1015
 217/1875 [==>...........................] - ETA: 15s - loss: 5.2828 - accuracy: 0.1025
 223/1875 [==>...........................] - ETA: 15s - loss: 5.2807 - accuracy: 0.1024
 229/1875 [==>...........................] - ETA: 15s - loss: 5.2826 - accuracy: 0.1019
 235/1875 [==>...........................] - ETA: 15s - loss: 5.2815 - accuracy: 0.1023
 241/1875 [==>...........................] - ETA: 15s - loss: 5.2778 - accuracy: 0.1028
 247/1875 [==>...........................] - ETA: 15s - loss: 5.2729 - accuracy: 0.1031
 253/1875 [===>..........................] - ETA: 15s - loss: 5.2810 - accuracy: 0.1025
 259/1875 [===>..........................] - ETA: 15s - loss: 5.2823 - accuracy: 0.1024
 265/1875 [===>..........................] - ETA: 14s - loss: 5.2855 - accuracy: 0.1026
 271/1875 [===>..........................] - ETA: 14s - loss: 5.2916 - accuracy: 0.1023
 277/1875 [===>..........................] - ETA: 14s - loss: 5.2909 - accuracy: 0.1024
 283/1875 [===>..........................] - ETA: 14s - loss: 5.2922 - accuracy: 0.1027
 289/1875 [===>..........................] - ETA: 14s - loss: 5.2908 - accuracy: 0.1024
 295/1875 [===>..........................] - ETA: 14s - loss: 5.2907 - accuracy: 0.1028
 301/1875 [===>..........................] - ETA: 14s - loss: 5.2874 - accuracy: 0.1031
 307/1875 [===>..........................] - ETA: 14s - loss: 5.2865 - accuracy: 0.1032
 313/1875 [====>.........................] - ETA: 14s - loss: 5.2845 - accuracy: 0.1025
 319/1875 [====>.........................] - ETA: 14s - loss: 5.2833 - accuracy: 0.1027
 325/1875 [====>.........................] - ETA: 14s - loss: 5.2854 - accuracy: 0.1021
 331/1875 [====>.........................] - ETA: 14s - loss: 5.2841 - accuracy: 0.1022
 337/1875 [====>.........................] - ETA: 14s - loss: 5.2815 - accuracy: 0.1027
 343/1875 [====>.........................] - ETA: 14s - loss: 5.2802 - accuracy: 0.1029
 349/1875 [====>.........................] - ETA: 14s - loss: 5.2792 - accuracy: 0.1027
 355/1875 [====>.........................] - ETA: 14s - loss: 5.2802 - accuracy: 0.1023
 361/1875 [====>.........................] - ETA: 14s - loss: 5.2755 - accuracy: 0.1030
 367/1875 [====>.........................] - ETA: 14s - loss: 5.2839 - accuracy: 0.1028
 373/1875 [====>.........................] - ETA: 13s - loss: 5.2849 - accuracy: 0.1025
 379/1875 [=====>........................] - ETA: 13s - loss: 5.2873 - accuracy: 0.1026
 385/1875 [=====>........................] - ETA: 13s - loss: 5.2872 - accuracy: 0.1023
 391/1875 [=====>........................] - ETA: 13s - loss: 5.2869 - accuracy: 0.1021
 397/1875 [=====>........................] - ETA: 13s - loss: 5.2809 - accuracy: 0.1020
 403/1875 [=====>........................] - ETA: 13s - loss: 5.2833 - accuracy: 0.1017
 409/1875 [=====>........................] - ETA: 13s - loss: 5.2888 - accuracy: 0.1011
 415/1875 [=====>........................] - ETA: 13s - loss: 5.2897 - accuracy: 0.1013
 421/1875 [=====>........................] - ETA: 13s - loss: 5.2913 - accuracy: 0.1011
 427/1875 [=====>........................] - ETA: 13s - loss: 5.2876 - accuracy: 0.1011
 433/1875 [=====>........................] - ETA: 13s - loss: 5.2866 - accuracy: 0.1013
 439/1875 [======>.......................] - ETA: 13s - loss: 5.2893 - accuracy: 0.1008
 445/1875 [======>.......................] - ETA: 13s - loss: 5.2847 - accuracy: 0.1013
 451/1875 [======>.......................] - ETA: 13s - loss: 5.2854 - accuracy: 0.1012
 457/1875 [======>.......................] - ETA: 13s - loss: 5.2848 - accuracy: 0.1011
 463/1875 [======>.......................] - ETA: 13s - loss: 5.2838 - accuracy: 0.1011
 469/1875 [======>.......................] - ETA: 13s - loss: 5.2875 - accuracy: 0.1009
 475/1875 [======>.......................] - ETA: 12s - loss: 5.2872 - accuracy: 0.1013
 481/1875 [======>.......................] - ETA: 12s - loss: 5.2907 - accuracy: 0.1012
 487/1875 [======>.......................] - ETA: 12s - loss: 5.2884 - accuracy: 0.1009
 493/1875 [======>.......................] - ETA: 12s - loss: 5.2850 - accuracy: 0.1012
 499/1875 [======>.......................] - ETA: 12s - loss: 5.2887 - accuracy: 0.1010
 505/1875 [=======>......................] - ETA: 12s - loss: 5.2926 - accuracy: 0.1004
 511/1875 [=======>......................] - ETA: 12s - loss: 5.2909 - accuracy: 0.1005
 517/1875 [=======>......................] - ETA: 12s - loss: 5.2924 - accuracy: 0.1005
 523/1875 [=======>......................] - ETA: 12s - loss: 5.2932 - accuracy: 0.1005
 529/1875 [=======>......................] - ETA: 12s - loss: 5.2945 - accuracy: 0.1004
 535/1875 [=======>......................] - ETA: 12s - loss: 5.2949 - accuracy: 0.1002
 541/1875 [=======>......................] - ETA: 12s - loss: 5.2991 - accuracy: 0.0995
 547/1875 [=======>......................] - ETA: 12s - loss: 5.2983 - accuracy: 0.0993
 553/1875 [=======>......................] - ETA: 12s - loss: 5.2977 - accuracy: 0.0989
 559/1875 [=======>......................] - ETA: 12s - loss: 5.2974 - accuracy: 0.0991
 565/1875 [========>.....................] - ETA: 12s - loss: 5.3006 - accuracy: 0.0991
 571/1875 [========>.....................] - ETA: 12s - loss: 5.3014 - accuracy: 0.0992
 577/1875 [========>.....................] - ETA: 12s - loss: 5.3002 - accuracy: 0.0991
 583/1875 [========>.....................] - ETA: 11s - loss: 5.2965 - accuracy: 0.0993
 589/1875 [========>.....................] - ETA: 11s - loss: 5.2960 - accuracy: 0.0991
 595/1875 [========>.....................] - ETA: 11s - loss: 5.2924 - accuracy: 0.0995
 601/1875 [========>.....................] - ETA: 11s - loss: 5.2923 - accuracy: 0.0997
 607/1875 [========>.....................] - ETA: 11s - loss: 5.2929 - accuracy: 0.0997
 613/1875 [========>.....................] - ETA: 11s - loss: 5.2965 - accuracy: 0.0995
 619/1875 [========>.....................] - ETA: 11s - loss: 5.2945 - accuracy: 0.0998
 625/1875 [=========>....................] - ETA: 11s - loss: 5.2961 - accuracy: 0.0997
 631/1875 [=========>....................] - ETA: 11s - loss: 5.2946 - accuracy: 0.0995
 637/1875 [=========>....................] - ETA: 11s - loss: 5.2940 - accuracy: 0.0995
 643/1875 [=========>....................] - ETA: 11s - loss: 5.2959 - accuracy: 0.0992
 649/1875 [=========>....................] - ETA: 11s - loss: 5.2957 - accuracy: 0.0992
 655/1875 [=========>....................] - ETA: 11s - loss: 5.2979 - accuracy: 0.0990
 661/1875 [=========>....................] - ETA: 11s - loss: 5.2983 - accuracy: 0.0989
 667/1875 [=========>....................] - ETA: 11s - loss: 5.2985 - accuracy: 0.0987
 673/1875 [=========>....................] - ETA: 11s - loss: 5.2964 - accuracy: 0.0986
 679/1875 [=========>....................] - ETA: 11s - loss: 5.2968 - accuracy: 0.0984
 685/1875 [=========>....................] - ETA: 11s - loss: 5.2958 - accuracy: 0.0988
 691/1875 [==========>...................] - ETA: 10s - loss: 5.2983 - accuracy: 0.0988
 697/1875 [==========>...................] - ETA: 10s - loss: 5.2984 - accuracy: 0.0987
 703/1875 [==========>...................] - ETA: 10s - loss: 5.3023 - accuracy: 0.0984
 709/1875 [==========>...................] - ETA: 10s - loss: 5.3023 - accuracy: 0.0984
 715/1875 [==========>...................] - ETA: 10s - loss: 5.3000 - accuracy: 0.0985
 721/1875 [==========>...................] - ETA: 10s - loss: 5.2973 - accuracy: 0.0986
 727/1875 [==========>...................] - ETA: 10s - loss: 5.2978 - accuracy: 0.0988
 733/1875 [==========>...................] - ETA: 10s - loss: 5.2964 - accuracy: 0.0990
 739/1875 [==========>...................] - ETA: 10s - loss: 5.2941 - accuracy: 0.0992
 745/1875 [==========>...................] - ETA: 10s - loss: 5.2924 - accuracy: 0.0995
 751/1875 [===========>..................] - ETA: 10s - loss: 5.2907 - accuracy: 0.0995
 757/1875 [===========>..................] - ETA: 10s - loss: 5.2932 - accuracy: 0.0992
 763/1875 [===========>..................] - ETA: 10s - loss: 5.2935 - accuracy: 0.0992
 769/1875 [===========>..................] - ETA: 10s - loss: 5.2910 - accuracy: 0.0992
 775/1875 [===========>..................] - ETA: 10s - loss: 5.2924 - accuracy: 0.0992
 781/1875 [===========>..................] - ETA: 10s - loss: 5.2930 - accuracy: 0.0992
 787/1875 [===========>..................] - ETA: 10s - loss: 5.2912 - accuracy: 0.0992
 793/1875 [===========>..................] - ETA: 10s - loss: 5.2892 - accuracy: 0.0992
 799/1875 [===========>..................] - ETA: 9s - loss: 5.2882 - accuracy: 0.0994 
 805/1875 [===========>..................] - ETA: 9s - loss: 5.2887 - accuracy: 0.0996
 811/1875 [===========>..................] - ETA: 9s - loss: 5.2908 - accuracy: 0.0995
 817/1875 [============>.................] - ETA: 9s - loss: 5.2924 - accuracy: 0.0994
 823/1875 [============>.................] - ETA: 9s - loss: 5.2935 - accuracy: 0.0993
 829/1875 [============>.................] - ETA: 9s - loss: 5.2945 - accuracy: 0.0991
 835/1875 [============>.................] - ETA: 9s - loss: 5.2931 - accuracy: 0.0993
 841/1875 [============>.................] - ETA: 9s - loss: 5.2910 - accuracy: 0.0994
 847/1875 [============>.................] - ETA: 9s - loss: 5.2924 - accuracy: 0.0994
 853/1875 [============>.................] - ETA: 9s - loss: 5.2925 - accuracy: 0.0995
 859/1875 [============>.................] - ETA: 9s - loss: 5.2914 - accuracy: 0.0994
 865/1875 [============>.................] - ETA: 9s - loss: 5.2960 - accuracy: 0.0993
 871/1875 [============>.................] - ETA: 9s - loss: 5.2942 - accuracy: 0.0996
 877/1875 [=============>................] - ETA: 9s - loss: 5.2976 - accuracy: 0.0995
 883/1875 [=============>................] - ETA: 9s - loss: 5.2973 - accuracy: 0.0995
 889/1875 [=============>................] - ETA: 9s - loss: 5.3000 - accuracy: 0.0995
 895/1875 [=============>................] - ETA: 9s - loss: 5.3005 - accuracy: 0.0994
 901/1875 [=============>................] - ETA: 9s - loss: 5.3008 - accuracy: 0.0995
 907/1875 [=============>................] - ETA: 8s - loss: 5.3019 - accuracy: 0.0994
 913/1875 [=============>................] - ETA: 8s - loss: 5.3020 - accuracy: 0.0994
 919/1875 [=============>................] - ETA: 8s - loss: 5.3007 - accuracy: 0.0994
 925/1875 [=============>................] - ETA: 8s - loss: 5.2981 - accuracy: 0.0997
 931/1875 [=============>................] - ETA: 8s - loss: 5.2986 - accuracy: 0.0995
 937/1875 [=============>................] - ETA: 8s - loss: 5.2985 - accuracy: 0.0996
 943/1875 [==============>...............] - ETA: 8s - loss: 5.2982 - accuracy: 0.0995
 949/1875 [==============>...............] - ETA: 8s - loss: 5.2963 - accuracy: 0.0995
 955/1875 [==============>...............] - ETA: 8s - loss: 5.2965 - accuracy: 0.0993
 961/1875 [==============>...............] - ETA: 8s - loss: 5.2959 - accuracy: 0.0993
 967/1875 [==============>...............] - ETA: 8s - loss: 5.2966 - accuracy: 0.0992
 973/1875 [==============>...............] - ETA: 8s - loss: 5.2941 - accuracy: 0.0995
 979/1875 [==============>...............] - ETA: 8s - loss: 5.2940 - accuracy: 0.0996
 985/1875 [==============>...............] - ETA: 8s - loss: 5.2958 - accuracy: 0.0996
 991/1875 [==============>...............] - ETA: 8s - loss: 5.2945 - accuracy: 0.0998
 997/1875 [==============>...............] - ETA: 8s - loss: 5.2951 - accuracy: 0.0997
1003/1875 [===============>..............] - ETA: 8s - loss: 5.2930 - accuracy: 0.0998
1009/1875 [===============>..............] - ETA: 8s - loss: 5.2936 - accuracy: 0.0996
1015/1875 [===============>..............] - ETA: 7s - loss: 5.2921 - accuracy: 0.0997
1021/1875 [===============>..............] - ETA: 7s - loss: 5.2923 - accuracy: 0.0997
1027/1875 [===============>..............] - ETA: 7s - loss: 5.2934 - accuracy: 0.0997
1033/1875 [===============>..............] - ETA: 7s - loss: 5.2937 - accuracy: 0.0997
1039/1875 [===============>..............] - ETA: 7s - loss: 5.2931 - accuracy: 0.0999
1045/1875 [===============>..............] - ETA: 7s - loss: 5.2944 - accuracy: 0.1000
1051/1875 [===============>..............] - ETA: 7s - loss: 5.2949 - accuracy: 0.0998
1057/1875 [===============>..............] - ETA: 7s - loss: 5.2954 - accuracy: 0.0999
1063/1875 [================>.............] - ETA: 7s - loss: 5.2943 - accuracy: 0.0999
1069/1875 [================>.............] - ETA: 7s - loss: 5.2951 - accuracy: 0.0998
1075/1875 [================>.............] - ETA: 7s - loss: 5.2935 - accuracy: 0.0999
1081/1875 [================>.............] - ETA: 7s - loss: 5.2940 - accuracy: 0.0999
1087/1875 [================>.............] - ETA: 7s - loss: 5.2941 - accuracy: 0.0999
1093/1875 [================>.............] - ETA: 7s - loss: 5.2940 - accuracy: 0.1000
1099/1875 [================>.............] - ETA: 7s - loss: 5.2943 - accuracy: 0.1001
1105/1875 [================>.............] - ETA: 7s - loss: 5.2943 - accuracy: 0.1001
1111/1875 [================>.............] - ETA: 7s - loss: 5.2926 - accuracy: 0.1003
1117/1875 [================>.............] - ETA: 7s - loss: 5.2924 - accuracy: 0.1004
1123/1875 [================>.............] - ETA: 6s - loss: 5.2905 - accuracy: 0.1005
1129/1875 [=================>............] - ETA: 6s - loss: 5.2906 - accuracy: 0.1003
1135/1875 [=================>............] - ETA: 6s - loss: 5.2921 - accuracy: 0.1002
1141/1875 [=================>............] - ETA: 6s - loss: 5.2891 - accuracy: 0.1003
1147/1875 [=================>............] - ETA: 6s - loss: 5.2883 - accuracy: 0.1003
1153/1875 [=================>............] - ETA: 6s - loss: 5.2862 - accuracy: 0.1004
1159/1875 [=================>............] - ETA: 6s - loss: 5.2858 - accuracy: 0.1004
1165/1875 [=================>............] - ETA: 6s - loss: 5.2860 - accuracy: 0.1002
1171/1875 [=================>............] - ETA: 6s - loss: 5.2858 - accuracy: 0.1002
1177/1875 [=================>............] - ETA: 6s - loss: 5.2870 - accuracy: 0.1001
1183/1875 [=================>............] - ETA: 6s - loss: 5.2872 - accuracy: 0.1001
1189/1875 [==================>...........] - ETA: 6s - loss: 5.2864 - accuracy: 0.1001
1195/1875 [==================>...........] - ETA: 6s - loss: 5.2838 - accuracy: 0.1001
1201/1875 [==================>...........] - ETA: 6s - loss: 5.2837 - accuracy: 0.1000
1207/1875 [==================>...........] - ETA: 6s - loss: 5.2826 - accuracy: 0.1002
1213/1875 [==================>...........] - ETA: 6s - loss: 5.2843 - accuracy: 0.1000
1219/1875 [==================>...........] - ETA: 6s - loss: 5.2847 - accuracy: 0.0999
1225/1875 [==================>...........] - ETA: 6s - loss: 5.2830 - accuracy: 0.1001
1231/1875 [==================>...........] - ETA: 5s - loss: 5.2844 - accuracy: 0.1000
1237/1875 [==================>...........] - ETA: 5s - loss: 5.2841 - accuracy: 0.1000
1243/1875 [==================>...........] - ETA: 5s - loss: 5.2836 - accuracy: 0.1002
1249/1875 [==================>...........] - ETA: 5s - loss: 5.2847 - accuracy: 0.1003
1255/1875 [===================>..........] - ETA: 5s - loss: 5.2842 - accuracy: 0.1002
1261/1875 [===================>..........] - ETA: 5s - loss: 5.2841 - accuracy: 0.1003
1267/1875 [===================>..........] - ETA: 5s - loss: 5.2846 - accuracy: 0.1004
1273/1875 [===================>..........] - ETA: 5s - loss: 5.2852 - accuracy: 0.1004
1279/1875 [===================>..........] - ETA: 5s - loss: 5.2857 - accuracy: 0.1004
1285/1875 [===================>..........] - ETA: 5s - loss: 5.2849 - accuracy: 0.1004
1291/1875 [===================>..........] - ETA: 5s - loss: 5.2865 - accuracy: 0.1003
1297/1875 [===================>..........] - ETA: 5s - loss: 5.2858 - accuracy: 0.1000
1303/1875 [===================>..........] - ETA: 5s - loss: 5.2871 - accuracy: 0.0997
1309/1875 [===================>..........] - ETA: 5s - loss: 5.2864 - accuracy: 0.0997
1315/1875 [====================>.........] - ETA: 5s - loss: 5.2871 - accuracy: 0.0997
1321/1875 [====================>.........] - ETA: 5s - loss: 5.2870 - accuracy: 0.0997
1327/1875 [====================>.........] - ETA: 5s - loss: 5.2880 - accuracy: 0.0995
1333/1875 [====================>.........] - ETA: 5s - loss: 5.2885 - accuracy: 0.0995
1339/1875 [====================>.........] - ETA: 4s - loss: 5.2883 - accuracy: 0.0996
1345/1875 [====================>.........] - ETA: 4s - loss: 5.2880 - accuracy: 0.0997
1351/1875 [====================>.........] - ETA: 4s - loss: 5.2870 - accuracy: 0.0998
1357/1875 [====================>.........] - ETA: 4s - loss: 5.2877 - accuracy: 0.0999
1363/1875 [====================>.........] - ETA: 4s - loss: 5.2867 - accuracy: 0.0999
1369/1875 [====================>.........] - ETA: 4s - loss: 5.2857 - accuracy: 0.1000
1375/1875 [=====================>........] - ETA: 4s - loss: 5.2855 - accuracy: 0.1000
1381/1875 [=====================>........] - ETA: 4s - loss: 5.2847 - accuracy: 0.0999
1387/1875 [=====================>........] - ETA: 4s - loss: 5.2843 - accuracy: 0.0999
1393/1875 [=====================>........] - ETA: 4s - loss: 5.2844 - accuracy: 0.0998
1399/1875 [=====================>........] - ETA: 4s - loss: 5.2844 - accuracy: 0.0997
1405/1875 [=====================>........] - ETA: 4s - loss: 5.2849 - accuracy: 0.0998
1411/1875 [=====================>........] - ETA: 4s - loss: 5.2858 - accuracy: 0.0997
1417/1875 [=====================>........] - ETA: 4s - loss: 5.2857 - accuracy: 0.0997
1423/1875 [=====================>........] - ETA: 4s - loss: 5.2865 - accuracy: 0.0997
1429/1875 [=====================>........] - ETA: 4s - loss: 5.2852 - accuracy: 0.0998
1435/1875 [=====================>........] - ETA: 4s - loss: 5.2844 - accuracy: 0.1000
1441/1875 [======================>.......] - ETA: 4s - loss: 5.2852 - accuracy: 0.0999
1447/1875 [======================>.......] - ETA: 3s - loss: 5.2848 - accuracy: 0.1000
1453/1875 [======================>.......] - ETA: 3s - loss: 5.2855 - accuracy: 0.0999
1459/1875 [======================>.......] - ETA: 3s - loss: 5.2870 - accuracy: 0.0998
1465/1875 [======================>.......] - ETA: 3s - loss: 5.2871 - accuracy: 0.0998
1471/1875 [======================>.......] - ETA: 3s - loss: 5.2861 - accuracy: 0.0998
1477/1875 [======================>.......] - ETA: 3s - loss: 5.2865 - accuracy: 0.0997
1483/1875 [======================>.......] - ETA: 3s - loss: 5.2869 - accuracy: 0.0995
1489/1875 [======================>.......] - ETA: 3s - loss: 5.2880 - accuracy: 0.0995
1495/1875 [======================>.......] - ETA: 3s - loss: 5.2884 - accuracy: 0.0994
1501/1875 [=======================>......] - ETA: 3s - loss: 5.2898 - accuracy: 0.0993
1507/1875 [=======================>......] - ETA: 3s - loss: 5.2903 - accuracy: 0.0992
1513/1875 [=======================>......] - ETA: 3s - loss: 5.2898 - accuracy: 0.0992
1519/1875 [=======================>......] - ETA: 3s - loss: 5.2900 - accuracy: 0.0993
1525/1875 [=======================>......] - ETA: 3s - loss: 5.2901 - accuracy: 0.0993
1531/1875 [=======================>......] - ETA: 3s - loss: 5.2898 - accuracy: 0.0993
1537/1875 [=======================>......] - ETA: 3s - loss: 5.2891 - accuracy: 0.0994
1543/1875 [=======================>......] - ETA: 3s - loss: 5.2877 - accuracy: 0.0996
1549/1875 [=======================>......] - ETA: 3s - loss: 5.2896 - accuracy: 0.0994
1555/1875 [=======================>......] - ETA: 2s - loss: 5.2900 - accuracy: 0.0994
1561/1875 [=======================>......] - ETA: 2s - loss: 5.2884 - accuracy: 0.0996
1567/1875 [========================>.....] - ETA: 2s - loss: 5.2890 - accuracy: 0.0996
1573/1875 [========================>.....] - ETA: 2s - loss: 5.2880 - accuracy: 0.0997
1579/1875 [========================>.....] - ETA: 2s - loss: 5.2880 - accuracy: 0.0996
1585/1875 [========================>.....] - ETA: 2s - loss: 5.2876 - accuracy: 0.0997
1591/1875 [========================>.....] - ETA: 2s - loss: 5.2866 - accuracy: 0.0997
1597/1875 [========================>.....] - ETA: 2s - loss: 5.2865 - accuracy: 0.0998
1603/1875 [========================>.....] - ETA: 2s - loss: 5.2876 - accuracy: 0.0998
1609/1875 [========================>.....] - ETA: 2s - loss: 5.2877 - accuracy: 0.0998
1615/1875 [========================>.....] - ETA: 2s - loss: 5.2874 - accuracy: 0.0997
1621/1875 [========================>.....] - ETA: 2s - loss: 5.2875 - accuracy: 0.0998
1627/1875 [=========================>....] - ETA: 2s - loss: 5.2872 - accuracy: 0.0998
1633/1875 [=========================>....] - ETA: 2s - loss: 5.2871 - accuracy: 0.0998
1639/1875 [=========================>....] - ETA: 2s - loss: 5.2868 - accuracy: 0.0999
1645/1875 [=========================>....] - ETA: 2s - loss: 5.2865 - accuracy: 0.0999
1651/1875 [=========================>....] - ETA: 2s - loss: 5.2869 - accuracy: 0.0999
1657/1875 [=========================>....] - ETA: 2s - loss: 5.2855 - accuracy: 0.1001
1663/1875 [=========================>....] - ETA: 1s - loss: 5.2850 - accuracy: 0.1001
1669/1875 [=========================>....] - ETA: 1s - loss: 5.2841 - accuracy: 0.1002
1675/1875 [=========================>....] - ETA: 1s - loss: 5.2840 - accuracy: 0.1002
1681/1875 [=========================>....] - ETA: 1s - loss: 5.2837 - accuracy: 0.1003
1687/1875 [=========================>....] - ETA: 1s - loss: 5.2840 - accuracy: 0.1003
1693/1875 [==========================>...] - ETA: 1s - loss: 5.2838 - accuracy: 0.1003
1699/1875 [==========================>...] - ETA: 1s - loss: 5.2844 - accuracy: 0.1003
1705/1875 [==========================>...] - ETA: 1s - loss: 5.2843 - accuracy: 0.1003
1711/1875 [==========================>...] - ETA: 1s - loss: 5.2858 - accuracy: 0.1001
1717/1875 [==========================>...] - ETA: 1s - loss: 5.2848 - accuracy: 0.1000
1723/1875 [==========================>...] - ETA: 1s - loss: 5.2853 - accuracy: 0.0998
1729/1875 [==========================>...] - ETA: 1s - loss: 5.2848 - accuracy: 0.0999
1735/1875 [==========================>...] - ETA: 1s - loss: 5.2847 - accuracy: 0.0999
1741/1875 [==========================>...] - ETA: 1s - loss: 5.2857 - accuracy: 0.0998
1747/1875 [==========================>...] - ETA: 1s - loss: 5.2857 - accuracy: 0.0998
1753/1875 [===========================>..] - ETA: 1s - loss: 5.2850 - accuracy: 0.0997
1759/1875 [===========================>..] - ETA: 1s - loss: 5.2845 - accuracy: 0.0998
1765/1875 [===========================>..] - ETA: 1s - loss: 5.2842 - accuracy: 0.0998
1771/1875 [===========================>..] - ETA: 0s - loss: 5.2838 - accuracy: 0.0999
1777/1875 [===========================>..] - ETA: 0s - loss: 5.2847 - accuracy: 0.0999
1783/1875 [===========================>..] - ETA: 0s - loss: 5.2837 - accuracy: 0.0998
1789/1875 [===========================>..] - ETA: 0s - loss: 5.2847 - accuracy: 0.0997
1795/1875 [===========================>..] - ETA: 0s - loss: 5.2847 - accuracy: 0.0998
1801/1875 [===========================>..] - ETA: 0s - loss: 5.2847 - accuracy: 0.0997
1807/1875 [===========================>..] - ETA: 0s - loss: 5.2852 - accuracy: 0.0997
1813/1875 [============================>.] - ETA: 0s - loss: 5.2851 - accuracy: 0.0998
1819/1875 [============================>.] - ETA: 0s - loss: 5.2849 - accuracy: 0.0998
1825/1875 [============================>.] - ETA: 0s - loss: 5.2842 - accuracy: 0.0998
1831/1875 [============================>.] - ETA: 0s - loss: 5.2843 - accuracy: 0.0998
1837/1875 [============================>.] - ETA: 0s - loss: 5.2842 - accuracy: 0.0998
1843/1875 [============================>.] - ETA: 0s - loss: 5.2848 - accuracy: 0.0997
1849/1875 [============================>.] - ETA: 0s - loss: 5.2861 - accuracy: 0.0995
1855/1875 [============================>.] - ETA: 0s - loss: 5.2868 - accuracy: 0.0993
1861/1875 [============================>.] - ETA: 0s - loss: 5.2862 - accuracy: 0.0994
1867/1875 [============================>.] - ETA: 0s - loss: 5.2863 - accuracy: 0.0995
1873/1875 [============================>.] - ETA: 0s - loss: 5.2861 - accuracy: 0.0996
1875/1875 [==============================] - 20s 9ms/step - loss: 5.2862 - accuracy: 0.0997

  1/313 [..............................] - ETA: 1:14 - loss: 5.7550 - accuracy: 0.0000e+00
  6/313 [..............................] - ETA: 3s - loss: 5.6974 - accuracy: 0.0000e+00  
 11/313 [>.............................] - ETA: 3s - loss: 5.6765 - accuracy: 0.0000e+00
 16/313 [>.............................] - ETA: 3s - loss: 5.6989 - accuracy: 0.0000e+00
 21/313 [=>............................] - ETA: 3s - loss: 5.7231 - accuracy: 0.0000e+00
 26/313 [=>............................] - ETA: 3s - loss: 5.7135 - accuracy: 0.0000e+00
 31/313 [=>............................] - ETA: 2s - loss: 5.6709 - accuracy: 0.0000e+00
 36/313 [==>...........................] - ETA: 2s - loss: 5.0985 - accuracy: 0.0017    
 41/313 [==>...........................] - ETA: 2s - loss: 4.6722 - accuracy: 0.0023
 46/313 [===>..........................] - ETA: 2s - loss: 4.3355 - accuracy: 0.0020
 51/313 [===>..........................] - ETA: 2s - loss: 4.0749 - accuracy: 0.0025
 56/313 [====>.........................] - ETA: 2s - loss: 3.8672 - accuracy: 0.0028
 61/313 [====>.........................] - ETA: 2s - loss: 3.7010 - accuracy: 0.0026
 66/313 [=====>........................] - ETA: 2s - loss: 3.5557 - accuracy: 0.0028
 72/313 [=====>........................] - ETA: 2s - loss: 3.2834 - accuracy: 0.0846
 78/313 [======>.......................] - ETA: 2s - loss: 3.0514 - accuracy: 0.1550
 84/313 [=======>......................] - ETA: 2s - loss: 2.8526 - accuracy: 0.2154
 89/313 [=======>......................] - ETA: 2s - loss: 2.7077 - accuracy: 0.2595
 94/313 [========>.....................] - ETA: 2s - loss: 2.5764 - accuracy: 0.2989
 99/313 [========>.....................] - ETA: 2s - loss: 2.4999 - accuracy: 0.3277
105/313 [=========>....................] - ETA: 2s - loss: 2.7473 - accuracy: 0.3089
110/313 [=========>....................] - ETA: 2s - loss: 2.9337 - accuracy: 0.2949
116/313 [==========>...................] - ETA: 2s - loss: 3.1447 - accuracy: 0.2796
121/313 [==========>...................] - ETA: 1s - loss: 3.3131 - accuracy: 0.2681
126/313 [===========>..................] - ETA: 1s - loss: 3.4729 - accuracy: 0.2574
131/313 [===========>..................] - ETA: 1s - loss: 3.6138 - accuracy: 0.2476
137/313 [============>.................] - ETA: 1s - loss: 3.7409 - accuracy: 0.2368
142/313 [============>.................] - ETA: 1s - loss: 3.8396 - accuracy: 0.2284
147/313 [=============>................] - ETA: 1s - loss: 3.9325 - accuracy: 0.2207
152/313 [=============>................] - ETA: 1s - loss: 4.0205 - accuracy: 0.2134
158/313 [==============>...............] - ETA: 1s - loss: 4.1186 - accuracy: 0.2053
164/313 [==============>...............] - ETA: 1s - loss: 4.1424 - accuracy: 0.1978
169/313 [===============>..............] - ETA: 1s - loss: 4.1200 - accuracy: 0.1919
175/313 [===============>..............] - ETA: 1s - loss: 4.0961 - accuracy: 0.1854
180/313 [================>.............] - ETA: 1s - loss: 4.0830 - accuracy: 0.1802
185/313 [================>.............] - ETA: 1s - loss: 4.0661 - accuracy: 0.1753
190/313 [=================>............] - ETA: 1s - loss: 4.0930 - accuracy: 0.1707
196/313 [=================>............] - ETA: 1s - loss: 4.2328 - accuracy: 0.1655
202/313 [==================>...........] - ETA: 1s - loss: 4.3653 - accuracy: 0.1606
208/313 [==================>...........] - ETA: 1s - loss: 4.4871 - accuracy: 0.1559
214/313 [===================>..........] - ETA: 1s - loss: 4.6061 - accuracy: 0.1516
219/313 [===================>..........] - ETA: 0s - loss: 4.7009 - accuracy: 0.1481
225/313 [====================>.........] - ETA: 0s - loss: 4.8051 - accuracy: 0.1442
231/313 [=====================>........] - ETA: 0s - loss: 4.9071 - accuracy: 0.1404
236/313 [=====================>........] - ETA: 0s - loss: 4.9900 - accuracy: 0.1374
241/313 [======================>.......] - ETA: 0s - loss: 5.0743 - accuracy: 0.1346
246/313 [======================>.......] - ETA: 0s - loss: 5.1633 - accuracy: 0.1319
252/313 [=======================>......] - ETA: 0s - loss: 5.2274 - accuracy: 0.1287
258/313 [=======================>......] - ETA: 0s - loss: 5.1892 - accuracy: 0.1257
264/313 [========================>.....] - ETA: 0s - loss: 5.1531 - accuracy: 0.1229
269/313 [========================>.....] - ETA: 0s - loss: 5.1234 - accuracy: 0.1206
275/313 [=========================>....] - ETA: 0s - loss: 5.0919 - accuracy: 0.1180
280/313 [=========================>....] - ETA: 0s - loss: 5.0673 - accuracy: 0.1158
286/313 [==========================>...] - ETA: 0s - loss: 5.0920 - accuracy: 0.1134
291/313 [==========================>...] - ETA: 0s - loss: 5.1193 - accuracy: 0.1115
297/313 [===========================>..] - ETA: 0s - loss: 5.1507 - accuracy: 0.1092
303/313 [============================>.] - ETA: 0s - loss: 5.1886 - accuracy: 0.1071
309/313 [============================>.] - ETA: 0s - loss: 5.2268 - accuracy: 0.1050
313/313 [==============================] - ETA: 0s - loss: 5.2481 - accuracy: 0.1038
313/313 [==============================] - 3s 10ms/step - loss: 5.2481 - accuracy: 0.1038

[train acc: 0.09968333691358566, train loss: 5.286210536956787]
[test acc: 0.10379999876022339, test loss: 5.248051166534424]
KERAS CLF ACC AND LOSS DONE. [time: 23.654448747634888 s]

[keras clf norms of weights before fit -> l1: 21719.2, l2: 34.21651]

KERAS FIT...
Epoch 1/100
